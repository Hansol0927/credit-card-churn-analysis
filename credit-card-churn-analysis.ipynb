{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":12269306,"sourceType":"datasetVersion","datasetId":7731568}],"dockerImageVersionId":31089,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Credit Card Customer Churn Analysis\n\n- 본 프로젝트는 신용카드 고객의 이탈(churn)을 분석하고 예측하기 위해 진행되었습니다. EDA, 머신러닝 모델링, 클러스터링을 통해 고객 특성을 파악하고, 타겟 마케팅 및 유지 전략을 도출하였습니다.  \n\n>  📌 본 프로젝트는 **ZB Team Project 01**의 일환으로 진행되었습니다.\n---\n> ### **목차(Context)**\n✔ Project Summary <br>\n✔ Process 01 - EDA <br>\n✔ Process 02 - 이탈예측 모델링 <br>\n✔ Process 03 - Clustering <br>\n✔ Process 04 - 타겟 클러스터 분석 <br>\n✔ Process 05 - 전략도출 및 제안 <br>","metadata":{}},{"cell_type":"markdown","source":"## 📖 Project Summary\n---\n\n### 시나리오\n```\nB사는 소비자 금융 서비스 산업에 종사하며, 특히 신용카드 서비스를 제공하고 있습니다. \n데이터 분석팀은 최근 소비자 신용카드 포트폴리오에서 수집된 방대한 고객 정보를 활용하려 합니다. 분석팀의 목표는 고객 이탈을 예측하는 것으로, 이를 통해 서비스 개선 및 고객 충성도 향상에 필요한 조치를 취하고자 합니다.\n이들이 활용하려는 데이터에는 나이, 성별, 결혼 상태, 소득 카테고리와 같은 고객의 인구통계학적 세부사항이 포함됩니다. 더 나아가, 신용카드 유형, 가입 기간, 비활성 기간 등 신용카드 제공 업체와의 관계에 대한 인사이트를 제공하는 데이터도 포함되어 있습니다.\n특히, 고객의 소비 행동, 총 거래 잔액, 신용한도와 같은 중요한 데이터는 고객의 이탈 여부에 중요한 역할을 합니다.\n데이터 분석팀은 이를 통해 고객의 이탈을 예측하고, 이러한 예측 정보를 활용하여 포트폴리오 관리 전략을 조정하거나 개별 고객에게 더 맞춤화된 서비스를 제공할 방안을 모색할 예정입니다.\n```\n\n### 문제 정의\n```\n고객이탈은 B사의 수익성에 직결되는 중요한 문제입니다.\n현재로는 B사의 고객이탈에 대한 이탈 가능성을 사전에 예측하거나,\n이탈 가능성이 높은 고객을 사전에 식별하고 전략적으로 대응하는 시스템 및 체계가 부재합니다.\n\n다양한 고객의 정보(인구통계학적 정보 등)가 있음에도 불구하고,\n이를 종합적으로 분석하여 소위 '고위험 고객'을 식별하는 시스템이 마련되어 있지 않습니다.\n따라서 고객의 이탈 가능성을 사전에 예측하고, 이탈위험 점수를 부여하여 위험도를 정량화 한 뒤,\n이를 기반으로 맞춤형 대응전략을 수립할 필요가 있습니다.\n```\n\n### 기대 효과\n```\n- 고객 이탈 가능성이 높은 고객을 사전에 식별함으로서 선제적 대응 가능\n- 고객 세분화 기반 맞춤형 마케팅 캠페인 운영 체계 구축 및 운영, 이탈률 감소 기대\n- 예측 모델을 활용하여 지속적 고위험 고객 모니터링 및 리스크 관리 강화\n- 장기적 고객의 충성도 및 수익성 증대 효과 기대\n```\n\n### 해결 방안\n```\n1. EDA를 통하여 이탈/기존(잔존) 고객의 특성을 비교 및 주요 영향 변수를 탐색\n2. 고객 데이터를 기반으로 이탈 예측 모델(Machine Learning) 구축\n3. 주요 변수 기반으로 유지 고객을 여러 클러스터로 세분화하고 이탈 고객과 유사한 ‘Target’ 클러스터를 도출\n4. ‘Target’ 클러스터와 이탈률이 낮은 ‘Low’ 클러스터를 비교 분석하여 이탈 위험 요인 및 행동 특성 파악\n5. 분석 결과를 바탕으로 ‘Target’ 고객군에 맞춤형 유지 및 마케팅 전략을 수립하여 이탈 방지 강화\n```\n\n### 성과 측정\n```\n모델 성능 파악, 세그먼트 별 맞춤 전략 A/B Test, 주요 KPI(이탈률 감소, 거래 활성화, 고객 참여도 등)를 중심으로 성과 측정\n```\n\n### 운영 \n\n```\n- 정기적으로 고객 데이터를 업데이트하고, 모델 재 학습(분기별) 및 클러스터링(월별)을 통해 최신 타켓 고객군 선별\n- 분석 결과를 고객관리 시스템과 연계, 마케팅 및 CS부서 등에 제공\n- 고위험 고객 리스트를 월/주 단위로 부서에 전달\n- 성과 분석 결과에 따라 유동적인 대응전략 설계하고 지속 개선\n```","metadata":{}},{"cell_type":"markdown","source":"### 데이터셋 개요\n\n|Column|Description|\n|:---|:---|\n|CLIENTNUM|고객별 고유 식별 번호. (integer)|\n|Attrition_Flag|고객 이탈 여부를 나타내는 지표. (Boolean)|\n|Customer_Age|고객의 나이. (Integer)|\n|Gender|고객의 성별. (String)|\n|Dependent_count|고객이 경제적으로 부양하는 가족의 수. (Integer)|\n|Education_Level|고객의 교육 수준. (String)|\n|Marital_Status|고객의 결혼 상태. (String)|\n|Income_Category|고객의 연간 소득 범위를 나타내는 카테고리.. (String)|\n|Card_Category|고객이 소지한 신용카드의 유형(예: 일반, 골드, 플래티넘). (String)|\n|Months_on_book|고객 계정 유지 기간. (integer)|\n|Total_Relationship_Count|고객이 신용카드 회사와 맺고 있는 총 상품 또는 서비스 수. (integer)|\n|Months_Inactive_12_mon|지난 12개월 동안 고객 계정의 비활성화된 월 수 (integer)|\n|Contacts_Count_12_mon|최근 12개월간 고객과 회사간 연락 횟수 (integer)|\n|Credit_Limit|고객의 신용한도. (integer)|\n|Total_Revolving_Bal|결제 기한이 지났음에도 남아있는 채무의 총액. (integer)|\n|Avg_Open_To_Buy|평균 구매가능 잔여한도. (integer)|\n|Total_Amt_Chng_Q4_Q1|1분기 대비 4분기 총 금액 변동비율. (float)|\n|Total_Trans_Amt|총 거래 금액. (integer)|\n|Total_Trans_Ct|총 거래 횟수. (integer)|\n|Total_Ct_Chng_Q4_Q1|1분기 대비 4분기 총 거래 횟수 변동비율. (float)|\n|Avg_Utilization_Ratio|신용 한도 대비 사용한 한도의 비율, Total_Revolving_Bal / Credit_Limit (float)|\n\n<br>\n\n---","metadata":{}},{"cell_type":"markdown","source":"## **Import**","metadata":{}},{"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# 기본 라이브러리\nimport pandas as pd\nimport numpy as np\nimport math\n\n# 시각화 라이브러리\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom matplotlib.ticker import PercentFormatter\nimport platform\n%matplotlib inline\n\nsns.set_style(\"whitegrid\")\n\nplt.rcParams['font.family'] = 'NanumGothic'\nplt.rcParams['axes.unicode_minus'] = False\n\n# 모델링 라이브러리\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.metrics import (roc_auc_score, precision_score, recall_score, accuracy_score, f1_score,\nconfusion_matrix, ConfusionMatrixDisplay ,classification_report, make_scorer)\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\nimport lightgbm as lgb\nfrom lightgbm import LGBMClassifier\nfrom lightgbm import early_stopping, log_evaluation\n# !pip install optuna\n# !pip install catboost\nimport optuna\noptuna.logging.set_verbosity(optuna.logging.WARNING)\nfrom optuna.samplers import TPESampler\nfrom catboost import CatBoostClassifier, Pool\n\nimport shap\n\n# 클러스터링 라이브러리\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score\nfrom sklearn.decomposition import PCA\nfrom sklearn.manifold import TSNE\n\n# 통계 검증 라이브러리\nfrom scipy.stats import kruskal\n\n# 추가 라이브러리\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T07:00:51.234603Z","iopub.execute_input":"2025-08-10T07:00:51.234865Z","iopub.status.idle":"2025-08-10T07:01:07.993098Z","shell.execute_reply.started":"2025-08-10T07:00:51.234838Z","shell.execute_reply":"2025-08-10T07:01:07.992397Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/zero-base-project-creditcard-analysis/BankChurners_.csv')\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T07:01:07.994438Z","iopub.execute_input":"2025-08-10T07:01:07.99504Z","iopub.status.idle":"2025-08-10T07:01:08.09673Z","shell.execute_reply.started":"2025-08-10T07:01:07.995015Z","shell.execute_reply":"2025-08-10T07:01:08.096015Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# ✔ Process01 - EDA\n\n- Data 전처리\n- Data 분리\n- 타겟 변수(이탈) 분포 확인\n- Numeric Data 분석 (분포 확인)\n- Categoric Data 분석 (분포 확인)\n\n\n---","metadata":{}},{"cell_type":"markdown","source":"## 🔹 Data 전처리\n- Data Shape -> 10,127개의 row, 21개의 column\n- Data Type -> 이상 없음\n- Null값 -> 이상 없음\n- Outlier 값 -> 이상 없음\n","metadata":{}},{"cell_type":"code","source":"# Data Shape -> 10,127개의 row, 21개의 column\ndf.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T07:01:08.097477Z","iopub.execute_input":"2025-08-10T07:01:08.097749Z","iopub.status.idle":"2025-08-10T07:01:08.102551Z","shell.execute_reply.started":"2025-08-10T07:01:08.09773Z","shell.execute_reply":"2025-08-10T07:01:08.101893Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Data Type & Unique & Null -> 이상 없음\nsummary = pd.DataFrame({\n    'Type':df.dtypes,\n    'Unique':df.nunique(),\n    'Null':df.isnull().sum(),\n    'Null Ratio':round((df.isnull().sum() / len(df)) * 100, 2)\n})\n\nsummary","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T07:01:08.103227Z","iopub.execute_input":"2025-08-10T07:01:08.103526Z","iopub.status.idle":"2025-08-10T07:01:08.147582Z","shell.execute_reply.started":"2025-08-10T07:01:08.103499Z","shell.execute_reply":"2025-08-10T07:01:08.146787Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Outlier 확인 -> 이상 없음\ndf.describe()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T07:01:08.149699Z","iopub.execute_input":"2025-08-10T07:01:08.149944Z","iopub.status.idle":"2025-08-10T07:01:08.195544Z","shell.execute_reply.started":"2025-08-10T07:01:08.149925Z","shell.execute_reply":"2025-08-10T07:01:08.19475Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 🔹 Data 분리\n\n- Numeric Data(수치형 변수)\n    - `CLIENTNUM`은 고객의 고유 번호로 분석에 필요하지 않아 제거.\n- Categoric Data(범주형 변수)\n    - `Attrition_Flag`는 타겟 변수이므로 분석에 독립적으로 사용할 예정. -> 추후 파생 변수 생성 후 제거\n\n---","metadata":{}},{"cell_type":"code","source":"# Numeric Data와 Categoric Data로 분리\nnumeric_lst = []\ncategoric_lst = []\n\nfor i in df.columns:\n    if df[i].dtypes == 'O':\n        categoric_lst.append(i)\n    else:\n        numeric_lst.append(i)\n\nprint(\"Numeric: \", numeric_lst, '\\n')\nprint(\"Categoric \", categoric_lst)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T07:01:08.196285Z","iopub.execute_input":"2025-08-10T07:01:08.196544Z","iopub.status.idle":"2025-08-10T07:01:08.202518Z","shell.execute_reply.started":"2025-08-10T07:01:08.196524Z","shell.execute_reply":"2025-08-10T07:01:08.20167Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# CLIENTNUM은 고객의 고유 번호이므로 분석에서 제외 (타겟 변수 Attrition_Flag는 추후 제외 예정)\nnumeric_lst.remove('CLIENTNUM')\nprint(numeric_lst)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T07:01:08.203372Z","iopub.execute_input":"2025-08-10T07:01:08.203615Z","iopub.status.idle":"2025-08-10T07:01:08.220809Z","shell.execute_reply.started":"2025-08-10T07:01:08.203595Z","shell.execute_reply":"2025-08-10T07:01:08.219963Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 🔹 타겟 변수(Attrition_Flag) 분포 확인\n\n- Attrition_Flag\n    - Existing Customer: 8,500명(83.9%)\n    - Attrited Customer: 1,627명(16.1%)\n\n<br>\n\n- is_churned\n    - 추후 분포 확인 및 분석의 용이성을 위해 Attrition_Flag에서 파생 변수로 is_churned 생성\n        - 0: 유지 고객 / 1: 이탈 고객\n\n---","metadata":{}},{"cell_type":"markdown","source":"### **🔸 Attrition_Flag 분포확인** <br>","metadata":{}},{"cell_type":"code","source":"# 타겟 변수 분포 확인 -> Attrited Customer(이탈 고객)의 비율이 약 16%\nprint(df['Attrition_Flag'].value_counts(), '\\n')\nprint(round(df['Attrition_Flag'].value_counts(normalize=True)*100,2))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T07:01:08.221635Z","iopub.execute_input":"2025-08-10T07:01:08.221867Z","iopub.status.idle":"2025-08-10T07:01:08.241157Z","shell.execute_reply.started":"2025-08-10T07:01:08.221848Z","shell.execute_reply":"2025-08-10T07:01:08.240174Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_Target = df['Attrition_Flag'].value_counts()\ntotal = df_Target.sum()\nplt.figure(figsize=(10,6))\nsns.barplot(x=df_Target.index, y=df_Target.values)\nplt.xlabel(\"Attrition_Flag\")\nplt.ylabel(\"Count\")\nplt.legend(loc='upper left')\n\nfor i, j in enumerate(df_Target.values):\n    percent = j / total * 100\n    plt.text(i, j+100, f\"{j:,} ({percent:.1f}%)\", ha='center', fontweight='bold')\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T07:01:08.242175Z","iopub.execute_input":"2025-08-10T07:01:08.24302Z","iopub.status.idle":"2025-08-10T07:01:08.50981Z","shell.execute_reply.started":"2025-08-10T07:01:08.242997Z","shell.execute_reply":"2025-08-10T07:01:08.508984Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 이탈 컬럼 생성(is_churn: 고객의 유지/이탈 여부 -> 0: 유지 고객 / 1: 이탈 고객)\ndf['is_churn'] = df['Attrition_Flag'].apply(lambda x: 1 if x == 'Attrited Customer' else 0)\ndf.head(1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T07:01:08.510686Z","iopub.execute_input":"2025-08-10T07:01:08.511013Z","iopub.status.idle":"2025-08-10T07:01:08.532314Z","shell.execute_reply.started":"2025-08-10T07:01:08.510989Z","shell.execute_reply":"2025-08-10T07:01:08.531385Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 이탈 컬럼 boolean 형으로 재생성했으므로, 기존 Attrition_Flag는 범주형 변수에서 제거\ncategoric_lst.remove('Attrition_Flag')\nprint(categoric_lst)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T07:01:08.533405Z","iopub.execute_input":"2025-08-10T07:01:08.534182Z","iopub.status.idle":"2025-08-10T07:01:08.54833Z","shell.execute_reply.started":"2025-08-10T07:01:08.534144Z","shell.execute_reply":"2025-08-10T07:01:08.547529Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 🔹 **Numeric Data (수치형 데이터) 분석**\n\n### **🔸 Customer_Age(고객의 나이)**\n\n- KDE Plot\n    - 유지 고객(파랑)의 분포는 약 45세에서 가장 높고 좁음. 또한 약 25세부터 분포가 가파르게 올라감. 오른쪽으로 꼬리가 있음. 전체적인 분포는 높고 좁음. \n    - 이탈 고객(주황)의 분포는 마찬가지로 약 45세에서 가장 높고 좁음. 그러나 약 35세부터 분포가 가파르게 올라감. 왼쪽으로 약간의 꼬리가 있음. 전체적인 분포는 기존 고객보다 더 낮고 좌우로 퍼짐.\n- Box Plot\n    - 중앙값: 유지 고객(파랑)의 중앙값은 46세. 이탈 고객(주황)의 중앙값은 47세.\n    - 범위(IQR): 범위는 둘 모두 비슷.\n    - 이상치: 유지 고객(파랑)에는 이탈 고객(주황)보다 더 높은 고령층의 이상치들이 약간 보임. \n- 구간 별 평균 이탈률\n    - 39-44세, 53-73세 구간의 평균 이탈률이 17.3%로 가장 높음.\n    - 26-40세 구간의 평균 이탈률이 13.7%로 가장 낮음.\n\n|연령 구간|이탈률|\n|:---|:---|\n|26-39세|13.7%|\n|39-44세|17.3%|\n|44-48세|16.7%|\n|48-53세|15.4%|\n|53-73세|17.3%|\n\n\n#### **📌 Insight:** \n- 26-39세는 유지 고객층은 급증하는 반면, 이탈 고객층은 아직 큰 증가를 보이지 않고 있음.\n    - 해당 구간은 현재 상황만으로는 충성도가 높은 고객층으로 분류할 수 있음.\n    - 그러나, 변수들간의 상관관계성을 고려해 보아야 할 것으로 보임. 예를 들어, 나이와 가입 기간이 양의 상관성을 보인다면 이탈률이 나이가 아닌 가입 기간에 따라 변하는 것일 가능성이 있음.\n- 26-39세에서 39-44세의 구간에서는 이탈률이 급증하는 모습을 보임. (약 3.6%p 증가)\n    - 앞선 26-39세의 이탈률이 가장 낮다는 것과 함께 2,30대의 이탈률이 낮은 이유를 추가적으로 분석할 필요가 있음.\n- 따라서, 이탈률은 연령이 증가함에 따라 전반적으로 상승하는 경향을 보이지만, 중간 구간(44-53세)에서는 오히려 감소함.\n- 이는 다른 변수와의 상호작용에 의한 것일 가능성이 있음. 또한 40-44세 구간에서 이탈률이 급증하는 현상은 명확한 타겟팅 포인트가 될 수 있음.\n\n<br>\n\n### **🔸 Dependent_count(고객이 경제적으로 부양하는 가족의 수)**\n\n - KDE Plot\n    - 유지 고객(파랑)의 분포는 1명, 2명, 3명 등 개별 값 중심으로 뾰족함. 특히 2명에서 가장 높음. 양쪽 모두 꼬리가 길지 않음.\n    - 이탈 고객(주황)의 분포는 전체적으로 낮은 밀도를 가지며, 완만함. 2~3명 사이가 상대적으로 높으며, 특히 1명 이하, 5명 이상은 낮음. 양쪽으로 약간의 꼬리가 보임.\n- Box Plot\n    - 중앙값: 유지 고객과 이탈 고객 모두 중앙값은 2로 동일함.\n    - 범위: 유지 고객은 1-3 사이. 이탈 고객은 2-3 사이.\n    - 이상치: 이탈 고객에 더 많은 이상치가 확인됨.\n- 구간 별 평균 이탈률\n    - 2-3명일 때 평균 이탈률 17.6%로 가장 높음.\n    - 0-1명일 때 평균 이탈률 14.7%로 가장 낮음.\n\n|부양 가족 수 구간|이탈률|\n|:---|:---|\n|0-1명|14.7%|\n|1-2명|15.7%|\n|2-3명|17.6%|\n|3-5명|16.2%|\n\n\n<br>\n\n#### **📌 Insight:** \n- 부양 가족 수가 2-3명일 때 이탈률이 가장 높음(17.6%)\n    - 가족수가 많을수록 이탈률이 증가하는 경향이 있으나, 3명 이상일 경우 다시 이탈률이 줄어드는 모습을 보임.\n    - 단순히 부양 가족수가 많기 때문에 이탈률이 증가한다고 보기에는 어렵고, 2-3명인 그룹을 타겟팅 포인트로 볼 가능성이 있음.\n- 부양 가족 수가 0-1명일 때 이탈률이 가장 낮음(14.7%)\n    - 가족 부담이 적은 고객일수록 서비스 유지 확률이 높을 가능성이 있음.\n- Boxplot 기준 기존 고객은 더 넓은 분포를 보이며, 이상치가 더 많음.\n    - 유지 고객은 이탈 고객보다 다양한 가족 상황을 포괄하고 있으며, 이는 유지 고객에 대한 맞춤 전략 수립의 여지를 시사함.\n- 따라서, 이탈률은 부양 가족 수가 증가함에 따라 증가하는 경향을 보이나, 중간 구간(2-3명)에서 최고치를 기록하고, 다시 줄어듬(3-5명). 또한 0-1명의 가족을 둔 고객은 충성도가 높은 핵심군으로 판단할 수 있음. 그러나, 다른 변수와의 상호작용에 의한 것일 가능성이 있기 때문에 추가 분석이 필요함. 부양 가족 수 2-3명인 고객이 이탈률이 가장 높은 것은 명확한 타겟팅 포인트가 될 수 있음.\n\n<br>\n\n### **🔸 Months_on_book(고객 계정 유지 기간)**\n\n- KDE Plot\n    - 유지 고객(파랑)의 분포는 약 36개월 부근에서 가장 높고 뾰족함. 전체적으로 정규 분포에 가까움.\n    - 이탈 고객(주황)의 분포는 밀도가 훨씬 낮고, 완만함. 약 36개월 근처에서 가장 높고 뾰족함.\n- Box Plot\n    - 중앙값: 유지 고객과 이탈 고객 모두 36개월로 동일함.\n    - 범위: 유지 고객은 약 32-40개월까지 넓은 범위. 이탈 고객은 약 34-40개월까지 상대적으로 약간 좁은 범위. \n    - 이상치: 이탈 고객에 더 많은 이상치가 확인됨.\n- 구간 별 평균 이탈률\n    - 42-56개월에서 평균 이탈률 16.4%로 가장 높음.\n    - 13-30개월에서 평균 이탈률 15.3%로 가장 낮음.\n    - 시간이 지날수록 이탈률이 증가하는 경향을 보임.\n\n|계정 유지 기간 구간|이탈률|\n|:---|:---|\n|13-30개월|15.3%|\n|30-36개월|16.3%|\n|36-42개월|16.2%|\n|42-56개월|16.4%|\n\n<br>\n\n#### **📌 Insight:** \n- 고객의 가입 개월 수가 증가할수록 이탈률도 완만히 증가하는 경향이 있음.\n    - 30-36개월에 16.3%로 높은 이탈률을 보이나, 30-36개월에 가장 많은 인원수가 밀집되어 있음(4,045 / 그 외는 약 1,900-2,100).\n    - 증가하는 추세가 매우 완만함(1~2%p 이내).\n    - 가입 개월 수가 증가할수록 이탈률이 증가하기는 하나, 매우 완만하여 이탈에 큰 영향을 미친다고 보기는 어려움.\n- 30-36개월에 가장 많은 고객이 집중되어 있음.\n    - KDE Plot과 Boxplot에서 모두 36개월에 집중되어 있음.\n    - 이 시점에서의 이탈 관리는 중요할 것으로 보임.\n- 유지 고객의 분포는 넓고 다양하지만, 이탈 고객의 분포는 제한적이고 집중적임.\n    - 특정 기간 이후의 피로도나 혜택 감소 등의 영향을 고려해볼 수 있음.\n- 따라서, 고객 가입 개월 수의 증가에 따라 이탈률 역시 완만한 증가를 보이나, 큰 차이는 보이지 않음(1.1%p 이내). 각 구간 별로 차이가 크지 않기 때문에 이탈에 큰 영향을 미친다고 보기 어려움(다른 변수와의 상호작용에 대한 추가 분석 필요). 그러나, 30-36개월에 가장 많은 인원수가 밀집되어 있고, 해당 구간의 이탈률이 가장 높은 것은 명확한 타겟팅 포인트가 될 수 있음.\n\n<br>\n\n### **🔸 Total_Relationship_Count(고객이 신용카드 회사와 맺고 있는 총 상품 또는 서비스 수)**\n\n- KDE Plot\n    - 유지 고객(파랑)의 분포는 전반적으로 1개, 2개, 3개 등 범위에서 고르게 뾰족함. 특히 2-4에서 가장 높고 뾰족함.\n    - 이탈 고객(주황)의 분포는 전체적으로 낮은 밀도를 보임. 2-3에서 상대적으로 분포가 집중됨. 유지 고객보다 분포가 좁고 완만함.\n- Box Plot\n    - 중앙값: 유지 고객은 4. 이탈 고객은 3.\n    - 범위: 유지 고객은 3-5, 이탈 고객은 2-5.\n    - 이상치: 두 집단 모두 뚜렷한 이상치는 보이지 않음.\n- 구간 별 평균 이탈률\n    - 상품 가입 개수가 1-2개인 구간에서 평균 이탈률 26.9%로 가장 높음.\n    - 상품 가입 개수가 5-6개인 구간에서 평균 이탈률 10.5%로 가장 낮음.\n\n|상품 가입 개수 구간|이탈률|\n|:---|:---|\n|1-2개|26.9%|\n|2-3개|17.4%|\n|3-4개|11.8%|\n|4-5개|12.0%|\n|5-6개|10.5%|\n\n<br>\n\n#### **📌 Insight:** \n- 상품 가입 개수가 많아짐에 따라 이탈률이 줄어듬.\n    - 총 가입 개수가 적을수록 이탈률이 높고(26.9%), 많을수록 이탈률이 낮아지는(10.5%) 뚜렷한 패턴을 보임.\n- IQR의 범위, 중앙값이 이탈 고객이 더 좁고 낮음(중앙값 3, 범위 2-5).\n    - 이탈이 상품 가입 개수가 낮은 고객군에 더 집중되어 나타남.\n- 따라서 상품 가입 개수와 이탈률은 음의 상관관계에 있음. 패턴이 뚜렷하기 때문에 해당 변수는 단독적으로 이탈에 큰 영향을 미친다고 볼 수 있으며, 명확한 타겟팅 포인트가 될 수 있음.\n\n<br>\n\n### **🔸 Months_Inactive_12_mon(지난 12개월 동안 고객 계정의 비활성화된 월 수)**\n\n - KDE Plot\n    - 유지 고객(파랑)의 분포는 1개월, 2개월, 3개월 등에서 뾰족함. 특히 3개월 부근에서 가장 뾰족함. 4개월, 5개월, 6개월에서는 상대적으로 완만함.\n    - 이탈 고객(주황)의 분포는 마찬가지로 각 개월에서 뾰족한 모습을 보이나, 전체적으로 완만함. 특히 2개월과 3개월 부근에서 상대적으로 뾰족하고, 5개월과 6개월에서 상대적으로 완만함.\n- Box Plot\n    - 중앙값: 유지 고객은 2. 이탈 고객은 3.\n    - 범위: 유지 고객은 1-3개월. 이탈 고객은 2-3개월.\n    - 이상치: 유지 고객은 이상치가 발견되지 않으나, 이탈 고객은 이상치가 다소 보임.\n- 구간 별 평균 이탈률\n    - 계정 비활성화 월 수가 3-6개월일 때 24.6%로 가장 높음.\n    - 계정 비활성화 월 수가 0-1개월일 때 5.1%로 가장 낮음.\n\n|계정 비활성화 월 수 구간|이탈률|\n|:---|:---|\n|0-1개월|5.1%|\n|1-2개월|15.4%|\n|2-3개월|21.5%|\n|3-6개월|24.6%|\n\n<br>\n\n#### **📌 Insight:** \n- 계정 비활성화 기간이 낮을수록 이탈률 역시 낮음.\n    - 비활성화 기간이 0-1개월일 때 이탈률이 가장 낮고, 비활성화 기간이 길어질수록 이탈률 역시 높아짐.\n    - 3-6개월의 고객군에 가장 적은 인원수(737)가 있지만, 이탈률이 가장 높음.\n- 유지 고객의 비활동 기간과 이탈 고객의 비활동 기간의 중앙값과 범위가 다름.\n    - 위의 인사이트와 마찬가지로, 이탈 고객의 비활성화 기간이 더 높음.\n- 따라서 비활성화 기간과 이탈률은 명확한 양의 상관관계를 가짐. 패턴이 뚜렷하기 때문에 해당 변수는 단독적으로 이탈에 큰 영향을 미친다고 볼 수 있으며, 명확한 타겟팅 포인트가 될 수 있음.\n\n<br>\n\n### **🔸 Contacts_Count_12_mon(최근 12개월간 고객과 회사간 연락 횟수)**\n\n- KDE Plot\n    - 유지 고객(파랑)의 분포는 전체적으로 1회, 2회, 3회 등에서 뾰족함. 특히 2회와 3회에서 가장 높고 뾰족한 모습을 보임. 5회는 가장 낮은 모습을 보이고, 6회는 보이지 않음.\n    - 이탈 고객(주황)의 분포는 마찬가지로 1회, 2회, 3회 등에서 뾰족함. 유지 고객에 비해 완만하고 뭉특한 모습을 보임. 5회에서 가장 낮고 완만한 모습을 보이고, 0회는 거의 꼬리만 보임.\n- Box Plot\n    - 중앙값: 유지 고객의 중앙값은 2회. 이탈 고객의 중앙값은 3회.\n    - 범위: 유지 고객의 범위는 2-3회. 이탈 고객의 범위는 2-4회.\n    - 이상치: 유지 고객은 0회, 5회에 이상치가 존재하고, 이탈 고객은 이상치가 존재하지 않음.\n- 구간 별 평균 이탈률\n    - 3-6회 구간의 평균 이탈률이 26.4%로 가장 높음.\n    - 0-2회 구간의 평균 이탈률이 10.1%로 가장 낮음.\n\n|고객 센터 연락 횟수 구간|이탈률|\n|:---|:---|\n|0-2회|10.1%|\n|2-3회|20.1%|\n|3-6회|26.4%|\n\n<br>\n\n#### **📌 Insight:** \n- 연락 빈도가 높아질수록 이탈률 또한 높아짐(10.1% -> 26.4%).\n    - 고객 센터에 자주 연락한 사람일수록 이탈률이 높음.\n    - 선형적인 관계를 보이는 명백한 양의 상관관계\n- 중앙값과 IQR 범위에서도 이탈 고객이 더 높은 연락 빈도를 보임.\n    - 이탈 고객의 중앙값(3)이 유지 고객의 중앙값(2)보다 높음.\n    - 이탈 고객의 IQR(2-4회)이 유지 고객의 IQR(2-3회)보다 넓고 높음.\n- 따라서 연락 빈도와 이탈률은 명백한 양의 상관관계로 해당 변수는 이탈에 영향을 미침. 그러나, 유지 고객 역시 연락횟수가 많은 경우(4회 이상)가 보이기 때문에, 단순히 연락을 많이 하는 것이 이탈을 의미하는 것은 아님. 연락 사유, 해결 여부 등과 같은 데이터를 통해 교차 분석이 필요함.\n\n<br>\n\n### **🔸 Credit_Limit(고객의 신용한도)**\n\n- KDE Plot\n    - 유지 고객(파랑)의 분포는 약 5,000달러 이하에서 가장 높고 뾰족한 모습을 보인 후, 이후로 완만하게 감소. 일부 고객은 약 35,000달러까지 존재함.\n    - 이탈 고객(주황)의 분포는 유지 고객보다 전반적으로 낮은 밀도를 보이며, 주로 5,000달러 이하에 집중되어 있음.\n- Box Plot\n    - 중앙값: 유지 고객은 4643.5달러. 이탈 고객은 4178달러.\n    - 범위: 유지 고객은 약 2,600달러-12,000달러. 이탈 고객은 약 2,400달러-10,000달러\n    - 이상치: 유지 고객과 이탈 고객 모두 약 35,000달러까지 이상치가 다수 존재함.\n- 구간 별 평균 이탈률\n    - 1438.3-2307.2달러 구간의 평균 이탈률이 22.6%로 가장 높음.\n    - 2307.2-3398.4달러 구간의 평균 이탈률이 10.9%로 가장 낮음.\n\n|신용한도 구간|이탈률|\n|:---|:---|\n|1438.3-2307.2달러|22.6%|\n|2307.2-3398.4달러|10.9%|\n|3398.4-6279.2달러|17.1%|\n|6279.2-13562.6달러|15.3%|\n|13562.6-34516달러|14.4%|\n\n<br>\n\n#### **📌 Insight:** \n- 낮은 한도(1438.3-2307.2달러)를 가진 고객의 이탈률이 매우 높음(22.6%).\n    - 다른 구간과 5.5-11.7%p만큼 차이남.\n    - 낮은 한도의 그룹이 극단적으로 이탈률이 높은 이유를 추가 분석할 필요가 있음.\n- 높은 한도를 가진 고객일수록 이탈률이 점차 낮아지는 경향을 보임(22.6->14.4%).\n    - 그러나, 2307.2-3398.4달러 구간에서 최저 이탈률(10.9%)를 보이고 3398.4-6279.2달러 구간에서 다시 이탈률이 증가(17.1%)하기 때문에 선형적인 관계라고 보기는 어려움.\n- 중앙값 차이가 존재함(유지고객: 4643.5달러 / 이탈고객: 4178달러).\n    - 이탈 고객이 전반적으로 낮은 한도를 가지는 경향이 보임.\n- 따라서 해당 변수는 이탈과 음의 상관관계를 가진다고 해석할 수 있음. 그러나, 선형적인 관계를 보이지는 않기 때문에 단독적으로 이탈에 큰 영향을 끼친다고 보기는 어려움. 또한 낮은 신용한도 구간에서의 이탈률이 극단적으로 높은 이유를 추가 분석할 필요가 있음(다른 변수와의 상호 관계성).\n\n<br>\n\n### **🔸 Total_Revolving_Bal(결제 기한이 지났음에도 남아있는 채무의 총액)**\n\n- KDE Plot\n    - 유지 고객(파랑)의 분포는 약 0-500달러에서 가장 높고 뾰족함. 500-1,000달러 사이의 분포는 급격히 하락 후 완만히 상승하는 모습을 보임. 약 1,500-2,000달러에서 다시 가장 높은 모습을 보임.\n    - 이탈 고객(주황)의 분포는 0 근처에서 가장 높은 모습을 보임. 유지 고객보다 밀도 자체가 전반적으로 낮고 완만함.\n- Box Plot\n    - 중앙값: 유지 고객은 1364 달러. 이탈 고객은 0달러.\n    - 범위: 유지 고객은 약 800-1700달러. 이탈 고객은 약 0-1300달러.\n    - 이상치: 두 고객군 모두 이상치는 보이지 않음.\n- 구간 별 평균 이탈률\n    - 0-1037.4달러 구간의 평균 이탈률이 28.9%로 가장 높음.\n    - 1037.4-1482달러 구간의 평균 이탈률이 4.4%로 가장 낮음.\n\n|채무 총액 구간|이탈률|\n|:---|:---|\n|0-1037.4달러|28.9%|\n|1037.4-1482달러|4.4%|\n|1482-1903달러|4.5%|\n|1903-2517달러|13.6%|\n\n<br>\n\n#### **📌 Insight:** \n- 중앙값 차이가 뚜렷함(유지고객: 1,364 / 이탈 고객: 0).\n    - 이탈 고객 대부분은 채무액이 없음.\n- 채무 총액이 가장 낮은 구간(0-1037.4달러)에서 가장 높은 이탈률(28.9%)을 보임.\n    - 이탈 고객의 하나의 패턴으로 파악할 수 있음.\n    - 채무 총액이 1037.4-1482달러인 구간부터는 이탈률이 급격히 감소함(24.5%p 감소).\n- 따라서 해당 변수는 단독적으로 이탈에 영향을 끼친다고 볼 수 있음. 비록 가장 높은 채무 총액 구간(1903-2517달러)에서 이탈률이 다시 높아지는 모습(13.6%)을 보이지만, 이탈 고객의 중앙값(0)과 범위(0-1,300)를 보았을 때, 잔액이 1,000 달러 이하의 고객들이 주로 이탈한다는 것을 알 수 있음. 잔액이 1,000 달러 이하인 고객군의 다른 특성을 추가 분석할 필요가 있음.\n\n<br>\n\n### **🔸 Avg_Open_To_Buy(평균 구매 가능 잔여 한도)**\n\n- KDE Plot\n    - 유지 고객(파랑)의 분포는 0-10,000달러에서 밀도가 가장 높고 뾰족함. 이후 완만하게 감소하다 약 35,000달러에서 약간 높아지는 모습을 보임.\n    - 이탈 고객(주황)의 분포는 유지 고객보다 완만한 밀도를 보임. 마찬가지로 0-10,000달러에서 가장 높고 뾰족한 모습을 보이고, 약 35,000달러에서 미세하게 높아지는 모습을 보임.\n- Box Plot\n    - 중앙값: 유지 고객은 3469.5달러. 이탈 고객은 3488달러.\n    - 범위: 유지 고객은 약 2,000-10,000달러. 이탈 고객은 약 2,000-8,000달러.\n    - 이상치: 두 고객군 모두 약 35,000달러까지 이상치가 다수 존재함.\n- 구간 별 평균 이탈률\n    - 1026-2225달러 구간의 평균 이탈률이 21.8%로 가장 높음.\n    - 3-1026달러 구간의 평균 이탈률이 9%로 가장 낮음.\n\n|평균 잔여 한도 구간|이탈률|\n|:---|:---|\n|3-1026달러|9%|\n|1026-2225달러|21.8%|\n|2225-5195달러|18.2%|\n|5195-12419.8달러|16.6%|\n|12419.8-34516달러|14.8%|\n\n<br>\n\n#### **📌 Insight:** \n- 가장 높은 이탈률(21.8%)은 중간 정도의 잔여 한도 구간(1026-2225달러)에서 나타남.\n    - 가장 저액 구간(3-1026달러)의 이탈률은 오히려 낮음(9%).\n    - 단순히 잔여 한도가 적다고 이탈하는 것은 아님.\n- 잔여 한도가 높은 구간에서는 점차적으로 이탈률이 낮아지는 경햠을 보임.\n    - 1026-2225 달러 구간에서 가장 높은 이탈률(21.8%)을 기록한 후, 18.2% -> 16.6% -> 14.8%로 줄어듬.\n- 중앙값의 차이가 크지 않음(유지 고객: 3469.5 / 이탈 고객: 3488).\n    - 해당 변수는 이탈과의 상관관계가 크지 않음.\n- 따라서 해당 변수는 중앙값의 차이가 크지 않고, 구간 사이의 패턴이 명확하게 보이지 않기 때문에(중간 구간부터는 금액이 높아질수록 이탈률이 낮아지는 경향을 보이긴 하지만, 가장 저액인 구간에서의 이탈률이 가장 낮음) 이탈에 직접적으로 큰 영향을 끼친다고 보기는 어려움. 중간 금액대 구간의 이탈률이 높은 것에 대한 추가 분석이 필요함(해당 고객군의 패턴, 신용 한도 등).\n\n<br>\n\n### **🔸 Total_Amt_Chng_Q4_Q1(1분기 대비 4분기 총 금액 변동 비율)**\n\n- KDE Plot\n    - 유지 고객(파랑)의 분포는 약 0.8 부근에서 가장 높고 뾰족함. 이후 급격한 감소를 보임. 일부 고객은 2 이상에서도 분포되어 있음.\n    - 이탈 고객(주황)의 분포는 전반적으로 유지 고객보다 밀도가 낮고, 약 0.7 부근에서 가장 높고 뾰족함. 이후 상대적으로 완만한 감소를 보임. 2 이상에서의 분포는 없음.\n- Box Plot\n    - 중앙값: 유지 고객은 0.74. 이탈 고객은 0.7.\n    - 범위: 유지 고객은 약 0.7-0.8. 이탈 고객은 약 0.5-0.8.\n    - 이상치: 유지 고객은 약 3.5까지 이상치가 존재하고, 0.3 이하의 이상치도 존재함. 이탈 고객은 약 1.5까지 이상치가 존재하고, 0에서도 이상치가 존재함. 둘 모두 이상치가 다수 보이나, 유지 고객이 더 많은 이상치를 보임.\n- 구간 별 평균 이탈률\n    - 0-0.6 구간의 평균 이탈률이 27.2%로 가장 높음.\n    - 0.7-0.8 구간의 평균 이탈률이 12%로 가장 낮음.\n\n|금액 변동 비율 구간|이탈률|\n|:---|:---|\n|0-0.6|27.2%|\n|0.6-0.7|12.4%|\n|0.7-0.8|12%|\n|0.8-0.9|13.5%|\n|0.9-3.4|15.3%|\n\n<br>\n\n#### **📌 Insight:** \n- 이탈률이 가장 높은 구간은 0.0-0.6(27.2%).\n    - 가장 낮은 이탈률 구간과 15.2%p 차이가 남.\n    - 이 구간은 소비 금액이 크게 줄었거나 거의 변화가 없는 고객군으로 해석 가능함.\n- 변동 비율이 0.6 이상인 고객은 상대적으로 낮고 안정적인 이탈률을 보임(12~15% 수준).\n    - 뚜렷한 패턴 없이 완만함.\n- 중앙값 차이가 거의 나지 않음(유지 고객 0.74 / 이탈 고객 0.7).\n    - 해당 변수와 이탈 간의 상관관계가 크지 않음.\n- 따라서 해당 변수는 중앙값 차이가 크지 않고 뚜렷한 패턴이 없으므로 이탈과의 상관관계가 크지 않음. 그러나, 특정 구간(0-0.6)에서 이탈 가능성이 매우 높게 나오는 것은 타겟팅 포인트가 될 수 있음(추가 분석 필요). 또한 특정 구간과 다른 구간 간의 차이가 매우 크게 나므로 해당 지표가 이탈을 예측하는데 주요한 변수로 사용될 수 있음(파생 변수 생성 -> 소비 금액의 변동 비율이 높지 않은 구간과 그 외 구간으로 나누어서 분석해 볼 필요도 있음).\n\n<br>\n\n### **🔸 Total_Trans_Amt(총 거래 금액)**\n\n- KDE Plot\n    - 유지 고객(파랑)의 분포는 4,000 달러 전후에서 가장 밀도가 높음. 15,000 달러 전후로도 밀도가 높아지는 모습을 보임.\n    - 이탈 고객(주황)의 분포는 2,000-3,000달러에서 가장 밀도가 높고 뾰족한 모습을 보임. 유지 고객의 분포와는 다르게 15,000 달러에서의 밀도 상승은 없음.\n- Box Plot\n    - 중앙값: 유지 고객은 4100달러. 이탈 고객은 2329달러.\n    - 범위: 유지 고객은 약 2,500-4,900달러. 이탈 고객은 약 2,300-2,600달러.\n    - 이상치: 유지 고객은 17,500 달러 이상의 이상치들도 다수 보임. 이탈 고객은 약 11,500 달러까지의 이상치가 다수 보이고, 0달러에 가까운 이상치도 보임.\n- 구간 별 평균 이탈률\n    - 1914-3192.4달러 구간의 평균 이탈률이 43.9%로 가장 높음.\n    - 3192.4-4267달러 구간의 평균 이탈률이 0.8%로 가장 낮음.\n\n|총 거래 금액 구간|이탈률|\n|:---|:---|\n|510-1914달러|20.4%|\n|1914-3192.4달러|43.9%|\n|3192.4-4267달러|0.8%|\n|4267-4926달러|2.2%|\n|4926-18484달러|13%|\n\n<br>\n\n#### **📌 Insight:** \n- 중앙값의 차이가 뚜렷함(유지 고객 4100달러 / 이탈 고객 2329달러).\n    - 이탈 고객은 거래 금액 자체가 낮음.\n- 이탈률이 가장 높은 구간과 가장 낮은 구간의 차이가 극심함(43.1%p).\n    - 두 구간의 실제 인원수 차이도 크지 않음.\n    - 즉, 해당 구간에서 이탈률이 극심하게 높은 이유와 극심하게 낮은 이유를 추가 분석해야 할 필요가 있음.\n- 따라서 해당 변수는 비록 패턴이 뚜렷하게 드러나지는 않지만, 중앙값 차이가 크고 구간 별 차이가 크게 나타나므로 이탈에 직접적인 영향을 줄 가능성이 있음. 특히 이탈률이 가장 높은 구간과 가장 낮은 구간을 각각 추가 분석하여 해당 그룹들을 별로로 분석하고 관리하는 것이 전략적으로 큰 도움이 될 수 있음.\n\n<br>\n\n### **🔸 Total_Trans_Ct(총 거래 횟수)**\n\n- KDE Plot\n    - 유지 고객(파랑)의 분포는 약 80회 전후에서 가장 밀도가 높으며, 이후 완만히 감소. 분포가 전반적으로 넓고, 고거래 고객도 존재.\n    - 이탈 고객(주황)의 분포는 약 40-50회 사이에서 가장 밀도가 높음. 전반적으로 유지 고객보다 밀도가 낮고 분포가 좁음.\n- Box Plot\n    - 중앙값: 유지 고객 71회. 이탈 고객 43회.\n    - 범위: 유지 고객 약 58-82회. 이탈 고객 약 38-50회.\n    - 이상치: 유지 고객의 경우 약 140회까지 이상치가 다수 존재하며, 10 이하의 이상치도 존재. 이탈 고객의 경우 약 90회까지 이상치가 다수 존재하며, 10 이하의 이상치도 존재.\n- 구간 별 평균 이탈률\n    - 41-61회 구간의 평균 이탈률이 34.8%로 가장 높음.\n    - 83-139회 구간의 평균 이탈률이 1.1%로 가장 낮음.\n\n|총 거래 횟수 구간|이탈률|\n|:---|:---|\n|10-41회|32.7%|\n|41-61회|34.8%|\n|61-73회|6.6%|\n|73-83회|3.3%|\n|83-139회|1.1%|\n<br>\n\n#### **📌 Insight:** \n- 중앙값과 분포의 차이가 뚜렷함(유지 고객 중앙값: 71회 / 이탈 고객 중앙값: 43회).\n    - 이탈 고객의 중앙값이 유지 고객의 중앙값보다 낮고, 분포 역시 이탈 고객의 분포가 유지 고객의 분포보다 밀도가 낮고 분포가 좁으며, 가장 밀도가 높은 구간(40-50회) 역시 유지 고객의 가장 밀도가 높은 구간(약 80회 전후)보다 낮은 구간에 있음.\n    - 이는 이탈 고객이 총 거래 횟수가 낮은 경우가 많다는 것을 보여줌.\n- 41-61회 구간에서의 이탈률이 가장 높음(34.8%).\n    - 10-41회 구간에서의 이탈률 역시 높은 모습을 보임(32.7%).\n    - 61회 이상의 구간에서는 횟수가 높아질수록 이탈률이 점차적으로 낮아지는 경향을 보임(34.8->6.6->3.3->1.1%)\n- 따라서 해당 변수는 중앙값 차이와 분포 차이 모두 뚜렷하며, 60회 이전과 이후에서는 이탈률이 선형적으로 음의 상관관계를 가지는 패턴을 보이기 때문에 이탈에 단독적으로 영향을 미친다고 볼 수 있음. 60회를 기준으로 세그먼트를 분류하여 마케팅적 전략을 세울 수 있고, 이탈 위험 구간을 타겟팅할 수 있다는 점에서 명확한 타겟팅 포인트가 됨.\n\n<br>\n\n### **🔸 Total_Ct_Chng_Q4_Q1(1분기 대비 4분기 총 금액 변동 비율)**\n\n- KDE Plot\n    - 유지 고객(파랑)의 분포는 약 0.8 부근에서 가장 밀도가 높으며, 이후 완만하게 감소. 1 이상의 비율도 다수 보이며, 우측으로 긴 꼬리를 가짐.\n    - 이탈 고객(주황)의 분포는 약 0.4 부근에서 가장 밀도가 높으며, 이후 완만하게 감소. 1이상의 비율이 많지 않으며, 좌측으로 치우쳐져 있음.\n- Box Plot\n    - 중앙값: 유지 고객 0.72. 이탈 고객 0.53.\n    - 범위: 유지 고객 약 0.6-0.8. 이탈 고객 약 0.3-0.7.\n    - 이상치: 유지 고객은 3.5 이상의 이상치까지 다수 존재하며, 0에 가까운 이상치들도 다수 존재함. 이탈 고객은 2.5까지의 이상치가 다수 존재함.\n- 구간 별 평균 이탈률\n    - 0-0.5 구간의 평균 이탈률이 42.1%로 가장 높음.\n    - 0.9-3.7 구간의 평균 이탈률이 7.1%로 가장 낮음.\n\n|거래 횟수 변동 구간|이탈률|\n|:---|:---|\n|0-0.5|42.1%|\n|0.5-0.7|15.3%|\n|0.7-0.7|7.7%|\n|0.7-0.9|8%|\n|0.9-3.7|7.1%|\n\n<br>\n\n#### **📌 Insight:** \n- 0-0.5 구간의 이탈률(42.1%)은 압도적으로 높음.\n    - 해당 구간은 거래 횟수가 급감했거나 변화가 거의 없는 고객층.\n    - 앞선 총 거래 변동 비율과 마찬가지로 변동 비율이 낮은 고객층이 높은 이탈률을 보임.\n    - 반면, 거래 변화율이 높은 고객층(0.7 이상)은 낮은 이탈률을 보임(7-8% 수준).\n- 중앙값과 분포 차이가 뚜렷함(유지 고객 중앙값: 0.72 / 이탈 고객 중앙값: 0.53).\n    - 이탈 고객의 중앙값이 유지 고객의 중앙값보다 낮고, 분포 역시 이탈 고객의 분포가 유지 고객의 분포보다 낮은 구간에서 밀도가 높은 모습을 보임.\n    - 이는 이탈 고객의 거래 횟수 변동 비율이 유지 고객의 거래 횟수 변동 비율보다 전체적으로 낮다는 것을 보여줌.\n- 따라서 해당 변수는 선형적이진 않지만 높아질수록 이탈률이 낮아진다는 패턴이 존재하고, 중앙값과 분포의 차이가 뚜렷하며, 높은 이탈률과 낮은 이탈률 간 차이가 뚜렷하므로 단독적으로 이탈에 영향을 미칠 가능성이 있음. 그러나, 4사분기와 1사분기의 시계열성과 외부 요인들을 염두에 두어야 함. 특별히 변동 비율이 0에 가까운 사용자들의 이탈률이 매우 크게 나타나는 것은 명확한 타겟팅 포인트가 될 수 있으며, 추가 분석이 필요함.\n\n<br>\n\n### **🔸 Avg_Utilization_Ratio(신용 한도 대비 사용한 한도의 비율)**\n\n- KDE Plot\n    - 유지 고객(파랑)의 분포는 0.1-0.3에서 가장 높은 밀도를 보이며, 이후 완만한 분포를 보임. 0.5 이상의 높은 사용 비율을 가진 고객도 일부 존재.\n    - 이탈 고객(주황)의 분포는 0-0.1 구간에서 밀도가 집중되어 있으며, 전체적으로 좌측으로 치우친 분포를 보임. 0에 가까운 비율을 가진 고객 비중이 확연히 높음.\n- Box Plot\n    - 중앙값: 유지 고객 0.21. 이탈 고객 0.\n    - 범위: 유지 고객 약 0.08-0.53. 이탈 고객 약 0-0.22.\n    - 이상치: 유지 고객은 이상치가 보이지 않음. 이탈 고객은 1.0 이상까지 이상치가 다수 존재함.\n- 구간 별 평균 이탈률\n    - 0-0.1 구간의 평균 이탈률이 26.4%로 가장 높음.\n    - 0.3-0.6 구간의 평균 이탈률이 8.5%로 가장 낮음.\n\n|신용한도 대비 사용한 한도의 비율 구간|이탈률|\n|:---|:---|\n|0-0.1|26.4%|\n|0.1-0.3|9.4%|\n|0.3-0.6|8.5%|\n|0.6-1.0|9.6%|\n\n\n<br>\n    \n#### **📌 Insight:** \n- 0-0.1 구간에서의 이탈률이 가장 높음(26.4%).\n    - 이탈 고객일수록 신용카드를 거의 사용하지 않음.\n- 0.1 이상의 구간에서는 이탈률이 평탄함(8-9% 수준).\n    - 유지 고객은 신용한도를 일정 수준 이상(비율 0.1) 사용하는 경향을 보임.\n- 중앙값과 분포의 차이가 뚜렷함(유지 고객 중앙값: 0.21 / 이탈 고객 중앙값: 0).\n    - 이탈 고객의 중앙값이 유지 고객의 중앙값보다 낮고, 분포 역시 이탈 고객의 분포는 유지 고객보다 낮은 구간에서의 밀도를 보여주고, 0에 가까운 비율을 가진 고객 비중이 높은 모습을 보여줌.\n    - 이는 이탈 고객의 신용한도 대비 사용한 한도의 비율이 유지 고객보다 낮고 실제 비율 자체도 낮음을 보여줌.\n- 따라서 해당 변수는 뚜렷한 패턴은 없지만, 중앙값과 분포의 차이가 뚜렷하고, 구간 별 가장 높은 이탈률과 그 외의 이탈률의 차이가 크므로(17.8%p), 단독적으로 이탈에 영향을 미칠 가능성이 있음. 그러나, 사용하지 않고 유지되는 고객들도 있기에, 성급하게 해당 변수가 낮다고 이탈 할 것이라 단정지을 수는 없음. 0.1 이하에서의 이탈률이 가장 높고 그 외의 구간에서의 이탈률이 큰 변화없다는 점을 통해 마케팅 전략, 예측 타겟팅 등으로 활용할 수 있기에 해당 변수는 타겟팅 포인트가 될 수 있음.\n\n<br>\n\n","metadata":{}},{"cell_type":"code","source":"df[numeric_lst].head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T07:01:08.549117Z","iopub.execute_input":"2025-08-10T07:01:08.549393Z","iopub.status.idle":"2025-08-10T07:01:08.574489Z","shell.execute_reply.started":"2025-08-10T07:01:08.549366Z","shell.execute_reply":"2025-08-10T07:01:08.573745Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 수치형 변수들 분포 확인\nfor i in numeric_lst:\n    print(f\"\\n 변수: {i}\")\n    plt.figure(figsize=(10,6))\n\n    # KDE Plot\n    plt.subplot(1,3,1)\n    sns.kdeplot(data=df, x=i, hue='Attrition_Flag', fill=True)\n    plt.title(f\"{i} - KDE Plot\")\n\n    # Box Plot\n    plt.subplot(1,3,2)\n    ax = sns.boxplot(x='is_churn', y=i, data=df)\n    plt.title(f\"{i} - Boxplot\")\n    medians = df.groupby('is_churn')[i].median()\n    for idx, median in enumerate(medians):\n        ax.text(idx, median + 0.2, f'{median:.2f}', ha='center', color='black', fontsize=10, fontweight='bold')\n\n    # 구간 별 이탈률\n    raw_gp = pd.qcut(df[i], q=5, duplicates='drop')\n    labels = [f\"{round(b.left, 1)} - {round(b.right, 1)}\" for b in raw_gp.cat.categories]\n    df[f\"{i}_gp\"] = pd.qcut(df[i], q=5, duplicates='drop', labels=labels)\n    churn_by_gp = df.groupby(f'{i}_gp')['is_churn'].mean().reset_index()\n\n    plt.subplot(1,3,3)\n    sns.barplot(x=f'{i}_gp', y='is_churn', data=churn_by_gp)\n    plt.title(f\"{i} - Churn Rate by Bins\")\n    plt.ylabel(\"Churn Rate (%)\")\n    plt.xticks(rotation=45)\n    plt.gca().yaxis.set_major_formatter(PercentFormatter(1.0))\n    \n    plt.tight_layout()\n    plt.show()\n\n    # 잔존/이탈 고객 비율(*100%) & 인원수(명)\n    print(f\"{i}_gp\")\n    display(round(df.groupby(f\"{i}_gp\")['is_churn'].mean().reset_index(),3))\n    display(df.groupby(f\"{i}_gp\")['is_churn'].value_counts().reset_index())\n    print('\\n')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T07:01:08.575531Z","iopub.execute_input":"2025-08-10T07:01:08.576213Z","iopub.status.idle":"2025-08-10T07:01:19.862563Z","shell.execute_reply.started":"2025-08-10T07:01:08.576184Z","shell.execute_reply":"2025-08-10T07:01:19.8618Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 🔹 Categoric Data (범주형 데이터) 분석\n\n### **🔸 Gender(고객의 성별)**\n\n- 고객 수 분포\n    - 여성(F): 5,358명\n    - 남성(M): 4,769명\n    - 전체적으로 성별 고객 수는 거의 비슷하며, 여성 고객 수가 약간 더 많음.\n- Gender 별 이탈률\n    - 여성(F): 약 17.4%\n    - 남성(M): 약 14.6%\n    - 이탈률은 여성 고객이 남성 고객보다 약 2.8%p 높음.\n    #### **📌 Insight:** \n    - 여성 고객의 이탈률이 남성보다 다소 높음(약 2.8%p).\n        - 전체 고객 수가 유사하고 이탈률 역시 차이가 있으므로, 여성 고객층을 타겟팅한 이탈 방지 전략을 고려해 볼 수 있음.\n    - 고객수가 거의 비슷하고 이탈률은 다소 차이가 있기 때문에 해당 변수가 이탈에 무의미한 것은 아니나, 차이가 크지 않기 때문에 단독으로 이탈에 큰 영향을 끼친다고 볼 수는 없음.\n\n<br>\n\n### **🔸 Education_Level(고객의 교육 수준)**\n\n- 고객 수 분포\n    - College: 1,013명\n    - Doctorate: 451명\n    - Graduate: 3,128명\n    - High School: 2,013명\n    - Post-Graduate: 516명\n    - Uneducated: 1,487명\n    - Unknown: 1,519명\n- Education_Level 별 이탈률\n    - College: 15.2%\n    - Doctorate: 21.1%\n    - Graduate: 15.6%\n    - High School: 15.2%\n    - Post-Graduate: 17.8%\n    - Uneducated: 15.9%\n    - Unknown: 16.9%\n    #### **📌 Insight:** \n    - Doctorate의 이탈률이 가장 높음(21.1%).\n        - 이탈률에 차이가 있지만, Doctorate의 고객 수는 451명으로 가장 낮음.\n        - 소수의 고객밖에 없기 때문에, 정보에 신뢰성이 떨어짐.\n    - 대부분의 교육 수준은 15-18% 이탈률 범위로 비교적 유사함.\n    - Post-Graduate 고객군도 상대적으로 높은 이탈률을 가짐(17.8%).\n        - 그러나 이 역시 Post-Graduate의 고객 수가 516명으로 두번째로 낮으므로 신뢰성이 떨어짐.\n    - Uneducated, Unknown 고객층도 평균 이상의 이탈률을 보임(15.9%, 16.9%)\n    - 이탈의 차이가 약 5-6%p 정도 있지만 그 차이가 크지 않고 이탈률이 높은 고객군의 고객 수가 다른 고객군에 비해 낮기 때문에 해당 변수는 이탈에 영향을 미친다고 보기 어려움.\n\n<br>\n\n### **🔸 Marital_Status(고객의 결혼 상태)**\n\n- 고객 수 분포\n    - Divorced: 748명\n    - Married: 4,687명\n    - Single: 3,943명\n    - Unknown: 749명\n- Marital_Status 별 이탈률\n    - Divorced: 16.2%\n    - Married: 15.1%\n    - Single: 16.9%\n    - Unknown: 17.2%\n    #### **📌 Insight:** \n    - 모든 범주 별 이탈률이 15-17% 사이.\n        - 범주 별로 이탈률에 큰 차이가 없고 전체적으로 평탄함.\n        - Unknown이 17.2%로 약간 높지만(가장 낮은 이탈률과 2.1%p 차이) 이 역시 차이가 크지 않음.\n    - Married와 Single의 고객 수가 많음(4,687명, 3,943명)\n        - Married와 Single의 고객 수가 많기 때문에 해당 범주들은 신뢰성이 높음.\n        - 반대로 Divorced와 Unknown은 고객 수가 적어 이탈률에 민감하게 반응할 가능성이 있음.\n    - 따라서 Marital_Status가 이탈에 큰 영향을 주는 변수라고 할 수는 없음. 또한 신뢰성이 높은 Married와 Single의 이탈률 차이는 1.8%p밖에 나지 않기 때문에 단독 변수로 타겟팅 포인트가 되기에는 어려움. 다른 변수와의 조합을 통한 추가 분석이 필요함.\n\n<br>\n\n### **🔸 Income_Category(고객의 연간 소득 범위)**\n\n- 고객 수 분포\n    - 120K +: 727명\n    - 40K-60K: 1790명\n    - 60K-80K: 1,402명\n    - 80K-120K: 1,535명\n    - Less than 40K: 3,561명\n    - Unknown: 1,112명\n- Income_Category 별 이탈률\n    - 120K +: 17.3%\n    - 40K-60K: 15.1%\n    - 60K-80K: 13.5%\n    - 80K-120K: 15.8%\n    - Less than 40K: 17.2%\n    - Unknown: 16.8%\n    #### **📌 Insight:** \n    - 120K+, Unknown에서의 고객 수가 가장 적음(727명, 1,112명).\n        - 이탈률 해석 시 민감도에 주의할 필요가 있음.\n    - 중간 소득층인 60-80K 구간의 이탈률이 가장 낮음(13.5%).\n        - 반면, 저소득층(Less than $40K)와 고소득층(120K+)에서의 이탈률은 높음(17.2%, 17.3%).\n        - 소득 수준에 따른 이탈률의 경향성이 존재함.\n    - 따라서 해당 변수는 저소득층과 고소득층에서 이탈 비중이 높고 중소득층에서 이탈 비중이 상대적으로 낮은 특정 패턴을 보이므로, 이탈에 영향을 미친다고 할 수 있음. 또한 중소득층에서 이탈률이 가장 적다는 것과 앞선 특정 패턴을 통해 명확한 세그먼트 별 분석이 가능하므로 타겟팅 포인트가 될 수 있음.\n\n<br>\n\n### **🔸 Card_Category(고객이 소지한 신용카드의 유형)**\n\n- 고객 수 분포\n    - Blue: 9,436명\n    - Silver: 555명\n    - Gold: 116명\n    - Platinum: 20명\n- Card_Category 별 이탈률\n    - Blue: 16.1%\n    - Silver: 14.8%\n    - Gold: 18.1%\n    - Platinum: 25%\n    #### **📌 Insight:** \n    - 범주 별 인원수에 큰 차이가 있음.\n        - Blue 카드와 Platinum 카드의 인원수 차이가 9,416.\n        - Platinum 카드의 경우 등급제이기 때문에 인원수가 적을 수 밖에 없긴 하지만, 그럼에도 이탈률에 민감할 수 있기 때문에 주의가 필요함.\n    - 이탈률에 뚜렷한 패턴이 없음.\n        - Silver 카드는 가장 낮은 이탈률(14.8%). Platinum 카드는 가장 높은 이탈률(25%)\n        - 전반적으로 카드 등급이 높다고 이탈률이 낮아지는 구조는 아님.\n    - 따라서 해당 변수는 특정한 패턴을 보이지 않고, 구간 별 인원수 차이도 크기 때문에 이탈에 단독적으로 영향을 미친다고 보기 어려움. 그러나, 각 구간 별 마케팅 전략을 세울 수 있고, 추가 분석을 통해 구간 별 특정한 패턴을 알아낼 수 있을 것으로 예상되기 때문에 타겟팅 포인트가 될 수 있음.\n\n<br>\n\n---","metadata":{"execution":{"iopub.status.busy":"2025-07-12T14:24:16.490621Z","iopub.execute_input":"2025-07-12T14:24:16.491535Z","iopub.status.idle":"2025-07-12T14:24:16.510453Z","shell.execute_reply.started":"2025-07-12T14:24:16.491502Z","shell.execute_reply":"2025-07-12T14:24:16.509137Z"}}},{"cell_type":"code","source":"df[categoric_lst].head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T07:01:19.865823Z","iopub.execute_input":"2025-08-10T07:01:19.866051Z","iopub.status.idle":"2025-08-10T07:01:19.875083Z","shell.execute_reply.started":"2025-08-10T07:01:19.866033Z","shell.execute_reply":"2025-08-10T07:01:19.874326Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for i in categoric_lst:\n    print(f\"변수: {i}\\n\")\n    fig, axes = plt.subplots(1,2,figsize=(10,6))\n    sns.countplot(data=df, x=i, hue='Attrition_Flag',ax=axes[0])\n    axes[0].tick_params(axis='x', rotation=45)\n    axes[0].set_title(f\"{i} - Distribution of Customer Count\")\n\n    churn_rate = df.groupby(i)['is_churn'].mean().reset_index()\n    churn_rate.columns = [i, 'churn_rate']\n\n    sns.barplot(data=churn_rate, x=i, y='churn_rate', ax=axes[1], color='salmon')\n    axes[1].set_title(f\"{i} - Churn Rate (%)\")\n    axes[1].tick_params(axis='x', rotation=45)\n    axes[1].set_ylim(0,1)\n    axes[1].yaxis.set_major_formatter(plt.FuncFormatter(lambda y, _: '{:.0%}'.format(y)))\n\n    plt.tight_layout()\n    plt.show()\n\n    display(round(df.groupby(i)['is_churn'].mean().reset_index(),3))\n    display(df.groupby(i)['is_churn'].value_counts().reset_index())\n    print('\\n')\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T07:01:19.875938Z","iopub.execute_input":"2025-08-10T07:01:19.87616Z","iopub.status.idle":"2025-08-10T07:01:22.194247Z","shell.execute_reply.started":"2025-08-10T07:01:19.876141Z","shell.execute_reply":"2025-08-10T07:01:22.193595Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# ✔ Process 02 - 이탈예측 모델링\n\n- 모델링 전처리\n    - 파생변수 추가\n    - Unknown값 처리\n    - 범주형 변수 인코딩\n    - 모델링 전 분포확인\n- 모델링\n    - Logistic Regression (Base Line)\n    - SVM\n    - Random Forest\n    - Light GBM (+성능개선)\n    - Catboost (+성능개선)\n- 최종 모델해석 및 Feature Selection\n    - 모델 해석(SHAP)\n    - 변수선택 (Feature Selection)\n\n---","metadata":{}},{"cell_type":"markdown","source":"## 🔹 모델링 전처리\n- 파생변수 추가\n- Unknown값 처리\n- 범주형 변수 인코딩\n- 모델링 전 분포확인","metadata":{}},{"cell_type":"markdown","source":"### 🔸 파생 변수추가\n\n- 위의 인사이트를 종합하여 의미 있을 것으로 보이는 파생 변수들 생성\n- 범주형 변수에서 Unknown을 하나의 범주로 인정한 후, 추후 판단 논의 예정 (Unknown_Flag를 통해 Unknown 여부 설정)\n\n<br>\n\n| 변수명 | 설명 | 계산식 | 선정 이유 |\n|:---|:---|:---|:---|\n| **Engagement_Score** | 고객 활동성 종합 지표 | `(Total_Trans_Ct * Total_Amt_Chng_Q4_Q1) / (Months_Inactive_12_mon + 1)`| 거래 횟수와 금액의 변화율, 그리고 비활성 기간을 동시에 고려하여 고객의 전반적인 활동 수준을 종합적으로 반영 → EDA에서 이 세 변수 모두 이탈과 관련 있는 경향 확인됨 |\n\n<br>\n\n> **Engagement_Score(고객 활동성 수준)**\n> \n    - KDE Plot\n        - 유지 고객(파랑)의 분포는 약 20 부근에서 가장 높고 뾰족한 모습을 보임. 오른쪽 꼬리 조금 있음.\n        - 이탈 고객(주황)의 분포는 약 10 부근에서 가장 높고 뾰족한 모습을 보임. 오른쪽 꼬리 조금 있으며 약 20 부근 낮아지는 모습을 보임.\n    - Box Plot\n        - 중앙값: 유지 고객은 16.01. 이탈 고객은 7.80\n        - 범위(IQR): 유지고객은 약 12-23. 이탈 고객은 약 8-15.\n        - 이상치: 유지 고객은 약 100까지 이상치가 다수 발견됨. 이탈 고객은 약 60까지 이상치가 다수 발견됨.\n    - 구간 별 평균 이탈률\n        - 0-8.2 구간의 평균 이탈률이 약 42.6%로 가장 높음.\n        - 23.1-101.1 구간의 평균 이탈률이 약 2.6%로 가장 낮음.\n\n|활동성 수준 구간|이탈률|\n|:---|:---|\n|0-8.3|43.4%|\n|8.3-12.6|19.7%|\n|12.6-16.9|9.7%|\n|16.9-23.2|4.9%|\n|23.2-101.1|2.6%|\n\n<br>\n\n#### *인사이트*\n- 분포 차이, 중앙값 차이, IQR 범위 차이, 구간 별 이탈률 차이가 뚜렷하고 구간 별 패턴이 명확함.\n    - 활동성 수준과 이탈률은 명백한 음의 상관관계로 선형적 패턴을 보임.\n- 따라서 해당 파생 변수는 낮을수록 이탈 확률이 급격히 상승하며, 특히 8.3 미만 구간에서는 이탈률이 40%를 초과하는 등, 매우 우수한 변별력을 보임.\n\n\n<br>\n\n---","metadata":{}},{"cell_type":"code","source":"df['Months_Inactive_12_mon'].unique()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T07:01:22.195052Z","iopub.execute_input":"2025-08-10T07:01:22.195334Z","iopub.status.idle":"2025-08-10T07:01:22.201054Z","shell.execute_reply.started":"2025-08-10T07:01:22.195307Z","shell.execute_reply":"2025-08-10T07:01:22.200406Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 파생변수를 위한 df_feature 생성\ndf_feature = df.copy(deep=True)\n\n# 1. Engagement_Score: (Total_Trans_Ct * Total_Amt_Chng_Q4_Q1) / (Months_Inactive_12_mon + 1)\ndf_feature['Engagement_Score'] = (\n    df_feature['Total_Trans_Ct'] * df_feature['Total_Amt_Chng_Q4_Q1']\n) / (df_feature['Months_Inactive_12_mon']+1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T07:01:22.201915Z","iopub.execute_input":"2025-08-10T07:01:22.202194Z","iopub.status.idle":"2025-08-10T07:01:22.223371Z","shell.execute_reply.started":"2025-08-10T07:01:22.202175Z","shell.execute_reply":"2025-08-10T07:01:22.222514Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"derived_feature = ['Engagement_Score']\nfor i in derived_feature:\n    print(f\"\\n 변수: {i}\")\n    plt.figure(figsize=(10,6))\n\n    # KDE Plot\n    plt.subplot(1,3,1)\n    sns.kdeplot(data=df_feature, x=i, hue='Attrition_Flag', fill=True)\n    plt.title(f\"{i} - KDE Plot\")\n\n    # Box Plot\n    plt.subplot(1,3,2)\n    ax = sns.boxplot(x='is_churn', y=i, data=df_feature)\n    plt.title(f\"{i} - Boxplot\")\n    medians = df_feature.groupby('is_churn')[i].median()\n    for idx, median in enumerate(medians):\n        ax.text(idx, median + 0.2, f'{median:.2f}', ha='center', color='black', fontsize=10, fontweight='bold')\n\n    # 구간 별 이탈률\n    raw_gp = pd.qcut(df_feature[i], q=5, duplicates='drop')\n    labels = [f\"{round(b.left, 1)} - {round(b.right, 1)}\" for b in raw_gp.cat.categories]\n    df_feature[f\"{i}_gp\"] = pd.qcut(df_feature[i], q=5, duplicates='drop', labels=labels)\n    churn_by_gp = df_feature.groupby(f'{i}_gp')['is_churn'].mean().reset_index()\n\n    plt.subplot(1,3,3)\n    sns.barplot(x=f'{i}_gp', y='is_churn', data=churn_by_gp)\n    plt.title(f\"{i} - Churn Rate by Bins\")\n    plt.ylabel(\"Churn Rate (%)\")\n    plt.xticks(rotation=45)\n    plt.gca().yaxis.set_major_formatter(PercentFormatter(1.0))\n\n    # 잔존/이탈 고객 비율(*100%) & 인원수(명)\n    print(f\"{i}_gp\")\n    display(round(df_feature.groupby(f\"{i}_gp\")['is_churn'].mean().reset_index(),3))\n    display(df_feature.groupby(f\"{i}_gp\")['is_churn'].value_counts().reset_index())\n    print('\\n')\n    \n    plt.tight_layout()\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T07:01:22.224183Z","iopub.execute_input":"2025-08-10T07:01:22.224446Z","iopub.status.idle":"2025-08-10T07:01:23.030124Z","shell.execute_reply.started":"2025-08-10T07:01:22.224426Z","shell.execute_reply":"2025-08-10T07:01:23.029365Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 🔸 Unknown 값 처리\n\n- Unknown이 하나의 범주로 자리하고 있는 변수는 Marital_Status, Education_Level, Income_Category\n- 이탈에 미치는 고객의 특성을 확인하기 위해서는 Unknown(미기재)한 것을 무시할 수 없다고 판단됨.\n- 이 중 Education_Level과 Income_Category는 순서가 있는 범주형 변수라고 판단되어, Unknown 값을 중간값으로 대체하여 인코딩 진행 후, 각 변수 별 Unknown_Flag를 파생 변수로 추가\n- Marital_Status는 순서가 없는 범주형 변주이므로, 따로 처리하지 않고 하나의 범주로 판단.","metadata":{}},{"cell_type":"code","source":"# Unknown이 있는 컬럼들 확인\nprint(\"Marital Status: \", df_feature['Marital_Status'].unique())\nprint(\"\\n\")\nprint(\"Education Level: \", df_feature['Education_Level'].unique())\nprint(\"\\n\")\nprint(\"Income Category: \", df_feature['Income_Category'].unique())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T07:01:23.031386Z","iopub.execute_input":"2025-08-10T07:01:23.031902Z","iopub.status.idle":"2025-08-10T07:01:23.038969Z","shell.execute_reply.started":"2025-08-10T07:01:23.031872Z","shell.execute_reply":"2025-08-10T07:01:23.03836Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 순서가 있는 범주형 변수들(Unknown이 있는)의 Unknown_Flag 생성\ndf_feature['Edu_Unknown_Flag'] = df_feature['Education_Level'].apply(lambda x: 1 if x == 'Unknown' else 0)\ndf_feature['Income_Unknown_Flag'] = df_feature['Income_Category'].apply(lambda x: 1 if x == 'Unknown' else 0)\ndf_feature[['Education_Level', 'Edu_Unknown_Flag', 'Income_Category', 'Income_Unknown_Flag']].head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T07:01:23.039703Z","iopub.execute_input":"2025-08-10T07:01:23.039972Z","iopub.status.idle":"2025-08-10T07:01:23.069614Z","shell.execute_reply.started":"2025-08-10T07:01:23.039949Z","shell.execute_reply":"2025-08-10T07:01:23.068809Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 🔸 범주형 변수 인코딩\n\n- 순서가 있는 범주형 변수 (Education_Level, Income_Category, Card_Category)\n    - 각 범주를 순서에 맞게 0부터 숫자 부여\n    - Unknown 범주는 각 범주형 변수의 중앙 범주에 해당하는 값으로 대체\n    - 모델에서는 Unknown_Flag가 함께 들어가 Unknown을 확인\n    - Unknown 값을 제거하고 진행한다면 라벨 인코딩 사용 가능\n- 순서가 없는 범주형 변수\n    - LabelEncoder를 사용하여 인코딩","metadata":{}},{"cell_type":"code","source":"df_feature['Card_Category'].unique()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T07:01:23.070494Z","iopub.execute_input":"2025-08-10T07:01:23.070867Z","iopub.status.idle":"2025-08-10T07:01:23.091062Z","shell.execute_reply.started":"2025-08-10T07:01:23.070822Z","shell.execute_reply":"2025-08-10T07:01:23.090417Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 순서가 있는 범주형 변수\nedu_map = {\n    'Uneducated':0, 'High School':1, 'College':2, 'Graduate':3, 'Post-Graduate':4, 'Doctorate':5,\n    'Unknown':3\n}\n\nIncome_map = {\n    'Less than $40K':0, '$40K - $60K':1, '$60K - $80K':2, '$80K - $120K':3, '$120K +':4,\n    'Unknown':2\n}\n\ncard_map = {\n    'Blue':0, 'Silver':1, 'Gold':2, 'Platinum':3\n}\n\ndf_feature['Education_Level_encoded'] = df_feature['Education_Level'].map(edu_map)\ndf_feature['Income_Category_encoded'] = df_feature['Income_Category'].map(Income_map)\ndf_feature['Card_Category_encoded'] = df_feature['Card_Category'].map(card_map)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T07:01:23.091961Z","iopub.execute_input":"2025-08-10T07:01:23.092246Z","iopub.status.idle":"2025-08-10T07:01:23.11203Z","shell.execute_reply.started":"2025-08-10T07:01:23.092222Z","shell.execute_reply":"2025-08-10T07:01:23.11129Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 순서가 없는 범주형 변수\ncat_cols = ['Gender', 'Marital_Status']\n\nle = LabelEncoder()\nfor col in cat_cols:\n    df_feature[f\"{col}_encoded\"] = le.fit_transform(df_feature[col])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T07:01:23.112906Z","iopub.execute_input":"2025-08-10T07:01:23.113282Z","iopub.status.idle":"2025-08-10T07:01:23.132193Z","shell.execute_reply.started":"2025-08-10T07:01:23.113254Z","shell.execute_reply":"2025-08-10T07:01:23.131532Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_feature[['Gender', 'Gender_encoded', 'Marital_Status', 'Marital_Status_encoded']].head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T07:01:23.132988Z","iopub.execute_input":"2025-08-10T07:01:23.133253Z","iopub.status.idle":"2025-08-10T07:01:23.151451Z","shell.execute_reply.started":"2025-08-10T07:01:23.133228Z","shell.execute_reply":"2025-08-10T07:01:23.150663Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 🔸 모델링 전 분포 확인\n\n- 결측치 확인 -> 이상 없음\n- 인코딩된 컬럼 분포 확인 -> 이상 없음\n- 최종 모델에 사용할 변수 개수: 22개","metadata":{}},{"cell_type":"code","source":"# 결측값 확인\ndf_feature.isnull().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T07:01:23.152366Z","iopub.execute_input":"2025-08-10T07:01:23.153112Z","iopub.status.idle":"2025-08-10T07:01:23.176303Z","shell.execute_reply.started":"2025-08-10T07:01:23.15309Z","shell.execute_reply":"2025-08-10T07:01:23.175658Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 인코딩 된 컬럼 값 분포 확인\nencoded_cols = [col for col in df_feature.columns if '_encoded' in col or '_Flag' in col]\nfor col in encoded_cols:\n    print(f\"[{col}]\")\n    print(df_feature[col].value_counts())\n    print()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T07:01:23.17722Z","iopub.execute_input":"2025-08-10T07:01:23.177989Z","iopub.status.idle":"2025-08-10T07:01:23.197529Z","shell.execute_reply.started":"2025-08-10T07:01:23.177943Z","shell.execute_reply":"2025-08-10T07:01:23.196565Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 모델에 사용할 컬럼\nmodel_cols = [\n    col for col in df_feature.columns\n    if df_feature[col].dtype in ['int64', 'float64']\n    and col != 'is_churn'\n    and col != 'CLIENTNUM'\n]\n\nprint(\"모델 입력 변수 개수: \", len(model_cols))\nprint(\"샘플 변수 목록: \", model_cols[:5])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T07:01:23.198384Z","iopub.execute_input":"2025-08-10T07:01:23.198667Z","iopub.status.idle":"2025-08-10T07:01:23.211805Z","shell.execute_reply.started":"2025-08-10T07:01:23.198645Z","shell.execute_reply":"2025-08-10T07:01:23.210965Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 🔹 모델링\n- Logistic Regression (Base Line)\n- SVM\n- Random Forest\n- Light GBM (+성능개선)\n- Catboost (+성능개선)\n- 최종 모델 선정","metadata":{}},{"cell_type":"code","source":"# 데이터 분리\nX = df_feature[model_cols]\ny = df_feature['is_churn']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T07:01:23.212604Z","iopub.execute_input":"2025-08-10T07:01:23.212889Z","iopub.status.idle":"2025-08-10T07:01:23.237525Z","shell.execute_reply.started":"2025-08-10T07:01:23.212861Z","shell.execute_reply":"2025-08-10T07:01:23.236569Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 🔸 Logistic Regression (Base Line)\n\n<br>\n\n- 모델명\n    - Logistic Regression\n \n<br>\n\n- 적용 파라미터\n        \n| 파라미터 | 설명 | 현재 적용값 | 사용 이유 |\n| --- | --- | --- | --- |\n| `penalty` | 정규화 방식 (L1, L2 등) | 기본값 (`'l2'`) | 과적합을 방지하고 가중치를 안정화하기 위해 L2 적용 |\n| `C` | 규제 강도 (작을수록 규제 강함) | 기본값 (`1.0`) | 베이스라인 모델이라 디폴트 사용. 튜닝 시 성능 영향 |\n| `solver` | 최적화 알고리즘 | 기본값 (`lbfgs`) | 대부분 문제에 적합하며 멀티클래스와 L2에 잘 맞음 |\n| `class_weight` | 클래스 불균형 가중치 설정 | `'balanced'` | 이탈 클래스가 소수이므로 FN 감소를 위해 필수 |\n| `max_iter` | 최적화 반복 수 | `1000` | 수렴 실패 방지. 다차원 변수 모델에서 자주 필요 |\n| `random_state` | 난수 고정값 | `42` | 결과 재현성 확보 |\n\n<br>\n\n- 사용 이유\n    - 단순하고 빠르며 해석이 쉽기 때문에 Base Line으로 적합\n    - 각 변수의 계수를 통해 이탈 확률에 긍정/부정 영향을 주는 요소를 직관적으로 확인 가능\n    - 빠른 모델 훈련이 가능하고 튜닝이 간편하여 이후 복잡한 모델과 성능 비교가 용이함\n\n<br>\n\n---\n\n<br>\n\n\n#### **성능검증**\n\n- 선택 지표 성능\n    \n| **지표** | **값** |\n| --- | --- |\n| **Precision** | 0.5117 |\n| **Recall** | 0.8092 |\n| **F1 Score** | 0.6315 |\n| **ROC-AUC** | 0.9174 |\n\n- Confusion Matrix\n    \n|  | **Predicted 0** | **Predicted 1** |\n| --- | --- | --- |\n| **Actual 0** | 1,456 | 245 |\n| **Actual 1** | 62 | 263 |\n\n<br>\n\n- Logistic Regression을 통한 초기 모델링 결과, 이탈 고객의 재현율은 81%로 매우 우수하게 나타났으며, 전체 분류 성능을 나타내는 ROC-AUC도 0.917로 양호\n- 다만, 정밀도가 52%로 낮아 오분류(정상 고객을 이탈로 예측)가 다소 존재하므로, 이후 SVM 및 트리 기반 모델에서의 성능 개선을 확인해 볼 필요가 있음.","metadata":{}},{"cell_type":"code","source":"# Scaling\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\nX_scaled = pd.DataFrame(X_scaled, columns=X.columns)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T07:01:23.238407Z","iopub.execute_input":"2025-08-10T07:01:23.23878Z","iopub.status.idle":"2025-08-10T07:01:23.262785Z","shell.execute_reply.started":"2025-08-10T07:01:23.238741Z","shell.execute_reply":"2025-08-10T07:01:23.26174Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Split\nX_train, X_test, y_train, y_test = train_test_split(\n    X_scaled,\n    y,\n    test_size=0.2,\n    stratify=y,\n    random_state=42\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T07:01:23.263764Z","iopub.execute_input":"2025-08-10T07:01:23.264021Z","iopub.status.idle":"2025-08-10T07:01:23.274148Z","shell.execute_reply.started":"2025-08-10T07:01:23.263998Z","shell.execute_reply":"2025-08-10T07:01:23.27343Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 모델 정의\nlogreg = LogisticRegression(\n    class_weight = 'balanced',\n    max_iter = 1000,\n    random_state=42\n)\n\n# 학습\nlogreg.fit(X_train, y_train)\n\n# 예측\ny_pred = logreg.predict(X_test)\ny_proba = logreg.predict_proba(X_test)[:,1]\n\n# 검증\n# Confusino Matrix\ncm = confusion_matrix(y_test, y_pred)\nprint(\"Confusion Matirx\")\nprint(cm)\n\nplt.figure(figsize=(4,3))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\nplt.title(\"Logistic Regression - Confusion Matrix\")\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"Actual\")\nplt.show()\n\n# 지표\nprint(\"\\n Classification Report\")\nprint(classification_report(y_test, y_pred))\n\nprecision = precision_score(y_test, y_pred)\nrecall = recall_score(y_test, y_pred)\nf1 = f1_score(y_test, y_pred)\nauc = roc_auc_score(y_test, y_proba)\n\nprint(\"------------\")\nprint(f\"Precision      : {round(precision, 4)}\")\nprint(f\"Recall         : {round(recall, 4)}\")\nprint(f\"F1 Score       : {round(f1, 4)}\")\nprint(f\"ROC-AUC        : {round(auc, 4)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T07:01:23.275018Z","iopub.execute_input":"2025-08-10T07:01:23.275283Z","iopub.status.idle":"2025-08-10T07:01:23.743206Z","shell.execute_reply.started":"2025-08-10T07:01:23.275259Z","shell.execute_reply":"2025-08-10T07:01:23.742429Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 🔸 SVM (Support Vector Machine)\n\n- 모델명\n    - Support Vector Machine\n \n<br>\n\n- 적용 파라미터\n    \n| 파라미터 | 적용값 | 설명 | 사용 이유 |\n| --- | --- | --- | --- |\n| `kernel` | `'rbf'` | 커널 함수 종류 (결정 경계의 형태) | 비선형 분류에 강력, 실제 이탈 데이터는 선형 분리가 어려울 수 있음 |\n| `C` | 기본값 (`1.0`) | 오분류 허용도 조절 파라미터. 작을수록 마진 ↑, 과적합 ↓ | 베이스라인에서는 기본값 사용. 추후 튜닝으로 Recall/Precision 조정 가능 |\n| `gamma` | `'scale'` (기본값) | RBF 커널에서 한 포인트가 주변에 미치는 영향력 반경 | `'scale'`은 `1 / (n_features * X.var())` 기준으로 자동 조절. 기본값은 적절한 일반화 수준 제공 |\n| `class_weight` | `'balanced'` | 각 클래스의 데이터 수에 따라 가중치 자동 부여 | 이탈 고객처럼 소수 클래스의 Recall 향상을 위해 필수 |\n| `probability` | `True` | 확률 출력 가능하게 함 (`predict_proba`) | ROC-AUC 계산을 위해 필수 |\n| `random_state` | `42` | 난수 고정용 시드값 | 결과 재현성 확보 |\n| `max_iter` | `-1` (기본값, 무제한) | 반복 최대 횟수. 기본은 수렴할 때까지 반복 | 기본값으로 충분. 수렴 문제 발생 시 설정 필요 |\n\n<br>\n\n- 작동 원리\n    - 클래스 0과 클래스 1 사이를 나누는 선/면 (결정 경계)로 나눔\n        - 2D에서는 선, 3D 이상에서는 평면 또는 초평면\n    - 각 클래스의 가장 가까운 데이터 점(=Support Vector)과 결정 경계 사이의 거리를 측정\n    - 이 마진(거리)을 최대화하는 방향으로 학습\n    - 만약 선형으로 나눌 수 없다면 커널 기법을 통해 데이터를 고차원으로 매핑해서 선형으로 구분 가능하게 만듬\n        - linear(단순 선형), rbf(기본값, 비선형), poly(다항식 기반 분류) 등\n     \n<br>\n\n- 사용 이유\n    - 비선형 데이터 분리에 유리하기 때문에 Logistic보다 더 정교함\n    - 마진 기반 분류로 데이터가 혼재되어 있어도 경계에 민감함\n    - 해석은 어렵지만 분류 성능이 강함\n\n<br>\n\n---\n\n<br>\n\n#### **성능검증**\n\n- 선택 지표 성능\n    \n| **지표** | **값** |\n| --- | --- |\n| **Precision** | 0.6793 |\n| **Recall** | 0.88 |\n| **F1 Score** | 0.7668 |\n| **ROC-AUC** | 0.9573 |\n\n<br>\n\n- Confusion Matrix\n    \n|  | **Predicted 0** | **Predicted 1** |\n| --- | --- | --- |\n| **Actual 0** | 1,566 | 135 |\n| **Actual 1** | 39 | 286 |\n\n<br>\n\n- SVM 모델은 이탈 고객 예측 Recall을 0.88까지 높이며 이탈 고객을 효과적으로 탐지함\n- 동시에 Precision도 0.68로 이전보다 오르며 과잉 타겟팅 문제도 완화됨\n- ROC-AUC 역시 0.96으로 모델이 전체적으로 이탈과 비이탈 고객을 탁월하게 구분하고 있음\n- SVM은 베이스라인 모델 대비 모든 주요 지표에서 성능 향상을 보였으며, 이탈 예측 목적에 매우 적합한 분류기로 판단됨","metadata":{}},{"cell_type":"code","source":"# 모델 정의\nsvm = SVC(\n    kernel = 'rbf',\n    class_weight = 'balanced',\n    probability = True,\n    random_state = 42\n)\n\n# 학습\nsvm.fit(X_train, y_train)\n\n# 예측\ny_pred = svm.predict(X_test)\ny_proba = svm.predict_proba(X_test)[:,1]\n\n# 검증\n# Confusion Matrix\ncm = confusion_matrix(y_test, y_pred)\nprint(\"Confusion Matrix\")\nprint(cm)\n\nplt.figure(figsize=(4,3))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\nplt.title(\"SVM - Confusion Matrix\")\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"Actual\")\nplt.show()\n\n# 지표\nprint(\"\\n Classification Report\")\nprint(classification_report(y_test, y_pred))\n\nprecision = precision_score(y_test, y_pred)\nrecall = recall_score(y_test, y_pred)\nf1 = f1_score(y_test, y_pred)\nauc = roc_auc_score(y_test, y_proba)\n\nprint(\"------------\")\nprint(f\"Precision      : {round(precision, 4)}\")\nprint(f\"Recall         : {round(recall, 4)}\")\nprint(f\"F1 Score       : {round(f1, 4)}\")\nprint(f\"ROC-AUC        : {round(auc, 4)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T07:01:23.74414Z","iopub.execute_input":"2025-08-10T07:01:23.744536Z","iopub.status.idle":"2025-08-10T07:01:33.098333Z","shell.execute_reply.started":"2025-08-10T07:01:23.744509Z","shell.execute_reply":"2025-08-10T07:01:33.097464Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 🔸 Random Forest\n\n- 모델명\n    - Random Forest\n \n<br>\n\n- 적용 파라미터\n\n| 파라미터 | 설명 | 적용 값 | 적용 이유 |\n| --- | --- | --- | --- |\n| `n_estimators` | 트리의 개수(몇 개의 결정 트리를 사용할 것인가?) | 100 | 데이터의 수가 많지 않기 때문에\n적절한 수로 결정 \n(너무 높은 값을 설정하면 학습 속도가 느려지고, 너무 작은 값을 설정하면 성능이 불안정해 짐) |\n| `max_depth` | 각 트리의 최대 깊이를 제한 (과적합 방지) | None | 베이스 라인으로 활용할 모델이기 때문에 None(노드가 순수해질 때까지)으로 지정 후, 후에 튜닝 예정 |\n| `class_weight` | 클래스 불균형 문제 해결을 위한 자동 가중치 조정 옵션 | `‘balanced’` | 유지 고객과 이탈 고객이 불균형 문제가 있기 때문에 자동으로 가중치를 부여하도록 설정 |\n| `random_state` | 랜덤 분할의 재현성을 위한 시드 값 | 42 | 숫자의 크기와는 무관함 |\n\n<br>\n\n- 사용 이유\n    - 사용한 Feature가 수치형과 범주형이 모두 있고, 변수들과 타겟 변수의 분포를 확인한 결과, 선형성이 거의 발견되지 않음. 또한 변수들간의 상호 관계가 있을 것으로 예상됨.\n    - 또한 여러 Decision Tree를 통해 결정되는 강력한 모델이기 때문에 별도의 큰 전처리 없이 사용이 가능\n    - 따라서 초기 모델로 Random Forest를 사용하여 기본적인 성능 및 중요도를 확인하고자 함.\n    - 변수 중요도 추출 및 주요 변수 선별을 위한 기반 모델로서 최적으로 판단됨.\n\n<br>\n\n---\n\n<br>\n\n#### **성능검증**\n- 선택 지표 성능\n    \n| 지표 | 값 |\n| --- | --- |\n| **Precision (Class 1)** | 0.9228 |\n| **Recall (Class 1)** | 0.7354 |\n| **F1 Score** | 0.8185 |\n| **ROC-AUC** | 0.9854 |\n\n<br>\n\n- Confusion Matrix\n\n|  | Predicted 0  | Predicted 1 |\n| --- | --- | --- |\n| Acutal 0 | 1681 | 20 |\n| Actual 1 | 86 | 239 |\n- F1 Score 0.818로 전체적인 성능이 우수\n- 특히, Precision(0.9228)이 높아 이탈 예측 시 오탐(Fals Positive)을 잘 줄임.\n- 하지만 Recall(0.7354)은 다소 낮음 → 실제 이탈 고객 중 일부를 잡아내지 못함.\n- 이탈 위험도 분류를 나누기 위해 Recall 성능을 향상시킬 필요가 있음.","metadata":{}},{"cell_type":"code","source":"# 데이터 분리 -> 스케일링 되지 않은 데이터 필요\nX = df_feature[model_cols]\ny = df_feature['is_churn']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T07:01:33.099299Z","iopub.execute_input":"2025-08-10T07:01:33.09964Z","iopub.status.idle":"2025-08-10T07:01:33.113244Z","shell.execute_reply.started":"2025-08-10T07:01:33.099613Z","shell.execute_reply":"2025-08-10T07:01:33.11259Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 모델 정의\nrf = RandomForestClassifier(\n    n_estimators = 100,\n    max_depth = None,\n    class_weight = 'balanced',\n    random_state = 42,\n    n_jobs = -1\n)\n\n# 학습\nrf.fit(X_train, y_train)\n\n# 예측\ny_pred = rf.predict(X_test)\ny_proba = rf.predict_proba(X_test)[:,1]\n\n# 검증\n# Confusion Matrix\ncm = confusion_matrix(y_test, y_pred)\nprint(\"Confusion Matrix\")\nprint(cm)\n\nplt.figure(figsize=(4,3))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\nplt.title(\"RandomForest - Confusion Matrix\")\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"Actual\")\nplt.show()\n\n# 지표\nprint(\"\\n Classification Report\")\nprint(classification_report(y_test, y_pred))\n\nprecision = precision_score(y_test, y_pred)\nrecall = recall_score(y_test, y_pred)\nf1 = f1_score(y_test, y_pred)\nauc = roc_auc_score(y_test, y_proba)\n\nprint(\"------------\")\nprint(f\"Precision      : {round(precision, 4)}\")\nprint(f\"Recall         : {round(recall, 4)}\")\nprint(f\"F1 Score       : {round(f1, 4)}\")\nprint(f\"ROC-AUC        : {round(auc, 4)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T07:01:33.114104Z","iopub.execute_input":"2025-08-10T07:01:33.114428Z","iopub.status.idle":"2025-08-10T07:01:34.050063Z","shell.execute_reply.started":"2025-08-10T07:01:33.114399Z","shell.execute_reply":"2025-08-10T07:01:34.049382Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 🔸 LightGBM\n\n- 모델명\n    - LightGBM\n \n<br>\n\n- 적용 파라미터\n    \n| 파라미터 | 설명 | 적용 값 | 적용 이유 |\n| --- | --- | --- | --- |\n| `n_estimators` | 부스팅 반복 횟수(트리 개수) | 100 | - 지나치게 많은 트리는 과적합 위험 <br> - 데이터 수가 10,000건 이하로 많지 않아 적정 수준을 유지 <br> - 추후 범위 조정 예정 |\n| `learning_rate` | 학습률(트리마다 기여하는 정도) | 0.1 | - LightGBM에서 기본적으로 많이 쓰이는 값 <br> - 너무 크면 수렴이 불안정, 너무 작으면 학습이 오래 걸림 |\n| `class_weight` | 클래스 불균형 문제 해결을 위한 자동 가중치 조정 옵션 | `‘balanced’` | 유지 고객과 이탈 고객이 불균형 문제가 있기 때문에 자동으로 가중치를 부여하도록 설정 |\n| `random_state` | 랜덤 분할로 인한 결과의 재현성을 위한 시드 값 | 42 | 숫자의 크기와는 무관함 |\n| `n_jobs` | 병렬 처리할 CPU 코어 수 | -1 | - 가능한 모든 코어를 사용하여 학습 속도를 향상 |\n\n<br>\n\n- 사용 이유\n    - 훈련 속도가 빠르고, SHAP 값 기반 해석을 통해 변수 별 영향도를 확인할 수 있음\n    - 클래스 불균형 데이터에 강하고, 수치형/범주형 변수를 모두 복잡한 인코딩 없이 사용이 가능함.\n    - 중요도 해석과 예측의 안정성을 모두 고려하기에 적합한 모델\n\n<br>\n\n---\n\n<br>\n\n#### **성능검증**\n- 선택 지표 성능\n\n| 지표 | 값 |\n| --- | --- |\n| **Precision (Class 1)** | 0.8746 |\n| **Recall (Class 1)** | 0.9015 |\n| **F1 Score** | 0.8879 |\n| **ROC-AUC** | 0.9918 |\n\n<br>\n\n- Confusion Matrix\n\n|  | Predicted 0  | Predicted 1 |\n| --- | --- | --- |\n| Acutal 0 | 1659 | 42 |\n| Actual 1 | 32 | 293 |\n\n<br>\n\n- F1 Score 및 ROC-AUC는 모두 우수함.\n- 모든 지표가 Base Line 모델에 비해 우수하며, Random Forest에 비해 Precision은 떨어지지만, 다른 모든 지표가 우수함.\n- 해당 분석에서는 Precision보다 Recall에 중점을 두기로 하였으므로, 현재까지 LightGBM이 가장 우수한 성능을 보임.","metadata":{}},{"cell_type":"code","source":"# 모델 정의\nlgbm_model = lgb.LGBMClassifier(\n    n_estimators=100,\n    learning_rate=0.1,\n    class_weight='balanced',\n    random_state=42,\n    n_jobs=-1\n)\n\n# 학습\nlgbm_model.fit(X_train, y_train)\n\n# 예측\ny_pred = lgbm_model.predict(X_test)\ny_proba = lgbm_model.predict_proba(X_test)[:,1]\n\n# 성능 평가\ncm = confusion_matrix(y_test, y_pred)\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm)\ndisp.plot(cmap='Blues')\nplt.title(\"Confusion Matrix (LightGBM)\")\nplt.show()\n\n# 지표\nprint(\"\\n Classification Report\")\nprint(classification_report(y_test, y_pred))\n\nprecision = precision_score(y_test, y_pred)\nrecall = recall_score(y_test, y_pred)\nf1 = f1_score(y_test, y_pred)\nauc = roc_auc_score(y_test, y_proba)\n\nprint(\"------------\")\nprint(f\"Precision      : {round(precision, 4)}\")\nprint(f\"Recall         : {round(recall, 4)}\")\nprint(f\"F1 Score       : {round(f1, 4)}\")\nprint(f\"ROC-AUC        : {round(auc, 4)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T07:01:34.050916Z","iopub.execute_input":"2025-08-10T07:01:34.051177Z","iopub.status.idle":"2025-08-10T07:01:34.535466Z","shell.execute_reply.started":"2025-08-10T07:01:34.051151Z","shell.execute_reply":"2025-08-10T07:01:34.534492Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 🔸 LightGBM 성능 개선\n\n<br>\n\n- **LightGBM 성능 개선을 위한 방법(1)**\n\n    <br>\n\n    - 사용한 방법\n        - Early Stopping\n            - 모델 훈련 중 검증 성능이 더 이상 향상되지 않을 때 학습을 조기 종료하는 기법\n            - 주로 검증 데이터셋의 loss나 metric을 기준으로 판단\n            - 일정 patience동안 성능 향상이 없으면 멈춤\n\n        <br>\n  \n        - Validation Set 분할\n            - 모델의 일반화 성능을 측정하기 위해 사용하는 데이터셋으로 학습에는 사용되지 않고, 모델이 새 데이터를 얼마나 잘 예측할 수 있는지를 확인하는 역할\n            - 과적합 감지와 Early Stopping을 위해 필요\n            - Hold-out 분할\n                - 전체 데이터의 일부를 고정된 비율로 분할\n             \n      <br>\n      \n    - 사용 이유\n        - 과적합 방지: 기존 모델은 훈련 데이터에 너무 오래 학습되어 일반화 성능이 떨어짐\n        - 훈련 시간 단축: 최적 지점에서 자동으로 종료되어 불필요한 반복 제거\n        - 적정 반복 횟수 자동 선택: n_estimators를 크게 줘도 실제 반복은 최적 지점에서 조기 종료됨.\n        - 트리 기반 모델에서는 과적합이 빠르게 발생할 수 있기 때문에 유용하게 사용 가능함.\n\n<br>\n\n---\n\n<br>\n        \n- **LightGBM 성능 개선을 위한 방법 (2): 파라미터 조정 (Optuna)**\n\n    <br>\n\n    - 사용한 방법\n        - Optuna\n            - 베이지한 최적화 기반의 탐색 방식으로 하이퍼파라미터 자동 탐색을 위한 라이브러리\n            - 모델 성능을 가장 좋게 만드는 파라미터 조합을 자동으로 탐색\n \n    <br>\n\n    - 사용 이유\n        - 불필요한 조합을 시도하지 않아 시간을 단축함\n        - 과거 시도 결과를 기반으로 다음 조합을 결정하여 성능 향상을 노릴 수 있음\n        - 자동 반복과 조기 종료가 가능하여 효율적\n        - 과적합 방지를 위한 early_stopping과의 조합이 필수적임\n\n<br>\n\n- 파라미터 탐색표\n\n| 파라미터명 | 설명 | 영향 |\n| --- | --- | --- |\n| **`learning_rate`** | 학습률 (0.01 ~ 0.3) | 작을수록 안정적이지만 느림. 너무 크면 불안정 |\n| **`max_depth`** | 트리 최대 깊이 (3 ~ 10) | 클수록 복잡한 모델. 과적합 위험 증가 |\n| **`num_leaves`** | 하나의 트리에서 사용할 최대 리프 수 | 너무 크면 과적합, 너무 작으면 언더피팅 |\n| **`min_child_samples`** | 하나의 리프 노드가 가져야 할 최소 샘플 수 | 크면 일반화 ↑, 작으면 복잡도 ↑ |\n| **`subsample`** | 데이터 샘플링 비율 (0.5~1.0) | 트리마다 일부 샘플만 사용 → 과적합 방지 |\n| **`colsample_bytree`** | 피처 샘플링 비율 (0.5~1.0) | 트리마다 일부 피처만 사용 → 과적합 방지 |\n| **`n_estimators`** | 최대 부스팅 횟수 (1000) | early_stopping이 있으므로 크게 잡아도 OK |\n| **`objective`** | 목적 함수 (binary) | 이진 분류용 |\n| **`metric`** | 평가 기준 (AUC) | 모델이 최적화할 기준 점수 |\n| **`class_weight`** | 'balanced' | 불균형 데이터 대응. 소수 클래스에 가중치 |\n| **`random_state`** | 42 | 재현성 확보 |\n| **`verbosity`** | -1 | 불필요한 로그 제거 |\n\n<br>\n\n---\n\n<br>\n\n- **파라미터 적용 LightGBM**\n\n    <br>\n\n    - 모델명\n        - LightGBM\n     \n    <br>\n\n- 적용 파라미터\n             \n| 파라미터명 | 적용값 | 설명 | 영향 |\n| --- | --- | --- | --- |\n| **`learning_rate`** | 0.2112044515386995 | 학습률 (0.01 ~ 0.3) | 작을수록 안정적이지만 느림. 너무 크면 불안정 |\n| **`max_depth`** | 4 | 트리 최대 깊이 (3 ~ 10) | 클수록 복잡한 모델. 과적합 위험 증가 |\n| **`num_leaves`** | 25 | 하나의 트리에서 사용할 최대 리프 수 | 너무 크면 과적합, 너무 작으면 언더피팅 |\n| **`min_child_samples`** | 30 | 하나의 리프 노드가 가져야 할 최소 샘플 수 | 크면 일반화 ↑, 작으면 복잡도 ↑ |\n| **`subsample`** | 0.7967540180996274 | 데이터 샘플링 비율 (0.5~1.0) | 트리마다 일부 샘플만 사용 → 과적합 방지 |\n| **`colsample_bytree`** | 0.5939977278721073 | 피처 샘플링 비율 (0.5~1.0) | 트리마다 일부 피처만 사용 → 과적합 방지 |\n| **`n_estimators`** | 1,000 | 최대 부스팅 횟수 (1000) | early_stopping이 있으므로 크게 잡아도 OK |\n| **`objective`** | ‘binary’ | 목적 함수 (binary) | 이진 분류용 |\n| **`metric`** | ‘auc’ | 평가 기준 (AUC) | 모델이 최적화할 기준 점수.클래스 불균형에 강한 지표 |\n| **`class_weight`** | ‘balanced’ | 'balanced' | 불균형 데이터 대응. 소수 클래스에 가중치 |\n| **`random_state`** | 42 | 42 | 재현성 확보 |\n| **`deterministic`** |\tTrue | 재현성 확보를 위한 파라미터 | 재현성 확보 |\n| **`force_col_wise\tTrue`** | 재현성 확보를 위한 파라미터 | 히스토그램 생성 방식을 강제로 고정 |\n| **`n_jobs`** | 1 | 재현성 확보를 위한 파라미터 |\t병렬 처리 방식 결정 |\n\n<br>\n\n- 선택 지표 성능\n\n| 지표 | 값 |\n| --- | --- |\n| **Precision** | 0.8843 |\n| **Recall** | 0.9169 |\n| **F1 Score** | 0.9003 |\n| **ROC-AUC** | 0.993 |\n\n<br>\n\n- Confusion Matrix\n\n|  | Predicted 0  | Predicted 1 |\n| --- | --- | --- |\n| Acutal 0 | 1662 | 39 |\n| Actual 1 | 27 | 298 |\n\n<br>\n\n- 이전보다 Recall이 매우 향상되었고, ROC-AUC는 0.9905으로 매우 높은 예측 성능을 보임","metadata":{}},{"cell_type":"code","source":"X_tr, X_val, y_tr, y_val = train_test_split(\n    X_train, y_train,\n    test_size=0.2,\n    stratify=y_train,\n    random_state=42\n)\n\n# Optuna 탐색 함수 정의\ndef objective(trial):\n    params = {\n        'objective': 'binary',\n        'metric': 'auc',\n        'boosting_type': 'gbdt',\n        'verbosity': -1,\n        'n_estimators': 1000,\n        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n        'max_depth': trial.suggest_int('max_depth', 3, 10),\n        'num_leaves': trial.suggest_int('num_leaves', 15, 100),\n        'min_child_samples': trial.suggest_int('min_child_samples', 10, 50),\n        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n        'random_state': 42,\n        'class_weight': 'balanced'\n    }\n\n    model = lgb.LGBMClassifier(**params)\n\n    model.fit(\n        X_tr, y_tr,\n        eval_set=[(X_val, y_val)],\n        eval_metric='auc',\n        callbacks=[\n            lgb.early_stopping(30, verbose=False),\n            lgb.log_evaluation(period=0)\n        ]\n    )\n\n    preds = model.predict_proba(X_val, num_iteration=model.best_iteration_)[:, 1]\n    auc = roc_auc_score(y_val, preds)\n    return auc\n\n# Optuna 고정\nsampler = TPESampler(seed=42)\n\n# Optuna 탐색 실행\nstudy = optuna.create_study(direction='maximize', study_name='lgbm_no_pruning', sampler=sampler)\nstudy.optimize(objective, n_trials=100, timeout=600)\n\n# 최적 파라미터 추출\nbest_params = study.best_params\nbest_params.update({\n    'objective': 'binary',\n    'metric': 'auc',\n    'n_estimators': 1000,\n    'random_state': 42,\n    'class_weight': 'balanced'\n})\n\n# 최종 모델 학습 (validation 포함)\nfinal_model = lgb.LGBMClassifier(**best_params)\nfinal_model.fit(\n    X_tr, y_tr,\n    eval_set=[(X_val, y_val)],\n    eval_metric='auc',\n    callbacks=[lgb.early_stopping(30)]\n)\n\n# 테스트 데이터 예측\nbest_iter = final_model.best_iteration_\ny_pred = final_model.predict(X_test, num_iteration=best_iter)\ny_prob = final_model.predict_proba(X_test, num_iteration=best_iter)[:, 1]\n\n# 평가 지표 출력\ncm = confusion_matrix(y_test, y_pred)\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\nplt.title(\"Confusion Matrix (Optuna-Tuned LightGBM)\")\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"Actual\")\nplt.show()\n\nprecision = precision_score(y_test, y_pred)\nrecall = recall_score(y_test, y_pred)\nf1 = f1_score(y_test, y_pred)\nauc = roc_auc_score(y_test, y_prob)\n\nprint(\"\\n--- Optuna-Tuned LightGBM (No Pruning) ---\")\nprint(f\"Best Iteration: {best_iter}\")\nprint(f\"Precision : {round(precision, 4)}\")\nprint(f\"Recall    : {round(recall, 4)}\")\nprint(f\"F1 Score  : {round(f1, 4)}\")\nprint(f\"ROC-AUC   : {round(auc, 4)}\")\n\nprint(\"\\nClassification Report:\\n\")\nprint(classification_report(y_test, y_pred, digits=4))\n\n# 최적 파라미터 출력\nprint(\"\\nBest Parameters from Optuna:\")\nfor k, v in best_params.items():\n    print(f\"{k}: {v}\")\n\n# 최적 파라미터 시도 출력\nprint(\"\\n Best Trial Parameters from Optuna\")\nprint(study.best_trial.number)\nprint(study.best_trial.params)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T07:01:34.536576Z","iopub.execute_input":"2025-08-10T07:01:34.53725Z","iopub.status.idle":"2025-08-10T07:02:01.548624Z","shell.execute_reply.started":"2025-08-10T07:01:34.53722Z","shell.execute_reply":"2025-08-10T07:02:01.547773Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 최종 파라미터에 의한 모델\nbest_params = {\n    'learning_rate': 0.19521278190900546,\n    'max_depth': 4,\n    'num_leaves': 64,\n    'min_child_samples': 11,\n    'subsample': 0.6115056095234841,\n    'colsample_bytree': 0.7865774715859445,\n    'objective': 'binary',\n    'metric': 'auc',\n    'random_state': 42,\n    'class_weight': 'balanced',\n    'n_estimators' : 1000,\n    'deterministic' : True,\n    'force_col_wise' : True,\n    'n_jobs' : 1\n}\n\n# 모델 정의\nlgbm2_model = lgb.LGBMClassifier(**best_params)\nlgbm2_model.fit(\n    X_train, y_train,\n    eval_set=[(X_test, y_test)],\n    eval_metric='auc',\n    callbacks=[lgb.early_stopping(30)]\n)\n\n# 테스트 예측\nbest_iter = lgbm2_model.best_iteration_\ny_pred = lgbm2_model.predict(X_test, num_iteration=best_iter)\ny_prob = lgbm2_model.predict_proba(X_test, num_iteration=best_iter)[:, 1]\n\n# 성능 평가\nprecision = precision_score(y_test, y_pred)\nrecall = recall_score(y_test, y_pred)\nf1 = f1_score(y_test, y_pred)\nauc = roc_auc_score(y_test, y_prob)\n\n# 결과 출력\nprint(\"\\n최종 LightGBM 모델 성능\")\nprint(f\"Precision      : {round(precision, 4)}\")\nprint(f\"Recall         : {round(recall, 4)}\")\nprint(f\"F1 Score       : {round(f1, 4)}\")\nprint(f\"ROC-AUC        : {round(auc, 4)}\")\nprint(\"\\nClassification Report:\\n\")\nprint(classification_report(y_test, y_pred, digits=4))\n\n# Confusion Matrix 시각화\ncm = confusion_matrix(y_test, y_pred)\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\nplt.title(\"Confusion Matrix (Final LightGBM Model)\")\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"Actual\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T07:02:01.549561Z","iopub.execute_input":"2025-08-10T07:02:01.54986Z","iopub.status.idle":"2025-08-10T07:02:02.077591Z","shell.execute_reply.started":"2025-08-10T07:02:01.549834Z","shell.execute_reply":"2025-08-10T07:02:02.076768Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 🔸 CatBoost\n\n<br>\n\n#### **성능 개선 여부 확인 모델**\n\n- 모델명\n    - CatBoost\n\n - CatBoost는 범주형데이터를 매핑하지않고 그대로 진행 (Education_Level, Income_Category 등 문자열 그대로)\n\n - Unknown데이터도 따로 인식해서 처리를 진행하므로 중간값으로 매핑하지않고 그대로 진행\n\n   \n\n- 적용 파라미터\n\n| 파라미터 | 설명 | 적용 값 | 적용 이유 |\n| --- | --- | --- | --- |\n| `iterations` | 트리의 개수 | 500 | 학습속도, 성능을 고려하여 적정값 배정 |\n| `learning_rate` | 학습률 | 0.05 | 안정성과 속도의 균형 맞춘 0.05 배정 |\n| `depth` | 트리 깊이 | 6 | 과적합 방지 + 적당한 복잡도 |\n| `random_state` | 랜덤 분할의 재현성을 위한 시드 값 | 42 | 숫자의 크기와는 무관 |\n| `verbose` | 로그 출력 빈도 | 50 | 학습진행상황 확인용 |\n\n<br>\n\n- 사용 이유\n    - 범주형 변수 자동 인식 기능으로 별도의 인코딩 없이 모델 학습이 가능해 전처리 부담이 적음\n    - 수치형·범주형 변수 모두를 효율적으로 처리할 수 있어 다양한 변수 특성을 반영한 예측이 가능함\n    - 다른 트리 기반 모델 대비 높은 예측 성능과 빠른 학습 속도를 동시에 제공함\n    - 변수 중요도 및 SHAP 값 시각화를 통해 모델 해석이 가능해 인사이트 도출에 유리함\n    - 하이퍼파라미터 튜닝에 유연하며, 실무 적용 시 안정적인 baseline 이상의 성능을 보여줌\n\n<br>\n\n---\n\n<br>\n\n#### **성능 검증**\n\n- 선택 지표 성능\n\n| 지표 | Catboost | Base Line Model |\n| --- | --- | --- |\n| **Precision (Class 1)** | 0.9588 | 0.5117 |\n| **Recall (Class 1)** | 0.8585 | 0.8092 |\n| **F1 Score** | 0.9058 | 0.6315 |\n| **ROC-AUC** | 0.9934 | 0.9174 |\n    \n- Confusion Matrix\n\n| | Predicted 0  | Predicted 1 |\n| --- | --- | --- |\n| Acutal 0 | 1689 | 12 |\n| Actual 1 | 46 | 279 |\n\n- Precision (Class 1)은 0.9588로 Base Line 대비 +44.7%p 향상되어 이탈 고객을 정확히 식별하는 능력이 대폭 향상\n- Recall (Class 1)은 0.8585로 Base Line 대비 +4.9%p 개선되어 이탈 고객을 놓치지 않고 탐지하는 성능 강화\n- F1 Score는 0.9058로 Base Line 대비 약 +27.4%p 상승, Precision과 Recall이 모두 개선된 균형 잡힌 성능 향상을 확인\n- ROC-AUC는 0.9934로 Base Line 대비 +7.6%p 향상되어 모델의 전반적인 분류 성능이 강화되었음을 의미함\n\n- Confusion Matrix 분석 결과 <br>\n  → False Negative (FN) 수가 62 → 46명으로 감소하여 실제 이탈 고객 포착 능력이 개선됨 <br>\n  → False Positive (FP) 수 역시 245 → 12명으로 급감하여 불필요한 오탐지를 크게 줄임 <br>\n\n전반적으로 CatBoost는 Base Line(Logistic Regression) 대비 모든 주요 지표에서 우수한 성능을 보였으며, <br>\n범주형 변수 자동 인식 및 처리 기능의 장점이 실제 모델 성능 향상에 크게 기여했음을 확인함","metadata":{}},{"cell_type":"code","source":"numeric_features = ['Customer_Age', 'Dependent_count', 'Months_on_book', 'Total_Relationship_Count', \n                    'Months_Inactive_12_mon', 'Contacts_Count_12_mon', 'Credit_Limit', 'Total_Revolving_Bal', \n                    'Avg_Open_To_Buy', 'Total_Amt_Chng_Q4_Q1', 'Total_Trans_Amt', 'Total_Trans_Ct', 'Total_Ct_Chng_Q4_Q1', \n                    'Avg_Utilization_Ratio','Engagement_Score']\n\ncategoric_features = ['Gender', 'Marital_Status', 'Education_Level', 'Income_Category', 'Card_Category']\n\ncatboost_features = numeric_features + categoric_features\n\n# 데이터 정의\nX = df_feature[catboost_features]\ny = df_feature['is_churn']\n\n# 데이터 분할\nX_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n\n# Pool 객체 생성\ntrain_pool = Pool(X_train, y_train, cat_features=categoric_features)\ntest_pool = Pool(X_test, y_test, cat_features=categoric_features)\n\nmodel = CatBoostClassifier(\n    iterations=500,\n    learning_rate=0.05,\n    depth=6,\n    random_state=42,\n    verbose=50\n)\nmodel.fit(train_pool)\n\ny_pred = model.predict(test_pool)\ny_prob = model.predict_proba(test_pool)[:, 1]\n\nprint(f\"Precision: {round(precision_score(y_test, y_pred), 4)}\")\nprint(f\"Recall: {round(recall_score(y_test, y_pred), 4)}\")\nprint(f\"F1 Score: {round(f1_score(y_test, y_pred), 4)}\")\nprint(f\"ROC-AUC: {round(roc_auc_score(y_test, y_prob), 4)}\")\n\nprint(\"\\nClassification Report:\\n\")\nprint(classification_report(y_test, y_pred, digits=4))\n\ncm = confusion_matrix(y_test, y_pred)\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm)\ndisp.plot(cmap='Blues')\nplt.title(\"CatBoost - Confusion Matrix\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T07:02:02.078493Z","iopub.execute_input":"2025-08-10T07:02:02.078873Z","iopub.status.idle":"2025-08-10T07:02:09.062306Z","shell.execute_reply.started":"2025-08-10T07:02:02.078853Z","shell.execute_reply":"2025-08-10T07:02:09.061408Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 🔸 Catboost 성능 개선\n\n<br>\n\n- **Catboost 성능 개선을 위한 방법(1): Early Stopping**\n\n    <br>\n\n    - 사용한 방법\n        - Early Stopping\n            - 모델 훈련 중 검증 성능이 더 이상 향상되지 않을 때 학습을 조기 종료하는 기법\n            - 주로 검증 데이터셋의 loss나 metric을 기준으로 판단\n            - 일정 patience동안 성능 향상이 없으면 멈춤\n             \n      <br>\n\n    - 사용 이유\n        - 과적합 방지: 기존 모델은 훈련 데이터에 너무 오래 학습되어 일반화 성능이 떨어짐\n        - 훈련 시간 단축: 최적 지점에서 자동으로 종료되어 불필요한 반복 제거\n        - 모델선택기준 자동화: best_iteration 값을 저장하여 성능이 가장 좋은 시점의 모델만 추출가능\n\n<br>\n\n---\n\n<br>\n        \n- **Catboost 성능 개선을 위한 방법 (2): 파라미터 조정 (Optuna)**\n\n    <br>\n\n    - 사용한 방법\n        - Optuna\n            - 베이직한 최적화 기반의 탐색 방식으로 하이퍼파라미터 자동 탐색을 위한 라이브러리\n            - 모델 성능을 가장 좋게 만드는 파라미터 조합을 자동으로 탐색\n \n    <br>\n\n    - 사용 이유\n        - 불필요한 조합을 시도하지 않아 시간을 단축함\n        - 과거 시도 결과를 기반으로 다음 조합을 결정하여 성능 향상을 노릴 수 있음\n        - 자동 반복과 조기 종료가 가능하여 효율적\n        - 과적합 방지를 위한 early_stopping과의 조합이 필수적임\n<br>\n\n---\n\n<br>\n        \n- **Catboost 성능 개선을 위한 방법 (3): threshold 조정**\n\n    <br>\n\n    - 사용한 방법\n        - threshold 범위 조정\n            - 기존 threshold 0.5에서 ~ 0.7 까지 조정 진행 후 결과비교\n            - 비교결과 threshold가 높아질수록 Precision ↑, Recall ↓ 진행되며, 최종 threshold 0.55 선정\n \n    <br>\n\n    - 사용 이유\n        - 이진분류 결과의 기준 조정\n        - Precision vs Recall 간 Trade-off 조절\n        - 모델 평가지표 최적화\n\n<br>\n\n---\n\n<br>\n\n- 파라미터 탐색표\n\n| 파라미터명                     | 설명                                   | 영향                                                 |\n| ------------------------- | ------------------------------------ | -------------------------------------------------- |\n| **`iterations`**          | 부스팅 반복 횟수 (트리 개수)                    | 너무 작으면 언더피팅, 너무 크면 과적합 가능. `early_stopping`과 함께 조절 |\n| **`depth`**               | 트리의 최대 깊이                            | 깊을수록 복잡한 패턴을 학습하지만 과적합 위험 증가. 일반적으로 3\\~10 사이       |\n| **`learning_rate`**       | 학습률                                  | 작을수록 학습은 느리지만 안정적. 클수록 빠르게 수렴하나 불안정 가능             |\n| **`l2_leaf_reg`**         | L2 정규화 계수 (leaf-wise regularization) | 클수록 과적합 방지. 모델 일반화에 도움                             |\n| **`random_strength`**     | 분할 점수를 섞는 데 사용되는 랜덤 노이즈의 세기          | 값이 클수록 과적합 방지. 너무 크면 underfitting 가능               |\n| **`border_count`**        | 수치형 변수를 이산화할 때 사용하는 경계 개수            | 많을수록 복잡한 분할 가능. 과적합 위험 존재                          |\n| **`bagging_temperature`** | 샘플링 시 사용되는 온도값                       | 0이면 균등 샘플링, 클수록 희귀 케이스 강조. 과적합 방지에 도움              |\n| **`eval_metric`**         | 모델 평가 지표                             | 최적화를 위해 사용할 평가지표. 여기서는 F1-score 기준                 |\n| **`auto_class_weights`**  | 불균형 클래스 자동 가중치 조정                    | 'Balanced' 설정 시 소수 클래스에 가중치 부여 → Recall 향상 가능      |\n| **`random_seed`**         | 랜덤 시드                                | 결과 재현성 확보                                          |\n| **`verbose`**             | 로그 출력 간격                             | 학습 로그 출력 주기. 수치 클수록 출력 빈도 낮음 (ex: 100 = 100회마다 출력) |\n\n\n<br>\n\n---\n\n<br>\n\n- **파라미터 적용 LightGBM**\n\n    <br>\n\n    - 모델명\n        - LightGBM\n     \n    <br>\n\n- 적용 파라미터\n             \n| 파라미터명                     | 적용값      | 설명                | 영향                            |\n| ------------------------- | -------- | ----------------- | ----------------------------- |\n| **`iterations`**          | 424      | 부스팅 반복 횟수         | 트리 수. 작으면 언더피팅, 크면 과적합 가능     |\n| **`depth`**               | 4        | 트리 최대 깊이          | 깊을수록 복잡한 패턴 학습. 과적합 위험 존재     |\n| **`learning_rate`**       | 0.0994   | 학습률 (0.01 \\~ 0.3) | 작을수록 안정적이지만 느림. 너무 크면 불안정     |\n| **`l2_leaf_reg`**         | 8.2790   | L2 정규화 계수         | 클수록 과적합 방지. 모델 일반화에 도움        |\n| **`random_strength`**     | 0.0019   | 노이즈 기반 분할점 랜덤성    | 클수록 분산 증가 → 과적합 방지 효과         |\n| **`border_count`**        | 219      | 수치형 변수 이산화 경계 수   | 많을수록 정밀한 분할 가능. 과적합 위험 증가     |\n| **`bagging_temperature`** | 0.4744   | 샘플링 편향 정도 조절      | 클수록 드문 샘플 강조. 과적합 방지에 도움      |\n| **`eval_metric`**         | F1       | 평가 지표             | F1-score 기준으로 모델 최적화          |\n| **`auto_class_weights`**  | Balanced | 클래스 불균형 자동 보정     | 소수 클래스에 가중치 부여하여 Recall 향상 가능 |\n| **`random_seed`**         | 42       | 랜덤 시드             | 실험 재현성 확보                     |\n| **`verbose`**             | 100      | 출력 주기             | 학습 로그 출력 빈도 설정 (100번마다 출력)    |\n\n\n<br>\n\n- 선택 지표 성능\n\n| 지표 | 값 | 기존 Catboost | Base Line |\n| --- | --- | --- | --- |\n| **Precision** | 0.8571 | 0.9588 | 0.5117 |\n| **Recall** | 0.9231 | 0.8585 | 0.8092 |\n| **F1 Score** | 0.8889 | 0.9058 | 0.6315 |\n| **ROC-AUC** | 0.9915 | 0.9934 | 0.9174 |\n\n<br>\n\n- Confusion Matrix\n\n|  | Predicted 0  | Predicted 1 |\n| --- | --- | --- |\n| Acutal 0 | 1651 | 50 |\n| Actual 1 | 25 | 300 |\n\n<br>\n\n- Precision 손실이 있는 대신 이탈 고객을 더 많이 포착하는 방향으로 모델이 조정됨\n\n- F1 Score는 약간 하락했지만, 비즈니스 목표(Recall 우선 / 이탈 포착 중점)에 부합하는 방향성","metadata":{}},{"cell_type":"code","source":"# Optuna 최적 파라미터 탐색\ndef objective(trial):\n    params = {\n        \"iterations\": trial.suggest_int(\"iterations\", 100, 500),\n        \"depth\": trial.suggest_int(\"depth\", 4, 10),\n        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-3, 0.1, log=True),\n        \"l2_leaf_reg\": trial.suggest_float(\"l2_leaf_reg\", 1.0, 10.0),\n        \"random_strength\": trial.suggest_float(\"random_strength\", 1e-3, 1.0, log=True),\n        \"border_count\": trial.suggest_int(\"border_count\", 32, 255),\n        \"bagging_temperature\": trial.suggest_float(\"bagging_temperature\", 0.0, 1.0)\n    }\n\n    model = CatBoostClassifier(\n        **params,\n        verbose=0,\n        early_stopping_rounds=50,\n        auto_class_weights='Balanced',\n        random_state=42\n    )\n\n    model.fit(train_pool, eval_set=test_pool)\n    y_pred = model.predict(X_test)\n\n    return f1_score(y_test, y_pred)\n\nstudy = optuna.create_study(direction=\"maximize\")\nstudy.optimize(objective, n_trials=50)\n\nprint(\"Best Params:\", study.best_params)\nprint(\"Best F1 Score:\", study.best_value)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T07:02:09.063268Z","iopub.execute_input":"2025-08-10T07:02:09.063601Z","iopub.status.idle":"2025-08-10T07:05:44.457312Z","shell.execute_reply.started":"2025-08-10T07:02:09.063572Z","shell.execute_reply":"2025-08-10T07:05:44.456519Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 데이터 정의\nX = df_feature[catboost_features]\ny = df_feature['is_churn']\n\n# 데이터 분할\nX_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n\n# Pool 객체 생성\ntrain_pool = Pool(X_train, y_train, cat_features=categoric_features)\ntest_pool = Pool(X_test, y_test, cat_features=categoric_features)\n\n# 파라미터 설정 (Optuna결과 기반)\nbest_params = {\n    'iterations': 424,\n    'depth': 4,\n    'learning_rate': 0.09939714389022081,\n    'l2_leaf_reg': 8.279034253764316,\n    'random_strength': 0.0019246462632687622,\n    'border_count': 219,\n    'bagging_temperature': 0.474382640381189,\n    'eval_metric': 'F1',\n    'verbose': 100,\n    'random_seed': 42,\n    'auto_class_weights': 'Balanced'\n}\n\nmodel = CatBoostClassifier(**best_params)\n\nmodel.fit(\n    train_pool,\n    eval_set=test_pool,\n    early_stopping_rounds=50,\n    use_best_model=True\n)\n\n# 예측 확률\ny_prob = model.predict_proba(X_test)[:, 1]\n\n# threshold (0.5 ~ 0.7 사이로 조정, 최적값 탐색)\nthreshold = 0.55\ny_pred = (y_prob >= threshold).astype(int)\n\nprint(f\"Threshold: {threshold}\")\nprint(f\"Precision: {round(precision_score(y_test, y_pred), 4)}\")\nprint(f\"Recall: {round(recall_score(y_test, y_pred), 4)}\")\nprint(f\"F1 Score: {round(f1_score(y_test, y_pred), 4)}\")\nprint(f\"ROC-AUC: {round(roc_auc_score(y_test, y_prob), 4)}\")\n\nprint(\"\\nClassification Report:\\n\")\nprint(classification_report(y_test, y_pred, digits=4))\n\ncm = confusion_matrix(y_test, y_pred)\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm)\ndisp.plot(cmap='Blues')\nplt.title(f\"CatBoost - Confusion Matrix (Threshold={threshold})\")\n\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T07:05:44.458274Z","iopub.execute_input":"2025-08-10T07:05:44.459078Z","iopub.status.idle":"2025-08-10T07:05:45.969192Z","shell.execute_reply.started":"2025-08-10T07:05:44.459052Z","shell.execute_reply":"2025-08-10T07:05:45.968333Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### **🔸 최종 모델선정 : Catboost (파라미터 조정)**\n\n| **모델** | **Precision** | **Recall** | **F1 Score** | **ROC-AUC** | **특이점** |\n| --- | --- | --- | --- | --- | --- |\n| **Logistic Regression (Base Line)** | 0.5117 | 0.8092 | 0.6315 | 0.9174 | 전체적으로 성능이 나쁘지는 않으나, 아쉬운 성능 |\n| **SVM (Margin Base)** | 0.6793 | 0.88 | 0.7668 | 0.9573 | 베이스 라인 모델보다 성능이 향상된 모델 그러나 여전히 전체적인 성능이 아쉬움 |\n| **Random Forest** | 0.9228 | 0.7354 | 0.8185 | 0.9854 | 다른 모델들에 비해 매우 향상된 성능 Precision과 ROC-AUC Score가 매우 뛰어남 |\n| **LightGBM** | 0.8746 | 0.9015 | 0.8879 | 0.9918 | 이전 모델들 보다 모든 성능에서 우수함 Precision 성능이 다소 떨어지긴 했으나, Recall을 중점으로 볼 때 매우 우수한 성능을 보임 |\n| **LightGBM (파라미터 조정)** | 0.8843 | 0.9169 | 0.9003 | 0.993 | 성능 개선 후, 모든 지표가 0.9 이상의 성능을 보임. ROC-AUC Score가 매우 우수하고, 모든 지표의 균형이 우수함 |\n| **Catboost** | **0.9588** | 0.8585 | **0.9058** | **0.9934** | 튜닝된 LGBM에 비해 Recall을 제외한 다른 성능이 더 우수함 |\n| **최종: Catboost (파라미터 조정)** | 0.8571 | **0.9231** | 0.8889 | 0.9915 | 기존 Catboost에 비해 Precision을 떨어트리고 Recall을 상승 시킴 → 전체적인 성능이 뛰어나고, 무엇보다 Recall 성능이 가장 높음 |\n\n<br>\n\n---","metadata":{}},{"cell_type":"markdown","source":"## **🔹 최종 모델해석 및 Feature Selection**\n- 모델 해석(SHAP)\n- 변수선택 (Feature Selection) \n---\n\n<br>\n\n### **🔸 모델 해석(SHAP)**\n\n- 모델의 각 Feature가 예측 결과에 얼마나 기여했는지를 수치적으로 보여 주는 해석 방법  <br>\n- 모델이 어떤 Feature들의 영향으로 이탈을 예측했는지 해석하기 위해 사용  <br>\n- Feature Selection을 위한 중요도 분석용으로 사용  <br>\n- Summary Plot에서 중요도 기준 상위 10개의 변수를 선택  <br>\n- 기존 최종 모델에 선택된 변수들만으로 성능 재점검  <br><br>\n\n### **🔸 변수선택(Feature Selection)**\n\n중요도 기준 상위 10개 변수 <br>\n`Total_Trans_Ct`, `Total_Trans_Amt`, `Total_Revolving_Bal`, `Total_Ct_Chng_Q4_Q1`, `Total_Relationship_Count`,  <br>\n`Months_Inactive_12_mon`, `Total_Amt_Chng_Q4_Q1`, `Engagement_Score`, `Contacts_Count_12_mon`, `Customer_Age`\n\n<br>\n\n#### 성능 점검 결과\n\n| 지표 | Feature Selection | 전체 Feature |\n| --- | --- | --- |\n| Precision | 0.8674 | 0.8571 |\n| Recall | 0.9262 | 0.9231 |\n| F1 Score | 0.8958 | 0.8889 |\n| ROC-AUC | 0.9909 | 0.9915 |\n\n<br>\n\n- ROC-AUC를 제외한 전체적인 성능이 오히려 향상했으며, ROC-AUC 역시 큰 차이를 보이지 않고 있음\n- 해당 변수들로 모델 변수를 축소하여도 아무런 문제가 없음을 확인함\n\n---","metadata":{}},{"cell_type":"markdown","source":"#### 🔸 **모델 해석(SHAP)**","metadata":{}},{"cell_type":"code","source":"# SHAP을 통한 주요 변수 확인\nexplainer = shap.TreeExplainer(model)\nshap_values = explainer.shap_values(X_train)\n\nshap.summary_plot(shap_values, X_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T07:05:45.975097Z","iopub.execute_input":"2025-08-10T07:05:45.975617Z","iopub.status.idle":"2025-08-10T07:05:47.847288Z","shell.execute_reply.started":"2025-08-10T07:05:45.975593Z","shell.execute_reply":"2025-08-10T07:05:47.846415Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# SHAP 중요도 기준 상위 10개의 변수 선택\ntop_features = [\n    'Total_Trans_Ct', 'Total_Trans_Amt', 'Total_Revolving_Bal', 'Total_Ct_Chng_Q4_Q1', 'Total_Relationship_Count',\n    'Months_Inactive_12_mon', 'Total_Amt_Chng_Q4_Q1', 'Engagement_Score', 'Contacts_Count_12_mon', 'Customer_Age'\n]\n\n# feature selection 후 모델 성능 재점검\n# 데이터 정의\nX = df_feature[top_features]\ny = df_feature['is_churn']\n\n# 데이터 분할\nX_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n\n# Pool 객체 생성\ntrain_pool = Pool(X_train, y_train)\ntest_pool = Pool(X_test, y_test)\n\n# 파라미터 설정 (Optuna결과 기반)\nbest_params = {\n    'iterations': 424,\n    'depth': 4,\n    'learning_rate': 0.09939714389022081,\n    'l2_leaf_reg': 8.279034253764316,\n    'random_strength': 0.0019246462632687622,\n    'border_count': 219,\n    'bagging_temperature': 0.474382640381189,\n    'eval_metric': 'F1',\n    'verbose': 100,\n    'random_seed': 42,\n    'auto_class_weights': 'Balanced'\n}\n\nmodel = CatBoostClassifier(**best_params)\n\nmodel.fit(\n    train_pool,\n    eval_set=test_pool,\n    early_stopping_rounds=50,\n    use_best_model=True\n)\n\n# 예측 확률\ny_prob = model.predict_proba(X_test)[:, 1]\n\n# threshold (0.5 ~ 0.7 사이로 조정, 최적값 탐색)\nthreshold = 0.55\ny_pred = (y_prob >= threshold).astype(int)\n\nprint(f\"Threshold: {threshold}\")\nprint(f\"Precision: {round(precision_score(y_test, y_pred), 4)}\")\nprint(f\"Recall: {round(recall_score(y_test, y_pred), 4)}\")\nprint(f\"F1 Score: {round(f1_score(y_test, y_pred), 4)}\")\nprint(f\"ROC-AUC: {round(roc_auc_score(y_test, y_prob), 4)}\")\n\nprint(\"\\nClassification Report:\\n\")\nprint(classification_report(y_test, y_pred, digits=4))\n\ncm = confusion_matrix(y_test, y_pred)\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm)\ndisp.plot(cmap='Blues')\nplt.title(f\"CatBoost - Confusion Matrix (Threshold={threshold})\")\n\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T07:05:47.848311Z","iopub.execute_input":"2025-08-10T07:05:47.848648Z","iopub.status.idle":"2025-08-10T07:05:48.993888Z","shell.execute_reply.started":"2025-08-10T07:05:47.848623Z","shell.execute_reply":"2025-08-10T07:05:48.993022Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### **🔸 변수선택(Feature Selection)**\n\n#### 변수 선택 및 전처리 흐름 정리\n\n- **1. 상관관계 분석 (Top 10 변수 기준)**  \n  → `heatmap`을 통해 변수 간 상관관계를 시각화하고,  \n  → **0.7 이상 상관관계가 높은 변수들 중 일부를 제거**하여 중복 정보 줄임 (`Total_Trans_Amt` 제거)\n\n- **2. 주요 변수 리스트 확정**  \n  → 도출된 변수 중요도 + 상관관계 고려하여  \n  → 총 9개 변수(`cluster_features`)를 클러스터링에 사용할 주요 변수로 선정\n\n- **3. 클러스터링용 데이터 준비**  \n  → 선택된 변수만 추출하여 `X_cluster` 구성\n","metadata":{}},{"cell_type":"code","source":"# 변수 선정을 위한 상관관계 확인\nplt.figure(figsize=(10,8))\nsns.heatmap(df_feature[top_features].corr().abs(), annot=True, cmap='RdYlBu_r', vmin=0, vmax=1)\nplt.title(\"Correlation by Top Features\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T07:05:48.994885Z","iopub.execute_input":"2025-08-10T07:05:48.995196Z","iopub.status.idle":"2025-08-10T07:05:49.920658Z","shell.execute_reply.started":"2025-08-10T07:05:48.995167Z","shell.execute_reply":"2025-08-10T07:05:49.91978Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ▶ 사용할 주요 변수 리스트 (이미 뽑은 Top 10 변수 중 상관관계 높은 변수들(0.7 이상) 제거)\ncluster_features = [\n    'Total_Trans_Ct',\n    'Total_Revolving_Bal',\n    'Total_Ct_Chng_Q4_Q1',\n    'Total_Relationship_Count',\n    'Months_Inactive_12_mon',\n    'Total_Amt_Chng_Q4_Q1',\n    'Engagement_Score',\n    'Contacts_Count_12_mon',\n    'Customer_Age'\n]\n\n# ▶ 선택된 변수만 추출 (df_feature는 기존 최종 데이터프레임)\nX_cluster = df_feature[cluster_features].copy()\n\n# ▶ 이탈 확률('churn_probability', %) 추가\nX_cluster['churn_probability'] = model.predict_proba(df_feature[top_features])[:,1]\ndf_feature['churn_probability'] = model.predict_proba(df_feature[top_features])[:,1]\ncluster_features.append('churn_probability')\n\n\nX_cluster.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T07:05:49.921663Z","iopub.execute_input":"2025-08-10T07:05:49.921919Z","iopub.status.idle":"2025-08-10T07:05:49.947624Z","shell.execute_reply.started":"2025-08-10T07:05:49.921899Z","shell.execute_reply":"2025-08-10T07:05:49.946927Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 📃 Process Insight - 이탈예측 모델링\n---\n```\n다양한 모델(Logistic Regression, SVM, Random Forest, LightGBM, CatBoost 등)을 비교 분석한 결과 CatBoost(하이퍼파라미터 튜닝 적용) 모델이 가장 균형잡힌 성능(Precision 0.8571 / Recall 0.9231 / F1 Score 0.8889) 을 보여 최종 예측모델로 선정함.\n(특히 Recall(이탈 고객 탐지율) 이 가장 높은 모델로, 본 프로젝트의 목적(이탈 고객 조기 탐지)에 부합하는 선택임)\n```\n\n```\n모델 해석을 위해 SHAP(Shapley Additive exPlanations) 분석을 진행하였고, 이를 통해 고객 이탈에 영향을 미치는 주요 변수를 도출함\n가장 영향력이 큰 변수는 `Total_Trans_Ct`, `Total_Trans_Amt`, `Total_Revolving_Bal` 등 거래 및 활동성 관련 지표로 확인됨\n```\n\n```\n이후 클러스터링을 위한 Feature Selection 과정에서는\n상관관계 분석(heatmap) 을 통해 중복 정보를 줄이고, 상위 변수 중 상관계수가 높은 Total_Trans_Amt를 제외\n```\n```\n최종적으로 Total_Trans_Ct, Total_Revolving_Bal, Total_Ct_Chng_Q4_Q1 등 총 9개 변수(cluster_features) 를 클러스터링에 사용할 주요 변수로 확정함\n이탈 예측값(churn_probability)은 최종 모델의 .predict_proba() 결과를 활용해 산출하였으며, 해당 확률은 이후 위험군 분류 및 세부 클러스터링에 보조지표로 활용될 예정\n```","metadata":{}},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"# ✔ Process 03 - Clustering\n\n- 주요 변수 Scaling\n    - 핵심변수 분포확인\n    - 분포확인후 변수 Scaling (Robust, Standard, MinMax(sqrt), MinMax)\n    - Scaling 이후 변수별 분포 확인\n- Clustering\n    - 행동패턴 파악을 위한 Churn-probability 가중치 부여\n    - 적정 K값 탐색\n        - Elbow Method\n        - Silhouette Score\n    - Clustering (Kmeans)\n    - 클러스터링 분포 시각화\n        - PCA\n        - T-SNE\n    - 클러스터 기반 이탈 리스크 분석\n        - 클러스터별 실제 이탈률, 예측 이탈확률 비교\n        - 클러스터별 예측 이탈 확률 분포 시각화 (Violin Plot)\n        - 클러스터별 예측 이탈 확률 분포 + 실제 이탈자 표시 시각화\n- 클러스터별 패턴분석\n    - Radar Chart\n    - 클러스터 별 평균 변수 값 확인\n    - 클러스터 별 변수 별 분포 확인\n- 고위험군 세부 클러스터링\n    - 이탈확률 제거 및 Clustering\n    - 고위험군 대상 행동 기반 세부 세그먼트 분석\n    - 세부 클러스터 주요 변수 패턴 분석\n---","metadata":{}},{"cell_type":"markdown","source":"## 🔹 **주요 변수 Scaling**\n- 핵심변수 분포확인\n- 분포확인후 변수 Scaling (Robust, Standard, MinMax(sqrt), MinMax)\n- Scaling 이후 변수별 분포 확인","metadata":{}},{"cell_type":"markdown","source":"### **🔸 이탈고객과 유지고객 분리**\n```\n이탈 고객을 하나의 클러스터로 취급하고 유지 고객에 대해 클러스터링을 실행\n-> 이탈 확률에 가중치를 부여하여 이탈 확률 기준으로 유지 고객에 대한 클러스터링\n-> 이탈 확률이 확실하게 높은 클러스터와 이탈 확률이 확실하게 낮은 클러스터를 대상으로 이탈 확률을 제외한 세부 클러스터링 진행\n-> 이후 클러스터 별 분포를 비교하여 이상 패턴을 보이는 클러스터를 대상으로 정상 클러스터, 이탈 클러스터와 비교\n-> 만약 이탈 클러스터와 분포가 비슷하다면 \n```","metadata":{}},{"cell_type":"code","source":"# 유지자 대상 클러스터링 용 데이터프레임 생성\ndf_cluster_Existing = df_feature[df_feature['Attrition_Flag'] == 'Existing Customer']\ndf_cluster_Existing.head()\nX_cluster_Existing = df_cluster_Existing[cluster_features].copy()\nX_cluster_Existing.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T07:05:49.948544Z","iopub.execute_input":"2025-08-10T07:05:49.948836Z","iopub.status.idle":"2025-08-10T07:05:49.96703Z","shell.execute_reply.started":"2025-08-10T07:05:49.948808Z","shell.execute_reply":"2025-08-10T07:05:49.966188Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### **🔸 핵심 변수 분포확인**\n- 각 변수별 Histogram 및 Boxplot 분포확인을 진행하여 변수 별 특성확인\n- 변수 분포특성 별 Scaling 방법 결정","metadata":{}},{"cell_type":"code","source":"# ▶ Scaler 조정을 위해 각 변수 별 분포를 확인\nplt.figure(figsize=(15, len(cluster_features)*4))\n\nfor i, var in enumerate(cluster_features, 1):\n    plt.subplot(len(cluster_features), 2, 2*i-1)\n    plt.hist(X_cluster_Existing[var], bins=30, color='skyblue', edgecolor='black')\n    plt.title(f'Histogram of {var}')\n\n    plt.subplot(len(cluster_features), 2, 2*i)\n    sns.boxplot(x=X_cluster_Existing[var], color='lightgreen')\n    plt.title(f'Boxplot of {var}')\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T07:05:49.967872Z","iopub.execute_input":"2025-08-10T07:05:49.968139Z","iopub.status.idle":"2025-08-10T07:05:54.8078Z","shell.execute_reply.started":"2025-08-10T07:05:49.968118Z","shell.execute_reply":"2025-08-10T07:05:54.807007Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### **🔸 분포확인후 변수 Scaling** <br>\n\n#### 1. **RobustScaler 적용 : 이상치가 많거나 편향이 심한 변수** <br>\n`Total_Trans_Ct`, `Total_Revolving_Bal`, `Total_Amt_Chng_Q4_Q1`, `Contacts_Count_12_mon`, `Total_Ct_Chng_Q4_Q1`\n#### 2. **StandardScaler 적용 : 이상치가 적고 정규 분포에 가까운 변수**<br>\n`Customer_Age`\n#### 3. **MinMax(sqrt) 적용 : 이상치가 적거나 없으나 값의 치우침이 명확한 변수 혹은 이산형 변수**<br>\n`Engagement_Score`\n#### 4. **MinMax 적용 : 이상치나 값의 치우침이 거의 없는 이산형 변수**<br>\n`Total_Relationship_Count`, `Months_Inactive_12_mon`\n<br><br>\n#### ➡️ 스케일링 이후, 전체 스케일링 된 변수의 범위통일을 위한 MinMax적용","metadata":{}},{"cell_type":"code","source":"# 이상치가 많거나 편향이 심한 변수 -> RobustScaler\nrobust = ['Total_Trans_Ct', 'Total_Revolving_Bal', 'Total_Amt_Chng_Q4_Q1', 'Contacts_Count_12_mon', 'Total_Ct_Chng_Q4_Q1']\n\n# 이상치가 적고 정규 분포에 가까운 변수 -> StandardScaler\nstandard = ['Customer_Age']\n\n# 이상치가 적거나 없으나 값의 치우침이 명확한 변수 혹은 이산형 변수 -> 루트 MinMax\nsqrt = ['Engagement_Score']\n\n# 이상치나 값의 치우침이 거의 없는 이산형 변수 -> MinMax\nminmax = ['Total_Relationship_Count', 'Months_Inactive_12_mon']\n\n# 전체 스케일링된 변수를 범위를 맞추기 위해 MinMax\nfinal_scaler = MinMaxScaler()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T07:05:54.808786Z","iopub.execute_input":"2025-08-10T07:05:54.809028Z","iopub.status.idle":"2025-08-10T07:05:54.813723Z","shell.execute_reply.started":"2025-08-10T07:05:54.809008Z","shell.execute_reply":"2025-08-10T07:05:54.812813Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 스케일링 진행\n\nscalers = {\n    'robust':RobustScaler(),\n    'standard':StandardScaler(),\n    'minmax':MinMaxScaler()\n}\n\nX_scaled = pd.DataFrame(index=X_cluster_Existing.index)\nX_scaled[robust] = scalers['robust'].fit_transform(X_cluster_Existing[robust])\nX_scaled[standard] = scalers['standard'].fit_transform(X_cluster_Existing[standard])\nsqrt_scaled = np.sqrt(X_cluster_Existing[sqrt])\nX_scaled[sqrt] = scalers['minmax'].fit_transform(sqrt_scaled)\nX_scaled[minmax] = scalers['minmax'].fit_transform(X_cluster_Existing[minmax])\n\nX_scaled_final = X_scaled.copy()\ncols_to_minmax = list(set(robust+standard) - set(sqrt + minmax))\nX_scaled_final[cols_to_minmax] = MinMaxScaler().fit_transform(X_scaled[cols_to_minmax])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T07:05:54.814755Z","iopub.execute_input":"2025-08-10T07:05:54.81552Z","iopub.status.idle":"2025-08-10T07:05:54.860177Z","shell.execute_reply.started":"2025-08-10T07:05:54.815491Z","shell.execute_reply":"2025-08-10T07:05:54.859392Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### **🔸 Scaling 이후 변수별 분포확인**\n```\n각 핵심변수의 분포 특성을 파악 후 분포상태에 맞춘 Scaling 적용\n이후 변수별 Scaling 결과를 보기위하여 함수를 이용한 각 변수별 분포 재확인 진행\n```","metadata":{}},{"cell_type":"code","source":"print((X_scaled_final < 0).sum())\nprint((X_scaled_final > 1.0 + 1e-8).sum())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T07:05:54.861124Z","iopub.execute_input":"2025-08-10T07:05:54.861599Z","iopub.status.idle":"2025-08-10T07:05:54.869011Z","shell.execute_reply.started":"2025-08-10T07:05:54.861572Z","shell.execute_reply":"2025-08-10T07:05:54.868327Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for col in X_scaled_final.columns:\n    plt.figure(figsize=(10,6))\n    sns.kdeplot(X_scaled[col], label='Before MinMax', fill=True)\n    sns.kdeplot(X_scaled_final[col], label='After MinMax', fill=True)\n    plt.title(f\"{col} Distribution Comparison\")\n    plt.legend()\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T07:05:54.869786Z","iopub.execute_input":"2025-08-10T07:05:54.870034Z","iopub.status.idle":"2025-08-10T07:05:58.616873Z","shell.execute_reply.started":"2025-08-10T07:05:54.870009Z","shell.execute_reply":"2025-08-10T07:05:58.616011Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 🔹 **Clustering**\n- Churn-probability 가중치 부여\n- 적정 K값 탐색\n    - Elbow Method\n    - Silhouette Score\n- Clustering (Kmeans)\n- 클러스터링 분포 시각화\n    - PCA\n    - T-SNE\n- 클러스터 기반 이탈 리스크 분석\n    - 클러스터별 실제 이탈률, 예측 이탈확률 비교\n    - 클러스터별 예측 이탈 확률 분포 시각화 (Violin Plot)\n    - 클러스터별 예측 이탈 확률 분포 + 실제 이탈자 표시 시각화\n\n<!-- ### __Elbow Method와 Silhouette Score를 활용한 클러스터 수 결정 흐름__\n\n#### 1. Elbow Method 실행\n\n  - k를 1부터 10까지 바꿔가며 KMeans를 학습하고, 각 군집 내 분산(inertia)을 계산하여 inertia가 급격히 줄어들다가 완만해지는 지점(“엘보우”)를 찾음\n  - 결과 그래프에서 k=3 부근에서 꺾임이 나타나 적절한 클러스터 수로 판단\n\n#### 2. KMeans 클러스터링 (k=3)\n\n  - 엘보우 결과를 토대로 클러스터 수를 3으로 설정하여 모델 학습 및 클러스터 할당\n  - 각 클러스터별 데이터 분포는 0: 3816개, 1: 3530개, 2: 2781개로 비교적 균형 잡힘\n\n#### 3. Silhouette Score 평가\n\n  - Silhouette Score = 0.1775\n→ 군집 간 분리가 아주 뚜렷하지는 않지만, 고객 행동 데이터처럼 고차원·연속형 변수 중심의 복잡한 데이터에서는 비교적 합리적인 수준의 분리도로 해석 가능\n\n  - ※ 고객 데이터 특성상 일부 오버랩은 자연스러울 수 있음 -->","metadata":{}},{"cell_type":"markdown","source":"### **🔸churn-probability 가중치 부여**\n```\n이탈 확률(churn_probability) 변수에 다양한 가중치(1, 2, 5, 10, 15, 20)를 부여하여 클러스터링을 반복 수행하여 핵심변수가 클러스터링에 적당한 영향력을 행사할 수 있는 가중치 탐색 진행\n\n→ 가중치 2 부여 시 이탈 위험도에 따른 군집 분리 및 적당한 영향력의 균형을 확인함.\n  해당 기준을 기반으로 이후 세부 클러스터링 진행.\n\n```","metadata":{}},{"cell_type":"code","source":"# ▶ 모델링을 통해 얻은 churn_probability를 중심으로 행동 패턴을 파악하기 위해 해당 변수에 가중치를 부여한 후 클러스터링 진행\nX_scaled_final['churn_probability'] = X_cluster_Existing['churn_probability']\nfor weight in [1, 2, 5, 10, 15, 20]:\n    X_scaled_weight = X_scaled_final.copy()\n    X_scaled_weight['churn_probability'] = X_scaled_weight['churn_probability'] * weight\n    # 클러스터링 수행\n    kmeans = KMeans(n_clusters=10, random_state=42)\n    cluster_labels = kmeans.fit_predict(X_scaled_weight)\n    # 군집별 churn 확률 평균 출력\n    print(f'Weight: {weight}')\n    print(X_scaled_weight.groupby(cluster_labels)['churn_probability'].mean())\n    # 클러스터 별 샘플 수\n    print('\\n클러스터 별 샘플 수')\n    print(pd.Series(cluster_labels).value_counts().sort_index())\n    print('-'*30)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T07:05:58.617722Z","iopub.execute_input":"2025-08-10T07:05:58.61799Z","iopub.status.idle":"2025-08-10T07:05:59.719337Z","shell.execute_reply.started":"2025-08-10T07:05:58.617969Z","shell.execute_reply":"2025-08-10T07:05:59.718555Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 가중치 2 부여 시 이탈 위험도에 따른 군집 분리 및 적당한 영향력의 균형을 확인\n# 따라서 churn_probability에 가중치 2 조정하여 클러스터 분리 진행\nX_scaled_weight = X_scaled_final.copy()\nX_scaled_weight['churn_probability'] = X_scaled_weight['churn_probability'] * 2","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T07:05:59.720208Z","iopub.execute_input":"2025-08-10T07:05:59.720483Z","iopub.status.idle":"2025-08-10T07:05:59.726079Z","shell.execute_reply.started":"2025-08-10T07:05:59.720455Z","shell.execute_reply":"2025-08-10T07:05:59.725416Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### **🔸 Clustering 적정 K값 탐색**\n```\n클러스터링 진행을 위해 최적의 군집 수 K를 결정하는 과정에서\nElbow Method나 Silhouette Score만으로는 확정적인 K를 판단하기 어려웠으며\n실제 클러스터 해석 가능성, 고객 세분화의 적절한 수준, t-sne 시각화 기반의 군집 구조 확인 등 종합적인 요소를 고려해\n클러스터 수는 K=7로 최종 결정하여 진행\n```","metadata":{}},{"cell_type":"code","source":"# ▶ Elbow Method\ninertia = []\n\nfor k in range(1, 11):  # k = 1부터 10까지 반복\n    kmeans = KMeans(n_clusters=k, random_state=42)\n    kmeans.fit(X_scaled_weight)\n    inertia.append(kmeans.inertia_)\n\nplt.figure(figsize=(8,5))\nplt.plot(range(1, 11), inertia, marker='o')\nplt.title('Elbow Method for Optimal K')\nplt.xlabel('Number of clusters')\nplt.ylabel('Inertia')\nplt.grid(True)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T07:05:59.726964Z","iopub.execute_input":"2025-08-10T07:05:59.727215Z","iopub.status.idle":"2025-08-10T07:06:00.965499Z","shell.execute_reply.started":"2025-08-10T07:05:59.727189Z","shell.execute_reply":"2025-08-10T07:06:00.964709Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ▶ Silhouette Score\nsil_score = silhouette_score(X_scaled_weight, cluster_labels)\nprint(f'Silhouette Score for k=7: {sil_score:.4f}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T07:06:00.9663Z","iopub.execute_input":"2025-08-10T07:06:00.966577Z","iopub.status.idle":"2025-08-10T07:06:01.845944Z","shell.execute_reply.started":"2025-08-10T07:06:00.966558Z","shell.execute_reply":"2025-08-10T07:06:01.845121Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### **🔸 Clustering (Kmeans)**\n```\nKMeans 알고리즘을 활용하여 클러스터 수 7으로 클러스터링을 수행한 결과\n각 군집은 다음과 같이 분포됨.\n\nCluster 0: 1,288명\nCluster 1: 896명\nCluster 2: 1,275명\nCluster 3: 1,563명\nCluster 4: 470명\nCluster 5: 1,444명\nCluster 6: 1,564명\n\n➡️ 이후 각 클러스터의 행동 특성과 이탈 확률을 기반으로 세부 해석 및 전략 도출 예정\n```","metadata":{}},{"cell_type":"code","source":"# ▶ KMeans Clustering\n# 클러스터 개수 : 7\nkmeans = KMeans(n_clusters=7, random_state=42)\n\n# 학습 (fit) + 클러스터 번호 예측 (predict)\ncluster_labels = kmeans.fit_predict(X_scaled_weight)\n\n# 결과를 원본 데이터프레임에 컬럼으로 추가\nX_cluster_Existing['cluster'] = cluster_labels\ndf_cluster_Existing['cluster'] = cluster_labels\n\n# 클러스터 할당 결과 확인\nprint(X_cluster_Existing['cluster'].value_counts())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T07:06:01.846756Z","iopub.execute_input":"2025-08-10T07:06:01.846989Z","iopub.status.idle":"2025-08-10T07:06:01.9923Z","shell.execute_reply.started":"2025-08-10T07:06:01.846965Z","shell.execute_reply":"2025-08-10T07:06:01.991412Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### **🔸 클러스터링 분포 시각화**\n```\nPCA (2D) 시각화를 통해 클러스터 간의 전반적인 분포 확인\n\nT-SNE 시각화에서도 각 클러스터가 구분되어 거리 기반 분리됨을 확인함\n\n➡️ 두 시각화 기법 모두 군집 간 내부 응집도와 외부 분리도가 양호함을 확인\n```","metadata":{}},{"cell_type":"code","source":"# 시각화용 PCA (2D)\npca_2d = PCA(n_components=2, random_state=42)\nX_pca_2d = pca_2d.fit_transform(X_scaled_weight)\n\n# 군집 정보 그대로 붙이기\ndf_viz = pd.DataFrame(X_pca_2d, columns=['PC1', 'PC2'])\ndf_viz['Cluster'] = X_cluster_Existing['cluster']\n\n# 시각화\nplt.figure(figsize=(8,6))\nsns.scatterplot(data=df_viz, x='PC1', y='PC2', hue='Cluster', palette='tab20', edgecolor='k', s=60)\nplt.title('PCA Scatter Plot (k=3)')\nplt.grid(True)\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T07:06:01.9933Z","iopub.execute_input":"2025-08-10T07:06:01.993635Z","iopub.status.idle":"2025-08-10T07:06:02.652222Z","shell.execute_reply.started":"2025-08-10T07:06:01.993608Z","shell.execute_reply":"2025-08-10T07:06:02.651413Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tsne = TSNE(n_components=2, random_state=42, init='pca',perplexity=30, n_iter=1000)\nX_tsne = tsne.fit_transform(X_scaled_weight)\n\ntsne_df = pd.DataFrame(X_tsne, columns=['TSNE1', 'TSNE2'])\ntsne_df['cluster'] = cluster_labels\n\nplt.figure(figsize=(10,8))\nsns.scatterplot(\n    data = tsne_df,\n    x = 'TSNE1',\n    y = 'TSNE2',\n    hue = 'cluster',\n    palette = 'tab20',\n    alpha=0.7,\n    s = 60\n)\nplt.title(\"T-SNE Clustering Visualization\")\nplt.legend(title='Cluster', loc='best')\nplt.grid(True)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T07:06:02.653199Z","iopub.execute_input":"2025-08-10T07:06:02.653734Z","iopub.status.idle":"2025-08-10T07:06:50.371584Z","shell.execute_reply.started":"2025-08-10T07:06:02.65371Z","shell.execute_reply":"2025-08-10T07:06:50.370726Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### **🔸 클러스터 기반 이탈 리스크 분석**","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10, 6))\nsns.violinplot(\n    data=X_cluster_Existing,\n    x='cluster',\n    y='churn_probability',\n    palette='tab20',\n    inner='quartile',\n    cut = 0,\n    scale='width'\n)\n\nplt.title('Distribution of Predicted Churn Probability by Cluster', fontsize=14)\nplt.xlabel('Cluster Label', fontsize=12)\nplt.ylabel('Predicted Churn Probability', fontsize=12)\nplt.grid(axis='y', linestyle='--', alpha=0.7)\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T07:06:50.372737Z","iopub.execute_input":"2025-08-10T07:06:50.373032Z","iopub.status.idle":"2025-08-10T07:06:50.721494Z","shell.execute_reply.started":"2025-08-10T07:06:50.37301Z","shell.execute_reply":"2025-08-10T07:06:50.72065Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 🔹 클러스터 별 패턴 분석\n- Radar Chart와 클러스터 별 평균변수값, 변수 별 분포 확인 진행\n\n### 1. Radar Chart\n- 각 변수의 정규화 된 상대비교를 통하여 전반적인 프로파일 차이 파악 진행\n- 각 클러스터의 행동 특성 전반을 한눈에 비교가능함\n\n### 2. 클러스터 별 평균변수값 (cluster_summary)\n- 실제 절댓값 기준으로 변수의 높고 낮음을 판단\n\n### 3. 변수 별 분포 확인 (Boxplot, Barplot, Histogram)\n- 각 변수의 분포 및 극단값, 편향 여부, 클러스터 간의 겹침 여부 등을 시각적으로 확인\n- 단순 평균값 이상의 구조적인 특성까지 반영을 위함\n\n➡️ 변수에 따라 각 클러스터의 행동/이탈 성향이 뚜렷하게 구분되며,\n이런 특성은 이후의 세부 타겟 마케팅 전략 수립의 핵심 기반으로 활용 가능함","metadata":{}},{"cell_type":"code","source":"# 라벨링\ncluster_map = {\n    0: 'low5',\n    1: 'low2',\n    2: 'low1',\n    3: 'low6',\n    4: 'Target',\n    5: 'low4',\n    6: 'low3',\n}\n\ndf_cluster_Existing['cluster_label'] = df_cluster_Existing['cluster'].map(cluster_map)\ndf_cluster_Existing.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T07:06:50.722377Z","iopub.execute_input":"2025-08-10T07:06:50.722638Z","iopub.status.idle":"2025-08-10T07:06:50.743871Z","shell.execute_reply.started":"2025-08-10T07:06:50.722619Z","shell.execute_reply":"2025-08-10T07:06:50.743148Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 이탈자 전체를 하나의 클러스터로 구분\ndf_cluster_Attrition = df_feature[df_feature['Attrition_Flag'] == 'Attrited Customer'].copy()\ndf_cluster_Attrition['cluster'] = -1\ndf_cluster_Attrition['cluster_label'] = 'Attrited'\n\ndf_cluster_combined = pd.concat([df_cluster_Existing, df_cluster_Attrition], ignore_index=True)\nX_cluster_combined = df_cluster_combined[cluster_features].copy()\nX_cluster_combined['cluster'] = df_cluster_combined['cluster']\nX_cluster_combined['cluster_label'] = df_cluster_combined['cluster_label']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T07:06:50.744654Z","iopub.execute_input":"2025-08-10T07:06:50.744861Z","iopub.status.idle":"2025-08-10T07:06:50.770429Z","shell.execute_reply.started":"2025-08-10T07:06:50.744845Z","shell.execute_reply":"2025-08-10T07:06:50.769646Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(df_cluster_combined['cluster_label'].value_counts())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T07:06:50.771183Z","iopub.execute_input":"2025-08-10T07:06:50.771444Z","iopub.status.idle":"2025-08-10T07:06:50.777124Z","shell.execute_reply.started":"2025-08-10T07:06:50.77142Z","shell.execute_reply":"2025-08-10T07:06:50.776396Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### **🔸 Radar Chart**","metadata":{}},{"cell_type":"code","source":"# Radar Chart\ncluster_mean = df_cluster_combined.groupby('cluster_label')[cluster_features].mean()\n\nscaler = MinMaxScaler()\ncluster_scaled = pd.DataFrame(scaler.fit_transform(cluster_mean),\n                              index=cluster_mean.index,\n                              columns=cluster_features)\n\ncategories = cluster_features\nnum_vars = len(categories)\n\nangles = np.linspace(0, 2 * np.pi, num_vars, endpoint=False).tolist()\nangles += angles[:1]\n\nfig, ax = plt.subplots(figsize=(8, 8), subplot_kw=dict(polar=True))\n\n\nfor cluster_id in cluster_scaled.index:\n    values = cluster_scaled.loc[cluster_id].tolist()\n    values += values[:1]\n    ax.plot(angles, values, label=f'Cluster {cluster_id}')\n    ax.fill(angles, values, alpha=0.1)\n\nax.set_title(\"Cluster-wise Radar Chart\", size=16, y=1.1)\nax.set_xticks(angles[:-1])\nax.set_xticklabels(categories, fontsize=10)\nax.set_yticks([0.2, 0.4, 0.6, 0.8])\nax.set_yticklabels([\"0.2\", \"0.4\", \"0.6\", \"0.8\"], color=\"grey\", size=8)\nax.legend(loc='upper right', bbox_to_anchor=(1.3, 1.1))\n\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T07:06:50.778294Z","iopub.execute_input":"2025-08-10T07:06:50.77895Z","iopub.status.idle":"2025-08-10T07:06:51.527Z","shell.execute_reply.started":"2025-08-10T07:06:50.778928Z","shell.execute_reply":"2025-08-10T07:06:51.525877Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### **🔸 클러스터 별 평균 변수 및 분포확인**","metadata":{}},{"cell_type":"code","source":"# 클러스터 별 평균 변수 값 확인\nfor i in cluster_features:\n        print(f\"Feature - {i}\")\n        print(np.round(df_cluster_combined.groupby('cluster_label')[i].describe(),2))\n        print(\"\\n----------------------------------\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T07:06:51.528032Z","iopub.execute_input":"2025-08-10T07:06:51.528392Z","iopub.status.idle":"2025-08-10T07:06:51.706758Z","shell.execute_reply.started":"2025-08-10T07:06:51.528363Z","shell.execute_reply":"2025-08-10T07:06:51.705915Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 클러스터 별 변수 분포 확인\norder = ['Attrited', 'low1', 'low2', 'low3', 'low4', 'low5', 'low6', 'Target']\nfor var in cluster_features:\n    plt.figure(figsize=(10,6))\n    sns.violinplot(\n        data=df_cluster_combined,\n        x='cluster_label',\n        y=var,\n        palette='tab20',\n        inner='quartile',\n        order=order,\n        cut=1\n    )\n    medians = df_cluster_combined.groupby('cluster_label')[var].median()\n    medians = medians.reindex(order).values\n    plt.plot(range(len(order)), medians, marker='o', color='red', label='Median')\n    plt.legend()\n    plt.title(f\"Violin Plot - {var}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T07:06:51.707664Z","iopub.execute_input":"2025-08-10T07:06:51.708059Z","iopub.status.idle":"2025-08-10T07:06:56.193995Z","shell.execute_reply.started":"2025-08-10T07:06:51.708031Z","shell.execute_reply":"2025-08-10T07:06:56.192952Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 📃 Process Insight - Clustering\n---\n\n\n### 1. 주요변수 Scaling <br>\n```\n클러스터링 진행 전, 주요 수치형 변수들의 분포 특성과 이상치 여부를 고려하여 혼합형 스케일링 전략을 적용하였음\n각 변수의 분포 패턴을 개별적으로 분석한 후, 스케일러를 다음 기준에 따라 각각 다르게 적용하였다\n```\n| 변수명                      | 적용 스케일러       | 적용 사유                                               |\n|---------------------------|--------------------|--------------------------------------------------------|\n| Total_Trans_Ct            | RobustScaler       | 이상치 다수 존재, 비대칭 분포                              |\n| Total_Revolving_Bal       | RobustScaler       | 이상치 다수 존재, 0에 몰림 현상 있음                         |\n| Total_Amt_Chng_Q4_Q1      | RobustScaler       | 비대칭 분포, 이상치 존재                                   |\n| Contacts_Count_12_mon     | RobustScaler       | 분포 왜곡 및 이상치 존재                                  |\n| Total_Ct_Chng_Q4_Q1       | RobustScaler       | 오른쪽 꼬리 긴 분포, 이상치 다수                             |\n| Customer_Age              | StandardScaler     | 정규분포에 가까움, 이상치 거의 없음                          |\n| Engagement_Score          | MinMax (sqrt) | 극단값은 없음, 값 치우침 심함 → 루트 변환으로 왜곡 보정 후 정규화 |\n| Total_Relationship_Count  | MinMax             | 정수형 이산 변수, 이상치 없음                               |\n| Months_Inactive_12_mon    | MinMax             | 값의 범위 좁고, 이산 분포 → 단순 정규화 적합                   |\n <br> <br>\n1. RobustScaler 적용 <br>\n이상치가 많은 변수에 대해 적용 <br>\n이상치 영향 억제를 통해 왜곡을 최소화하고 중앙값 중심의 스케일링을 수행함.\n\n    적용 변수:\n    `Total_Trans_Ct`, `Total_Revolving_Bal`, `Total_Amt_Chng_Q4_Q1`,\n    `Contacts_Count_12_mon`, `Total_Ct_Chng_Q4_Q1`\n\n \n2. StandardScaler 적용 <br>\n이상치가 적고 정규 분포에 가까운 변수 <br>\n정보 손실 없이 평균 0, 표준편차 1의 표준화 수행.\n\n    적용 변수:\n    `Customer_Age`\n\n3. MinMax (√ 변환 후) 적용 <br>\n이상치는 적지만 값의 치우침이 뚜렷한 변수 <br>\n루트 변환 후 스케일링을 통해 분포 왜곡을 보정함.\n\n    적용 변수:\n    `Engagement_Score`\n\n4. MinMax 적용\n이산형 변수이거나, 이상치 및 분포 치우침이 거의 없는 변수\n단순 범위 정규화를 통해 크기 보정.\n\n    적용 변수:\n    `Total_Relationship_Count`, `Months_Inactive_12_mon`\n\n\n\n※ 모든 스케일링 완료 후, 최종적으로 스케일된 값들의 범위를 통일하기 위해 <br>\n전체 변수에 대해 MinMaxScaler를 추가 적용하여 0~1 사이로 정규화 완료 <br>\n이로 인해 클러스터링 알고리즘에서 거리 기반 계산 시 변수 간 스케일 편차로 인한 왜곡을 최소화하였음.\n\n➡️ 이 과정을 통해 **각 변수의 분포 특성을 고려한 맞춤형 스케일링을 통해\n클러스터 해석력 유지 + 거리 기반 알고리즘의 안정성을 확보**하였음\n\n\n### 2. Clustering <br>\n#### 적정 K값 결정\n```\n고객 세그먼트를 정의하기 위해 KMeans 클러스터링을 수행 전\n클러스터수(K값) 결정은 수치적 최적값보다는 실질적인 해석 가능성과 분포 차이에 초점을 맞춰 결정하였음\n\n세분화된 클러스터링을 위해서 초기 실험에서는 K=10으로 클러스터링을 진행했으며, 결과적으로 Low 5개, Middle 3개, High 2개의 클러스터가 생성되었다.\nHigh 위험군 내 클러스터 2개는 서로 상이한 분포를 보여 이탈 위험 고객 내에서도 세분화가 가능함을 확인할 수 있었다. 그러나 이렇게 많은 클러스터는 실제 마케팅 전략 수립 및 고객 관리 측면에서 활용성과 효율성이 떨어질 수 있다는 판단이 있었다.\n\n따라서 K 값을 줄여가며 분포를 재검토했고 K=7 수준에서 클러스터 간 분포 차이가 뚜렷하면서도, 각 군집에 대한 마케팅 전략 수립이 가능할 정도의 해석력과 실용성이 확보됨을 확인하였다.\n\nt-SNE 시각화 결과 역시 K=7 기준으로 군집 간 분리 구조가 확인되어 적합한 세분화 수준으로 판단하여 결정하였음.\n```\n#### 클러스터링 결과 (각 클러스터 인원수 및 전체 대비 비율)\n```\nAttrited 클러스터는 실제 이탈 고객들만 따로 분리하여 모은 집단으로, 클러스터링에는 포함되지 않음\n고객들은 7개의 클러스터로 분류하였고, 그 중 Target 클러스터는 이탈자 클러스터(Attrited)와 유사한 특성을 가지며 예측된 이탈 확률도 높은 집단으로 Target으로 네이밍하여 진행함\n(Target은 현재는 이탈하지 않았지만 향후 이탈 가능성이 높은 고위험 고객군으로 해석되며 리텐션 전략의 핵심 타겟으로 간주)\n```\n| Cluster Label | Count | Percent (%) |\n|---------------|--------|-------------|\n| Attrited      | 1,627  | 16.07%      |\n| low3          | 1,564  | 15.44%      |\n| low6          | 1,563  | 15.43%      |\n| low4          | 1,444  | 14.26%      |\n| low5          | 1,288  | 12.72%      |\n| low1          | 1,275  | 12.59%      |\n| low2          |   896  |  8.85%      |\n| Target        |   470  |  4.64%      |\n| **Total**     |10,127  | **100.00%** |\n\n\n\n### 3. 클러스터별 패턴분석 <br>\n```\n총 7개의 세부 클러스터가 도출되었고, 여기에 실제 이탈 고객(Attrited)을 포함하여 총 8개 그룹을 비교 분석 진행\n클러스터 수가 많아진 만큼 개별 클러스터 분석의 복잡성이 증가하였고,\n복잡한 다수의 클러스터 해석을 위해 유사한 특성 및 전략 목적에 따라 클러스터를 재그룹화하여 인사이트를 도출하였음\n```\n\n※ **Target 클러스터 (Cluster 4)**\n- churn_probability 평균: 0.56\n- 이탈자 집단(`Attrited`)의 평균인 0.93에 가장 근접\n- 변수별 분포도 유사 (`Total_Trans_Ct`, `Total_Amt_Chng_Q4_Q1`, `Engagement_Score` 등 대부분 낮음)\n    - → 이탈 가능성이 높은 ‘경계 고객군’으로 정의\n\n| 그룹명                 | 클러스터          | 주요 특징             | 전략설계 방향           |\n| ------------------- | ---------------- | ----------------- | --------------- |\n| **이탈 유사군 (Target)** | Cluster 4        | 이탈자와 유사한 활동/관계 패턴 | 최우선 리텐션, 사용 유도  |\n| **충성 고객군**          | low1, low2, low5 | 사용량, 충성도 높음       | VIP 혜택, 리워드 강화  |\n| **중간 리스크군**         | low3, low4       | 활동성은 높지만 관계성 낮음   | 고객만족·서비스 품질 관리  |\n| **비활성/저관여군**        | low6             | 낮은 사용, 낮은 리스크     | 브랜드 상기, 재활성화 유도 |\n| **실제 이탈군**          | Attrited         | 이탈 확정 고객          | 비교/해석 기준으로 활용   |\n\n\n\n\n\n","metadata":{}},{"cell_type":"markdown","source":"# ✔ Process 04 - 타겟 클러스터 분석\n\n- 주요 변수 Scaling (이탈자 포함)\n    - 핵심변수 분포확인\n    - 분포확인후 변수 Scaling (Robust, Standard, MinMax(sqrt), MinMax)\n    - Scaling 이후 변수별 분포 확인\n- 유클리드 거리를 통한 기준 클러스터 추출\n    - 스케일링된 데이터프레임에 클러스터 라벨을 병합\n    - 각 클러스터 라벨 기반 이탈 클러스터와의 중심 거리 평균 확인\n    - 가장 거리가 먼 클러스터와 가장 가까운 클러스터를 추출\n- 기준 클러스터들간의 분포 차이 통계검증\n    - 세 개의 클러스터를 Kruskal 통계 검증을 통해 p-value가 0.05보다 작은 변수들만을 추출\n- 클러스터 별 변수 별 분포 분석\n    - 통계적으로 유의한 변수들을 대상으로 violin plot을 통해 분포 확인\n    - 각 클러스터의 중앙값을 연결하여 직관적으로 차이 확인\n    - 클러스터 별 변수 별 통계값들을 확인\n---","metadata":{}},{"cell_type":"code","source":"# 스케일링된 전체 데이터에 cluster_label 병합\nX_scaled_final['cluster_label'] = df_cluster_Existing['cluster_label']\nX_scaled_final['cluster_label'].unique()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T07:06:56.194912Z","iopub.execute_input":"2025-08-10T07:06:56.195139Z","iopub.status.idle":"2025-08-10T07:06:56.203333Z","shell.execute_reply.started":"2025-08-10T07:06:56.195121Z","shell.execute_reply":"2025-08-10T07:06:56.202263Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"center_attrited = X_scaled_final[X_scaled_final['cluster_label'] == 'Target'][cluster_features].mean().values\n\n# 다른 클러스터들의 샘플과 중심 거리(유클리드) 평균 계산\ndistance_dict = {}\nfor c in X_scaled_final['cluster_label'].unique():\n    if c != 'Target':\n        cluster_data = X_scaled_final[X_scaled_final['cluster_label'] == c][cluster_features].values\n        distances = np.linalg.norm(cluster_data - center_attrited, axis=1)\n        distance_dict[c] = distances.mean()\n\ndf_dist = pd.DataFrame(distance_dict.items(), columns=['cluster', 'Distance_to_Attrited'])\ndf_dist = df_dist.sort_values(by='Distance_to_Attrited', ascending=False)\n\n# Bar plot을 통한 시각화 (빨강: 이탈과 가장 유사하지 않은 클러스터, 파랑: 이탈과 가장 유사한 클러스터)\nmin_cluster = df_dist.iloc[0]['cluster']\nmax_cluster = df_dist.iloc[-1]['cluster']\ncolors = []\nfor c in df_dist['cluster']:\n    if c == min_cluster:\n        colors.append('red')\n    elif c == max_cluster:\n        colors.append('blue')\n    else:\n        colors.append('lightgreen')\n\nplt.figure(figsize=(10,6))\nax = sns.barplot(x='cluster', y='Distance_to_Attrited', data=df_dist, palette=colors)\n\nfor i in ax.patches:\n    x = i.get_x() + i.get_width() / 2\n    y = i.get_height()\n    ax.text(x, y + 0.015, f\"{y:.3f}\", ha='center', va='center', fontsize=9, fontweight='bold')\n\nplt.title(\"Distance to Attrited Cluster (Euclidean Mean)\")\nplt.xlabel(\"Cluster Label\")\nplt.ylabel(\"Mean Euclidean Distance\")\nplt.ylim(0, df_dist['Distance_to_Attrited'].max() * 1.15)\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T07:06:56.204365Z","iopub.execute_input":"2025-08-10T07:06:56.205168Z","iopub.status.idle":"2025-08-10T07:06:56.477659Z","shell.execute_reply.started":"2025-08-10T07:06:56.205145Z","shell.execute_reply":"2025-08-10T07:06:56.476849Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 기준 클러스터 정의\ncompare_cluster = ['Attrited', 'low3', 'Target']\ndf_compare_cluster = df_cluster_combined[df_cluster_combined['cluster_label'].isin(compare_cluster)]\ndf_compare_cluster['cluster_label'].value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T07:06:56.478587Z","iopub.execute_input":"2025-08-10T07:06:56.479154Z","iopub.status.idle":"2025-08-10T07:06:56.489509Z","shell.execute_reply.started":"2025-08-10T07:06:56.479124Z","shell.execute_reply":"2025-08-10T07:06:56.488755Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 통계 검증\n# 비교할 그룹\ngroup_names = ['Attrited', 'Target', 'low3']\ngroup_data = {name: df_cluster_combined[df_cluster_combined['cluster_label'] == name] for name in group_names}\n\n# 결과 저장\nresults = []\n\nfor col in cluster_features:  # 비교할 변수들\n    data = [group_data[name][col].dropna() for name in group_names]\n    stat, p = kruskal(*data)\n    results.append((col, stat, p))\n\n# 정리된 결과 출력\ntest_result_df = pd.DataFrame(results, columns=['변수명', '통계량', 'p-value'])\ntest_result_df['유의여부'] = test_result_df['p-value'] < 0.05\ntest_result_df.sort_values('p-value')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T07:06:56.490391Z","iopub.execute_input":"2025-08-10T07:06:56.490695Z","iopub.status.idle":"2025-08-10T07:06:56.542243Z","shell.execute_reply.started":"2025-08-10T07:06:56.490665Z","shell.execute_reply":"2025-08-10T07:06:56.541621Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Customer_Age를 제외한 통계적으로 차이가 유의미한 변수들을 추출\ncluster_importance_vars = cluster_features.copy()\ncluster_importance_vars.remove('Customer_Age')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T07:06:56.543078Z","iopub.execute_input":"2025-08-10T07:06:56.543327Z","iopub.status.idle":"2025-08-10T07:06:56.546989Z","shell.execute_reply.started":"2025-08-10T07:06:56.543294Z","shell.execute_reply":"2025-08-10T07:06:56.546391Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 기준 클러스터들만 추출, 변수 별 분포 확인\norder = ['low3', 'Target', 'Attrited']\nfor var in cluster_importance_vars:\n    plt.figure(figsize=(10,6))\n    sns.violinplot(\n        data=df_compare_cluster,\n        x='cluster_label',\n        y=var,\n        palette='tab20',\n        inner='quartile',\n        cut=1,\n        order=order\n    )\n    medians = df_compare_cluster.groupby('cluster_label')[var].median().reindex(order)\n    plt.plot(range(len(order)), medians, marker='o', color='red', label='Median')\n    plt.legend()\n    plt.title(f\"Violin Plot - {var}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T07:06:56.547875Z","iopub.execute_input":"2025-08-10T07:06:56.548117Z","iopub.status.idle":"2025-08-10T07:06:59.011129Z","shell.execute_reply.started":"2025-08-10T07:06:56.548099Z","shell.execute_reply":"2025-08-10T07:06:59.010303Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 클러스터별 변수 중앙값을 표로 보기\nmedian_table = df_cluster_combined.groupby('cluster_label')[cluster_features].median()\n\n# 순서 맞추기\nmedian_table = median_table.reindex(order)\n\n# 기준: Target\ntarget_vals = median_table.loc['Target']\ncompare_clusters = ['low3', 'Attrited']\n\n# 퍼센트 차이 계산\npct_diff = pd.DataFrame()\nfor cl in compare_clusters:\n    pct_diff[cl] = ((median_table.loc[cl] - target_vals) / target_vals) * 100\n\npct_diff = pct_diff.T  # 클러스터가 행, 변수들이 열\npct_diff","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T07:06:59.012038Z","iopub.execute_input":"2025-08-10T07:06:59.012271Z","iopub.status.idle":"2025-08-10T07:06:59.036466Z","shell.execute_reply.started":"2025-08-10T07:06:59.012253Z","shell.execute_reply":"2025-08-10T07:06:59.035624Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(14, 7))\n\n# Set2 팔레트 가져오기 (클러스터 수에 맞게 자동 조절)\npalette = sns.color_palette(\"Set2\", n_colors=pct_diff.shape[1])\n\n# 막대그래프 그리기\npct_diff.T.plot(\n    kind='bar',\n    figsize=(14,7),\n    grid=True,\n    color=palette,\n    edgecolor='black',\n    linewidth=0.7\n)\n\nplt.axhline(0, color='gray', linestyle='--', linewidth=1)\n\nplt.title('Percentage Difference Compared to Target Cluster', fontsize=16, weight='bold')\nplt.ylabel('Percentage Difference (%)', fontsize=14)\nplt.xlabel('Variables', fontsize=14)\n\nplt.legend(title='Cluster', fontsize=12, title_fontsize=13, loc='upper right')\nplt.xticks(rotation=45, ha='right', fontsize=12)\nplt.yticks(fontsize=12)\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T07:06:59.037415Z","iopub.execute_input":"2025-08-10T07:06:59.03774Z","iopub.status.idle":"2025-08-10T07:06:59.477735Z","shell.execute_reply.started":"2025-08-10T07:06:59.037712Z","shell.execute_reply":"2025-08-10T07:06:59.47684Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 클러스터 별 변수 별 통계값 확인\nfor i in cluster_importance_vars:\n    summary = df_compare_cluster.groupby('cluster_label')[i].describe()\n    print(f\"Feature - {i}\\n\")\n    print(summary.round(2).T)\n    print(\"\\n----------------------------------------\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T07:06:59.478588Z","iopub.execute_input":"2025-08-10T07:06:59.478824Z","iopub.status.idle":"2025-08-10T07:06:59.549445Z","shell.execute_reply.started":"2025-08-10T07:06:59.478806Z","shell.execute_reply":"2025-08-10T07:06:59.548424Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 📃 Process Insight - Target Cluster 분석\n---\n\n\n### 1. 유클리드 거리 계산 및 기준 클러스터 선정 <br>\n\n```\nTarget 클러스터가 이전 클러스터링에서 가장 Attrited(이탈자 클러스터)와 유사한 분포를 보여줌\n\n따라서 해당 클러스터와 가장 분포가 비슷하지만 이탈 확률은 낮은 클러스터를 찾아 Target 클러스터와 비교하여 문제점을 파악하고자 함\n\nKMeans Clustering을 활용하였으므로, Target 클러스터를 기준으로 기타 low 클러스터들의 유클리드 거리(평균값 기준)를 탐색\n(기존에 스케일링한 데이터가 있으므로, 추가로 스케일링을 진행하지 않고 해당 데이터를 활용)\n\nlow 4에서 0.968, low 3에서 0.754로 각각 가장 높고, 낮은 값이 도출됨\n\nTarget 클러스터가 이탈 확률이 높고, 이탈과 분포가 유사한 이유를 확인하기 위해 low3, Target, Attrited 클러스터를 선정\n\n각 클러스터의 고객 분포가 1,627(Attrited), 1,564(low3), 470(Target)으로 Target을 제외한 두 클러스터가 거의 동일하여 그대로 진행\n```\n\n| Cluster Label | Target과의 거리(유클리드) |\n|:---|:---|\n| low4 | 0.968 |\n| low5 | 0.857 |\n| low2 | 0.844 |\n| low6 | 0.819 |\n| low1 | 0.775 |\n| low3 | 0.754 |\n\n<br>\n\n### 2. 통계 검증 <br>\n\n```\nTarget, low3, Attrited 클러스터들의 각 변수들의 통계적 유의성을 검증하였음\n\n3개 이상의 클러스터들을 대상으로 진행하고, 각 변수들의 정규성, 등분산성이 확인되지 않았기 때문에 비모수 검증 방법인 Kruskal-Wallis를 사용함\n\n이를 통해 차이가 의미 있는 변수들을 파악하고 해당 변수들의 클러스터 별 분포를 비교하여 Target 클러스터가 가지는 유의미한 차이를 탐색하기 위함\n\n유의 여부(p-value < 0.05)를 확인한 결과, Customer_Age를 제외한 다른 변수들에서 유의성이 확인되었음\n```\n\n| 변수명 | 통계량 | p-value | 유의여부 |\n|:---|:---|:---|:---|\n| Total_Trans_Ct           | 312.65  | 0.0000 | True  |\n| Total_Revolving_Bal      | 936.86  | 0.0000 | True  |\n| Total_Ct_Chng_Q4_Q1      | 535.39  | 0.0000 | True  |\n| Total_Relationship_Count | 112.26  | 0.0000 | True  |\n| Months_Inactive_12_mon   | 130.67  | 0.0000 | True  |\n| Total_Amt_Chng_Q4_Q1     | 78.16   | 0.0000 | True  |\n| Engagement_Score         | 537.22  | 0.0000 | True  |\n| churn_probability        | 2959.47 | 0.0000 | True  |\n| Contacts_Count_12_mon    | 10.67   | 0.0048 | True  |\n| Customer_Age             | 3.67    | 0.1595 | False |\n\n<br>\n\n### 3. Target Cluster와 기준 클러스터 비교 <br>\n\n```\nTarget 클러스터의 패턴을 파악하기 위해 기준 클러스터들의 변수 별 분포를 비교하였음 (Violin Plot과 Line Plot(중앙값))\n\n더욱 직관적인 확인을 위해 Target 클러스터를 기준으로 각 클러스터의 중앙값을 퍼센트로 비교하였음\n(클러스터 별 주요 변수의 중앙값을 기반으로, Target 클러스터와 다른 클러스터들 간의 중앙값 기준 상대적 차이(%)를 계산하여 비교)\n\n결과적으로 Target 클러스터의 고객들의 이탈을 방지하기 위해 어떤 변수(지표)를 더욱 늘리거나 낮춰야 하는지 파악하고 그에 맞는 마케팅 전략을 수립하고자 함\n```\n\n<br>\n\n#### **Total_Trans_Ct**\n\n| Cluster Label | Mean | Std | Median | IQR |\n|:---|:---|:---|:---|:---|\n| Attrited      | 44.93 | 14.57 | 43.0 | 14.0 |\n| Target        | 46.00 | 13.51 | 46.0 | 17.0 |\n| low3          | 57.26 | 20.08 | 61.0 | 35.0 |\n\n```\nTarget 클러스터의 총 거래 횟수의 통계는 Attrited와 매우 유사함(평균 약 2.07 차이, 중앙값 약 3 차이).\n\n또한 Std와 IQR 역시 낮은 모습을 보임 -> 분포가 좁고, 중앙값 기준으로 값이 다양하게 분포되어 있지는 않음.\n\n반대로 low3의 경우 Attrited, Target에 비해 높은 평균값(약 10차이), 중앙값(약 6차이)을 가지며, Std와 IQR 역시 넓음. -> 넓고 다양한 분포\n\n따라서 해당 변수는 Target이 low3에 비해 이탈확률이 높은 이유를 대변해 주는 변수라고 할 수 있음.\n```\n\n<br>\n\n#### **Total_Revolving_Bal**\n\n| Cluster Label | Mean | Std | Median | IQR |\n|:---|:---|:---|:---|:---|\n| Attrited      | 672.82  | 921.39 | 0.0    | 1303.5 |\n| Target        | 892.40  | 880.45 | 803.5  | 1560.0 |\n| low3          | 1650.64 | 448.58 | 1612.0 | 667.25 |\n\n```\nTarget 클러스터의 총 채무 총액의 통계는 평균에 있어서는 Attrited와 유사한 모습을 보임(약 200 차이).\n\n그러나, 중앙값에 있어서는 세 클러스터가 모두 다른 모습을 보여줌(Target 기준 각 800씩 차이).\n\n또한 Attrited와 Target은 Std와 IQR이 넓음(특히 Attrited의 IQR은 매우 넓은 모습을 보임). -> 분포가 넓고 중앙값 기준 값이 매우 다양함.\n\nlow3의 경우 평균은 두 클러스터에 비해 높음(Target 기준 약 800 차이).\n\n중앙값 역시 Target보다 높음(800 차이).\n\n언뜻 봤을 때 이탈 확률에 따른 선형적 패턴이라고 할 수 있으나, 앞선 전체 클러스터 패턴 파악에서 선형적인 모습은 발견되지 않았음.\n\n따라서 해당 변수는 Target 클러스터의 이탈 확률이 높은 이유를 대변한다고 하기 어려움.\n```\n\n<br>\n\n#### **Total_Ct_Chng_Q4_Q1**\n\n| Cluster Label | Mean | Std | Median | IQR |\n|:---|:---|:---|:---|:---|\n| Attrited      | 0.55  | 0.23 | 0.53    | 0.29 |\n| Target        | 0.61  | 0.22 | 0.60    | 0.28 |\n| low3          | 0.76  | 0.28 | 0.71    | 0.26 |\n\n\n```\nTarget 클러스터의 총 거래 횟수 변동 비율의 통계는 Attrited와 low3의 사이 값임.\n(평균: Attrited와 약 0.06 차이, low3과 약 0.15차이 / 중앙값: Attrited와 약 0.07 차이, low3과 약 0.11 차이)\n\nStd와 IQR 역시 모두 비슷한 모습을 보임.\n\n따라서 해당 변수만을 통해서 판단하기는 어려우나, 미세하게 Target의 분포가 low3보다는 Attrited와 유사한 모습을 보이기 때문에 해당 변수를 통해 Target 클러스터의 이탈 확률이 높은 이유를 조금이나마 대변한다고 할 수 있음.\n```\n\n<br>\n\n#### **Total_Relationship_Count**\n\n| Cluster Label | Mean | Std | Median | IQR |\n|:---|:---|:---|:---|:---|\n| Attrited      | 3.28  | 1.58 | 3.0    | 3.0 |\n| Target        | 3.96  | 1.33 | 4.0    | 2.0 |\n| low3          | 3.41  | 0.54 | 3.0    | 1.0 |\n\n```\nTarget 클러스터의 총 거래 상품 개수의 통계는 두 클러스터에 비해 높은 모습을 보임.\n(평균: Attrited와 약 0.7 차이, low3과 약 0.5 차이 / 중앙값: Attrited와 1차이, low3과 1차이)\n\nlow3의 경우 분포가 좁고 중앙값 기준 값이 다양하지 않기는 하지만 전체적으로 큰 이상은 보이지 않음.\n\n따라서 해당 변수는 Target 클러스터의 이탈 확률이 높은 이유를 대변한다고 하기 어려움.\n```\n\n#### **Months_Inactive_12_mon**\n\n| Cluster Label | Mean | Std | Median | IQR |\n|:---|:---|:---|:---|:---|\n| Attrited      | 2.69  | 0.90 | 3.0    | 1.0 |\n| Target        | 2.57  | 0.93 | 3.0    | 1.0 |\n| low3          | 2.34  | 1.03 | 2.0    | 1.0 |\n\n```\nTarget 클러스터의 비활성화 개월 수의 통계는 Attrited와 조금 더 유사한 모습을 보임.\n(평균: Attrited와 약 0.12 차이, low3과 약 0.23 차이 / 중앙값: Attrited와 차이 없음, low3과 1차이)\n\nStd와 IQR에서는 큰 이상이 발견되지 않음.\n\n따라서 해당 변수만을 통해서 판단하기는 어려우나, 미세하게 Target의 분포가 low3보다는 Attrited와 유사한 모습을 보이기 때문에 해당 변수를 통해 Target 클러스터의 이탈 확률이 높은 이유를 조금이나마 대변한다고 할 수 있음.\n```\n\n<br>\n\n#### **Total_Amt_Chng_Q4_Q1**\n\n| Cluster Label | Mean | Std  | Median | IQR  |\n| :------------ | :--- | :--- | :----- | :--- |\n| Attrited      | 0.69 | 0.21 | 0.70   | 0.32 |\n| Target        | 0.68 | 0.19 | 0.67   | 0.27 |\n| low3          | 0.79 | 0.26 | 0.73   | 0.27 |\n\n```\nTarget 클러스터의 총 거래 금액 변동률의 통계는 Attrited와 유사한 모습을 보임.\n(평균: Attrited와 약 0.01 차이, low3과 약 0.11 차이 / 중앙값: Attrited와 약 0.03 차이, low과 약 0.06 차이)\n\nStd와 IQR에서는 큰 차이가 발견되지 않음.\n\n따라서 해당 변수는 Target 클러스터의 이탈 확률이 높은 이유를 대변한다고 할 수 있음.\n```\n\n<br>\n\n#### **Engagement_Score**\n\n| Cluster Label | Mean  | Std  | Median | IQR   |\n| :------------ | :---- | :--- | :----- | :---- |\n| Attrited      | 9.32  | 5.95 | 7.80   | 6.13  |\n| Target        | 9.55  | 5.03 | 8.35   | 5.57  |\n| low3          | 14.47 | 7.60 | 13.05  | 9.31  |\n\n```\nTarget 클러스터의 총 활동 점수의 통계는 Attrited와 매우 유사한 모습을 보임.\n(평균: Attrited와 약 0.23 차이, low3과 약 6차이 / 중앙값: Attrited와 약 0.5차이, low3과 약 5차이)\n\nStd와 IQR 역시 Target 클러스터와 Attrited 클러스터가 low3보다 작은 모습을 보임. -> 분포가 좁고 값이 다양하지 않음.\n\n따라서 해당 변수는 Target 클러스터의 이탈 확률이 높은 이유를 대변한다고 할 수 있음.\n```\n\n<br>\n\n#### **Contacts_Count_12_mon**\n\n| Cluster Label | Mean | Std  | Median | IQR |\n| :------------ | :--- | :--- | :----- | :-- |\n| Attrited      | 2.97 | 1.09 | 3.0    | 2.0 |\n| Target        | 2.83 | 1.01 | 3.0    | 2.0 |\n| low3          | 3.01 | 0.81 | 3.0    | 2.0 |\n\n```\nTarget 클러스터의 연락 횟수의 통계는 Attrited와 조금 더 유사한 모습을 보이나, low3과의 차이도 크지 않음.\n(평균: Attrited와 약 0.14 차이, low3과 약 0.47 차이 / 중앙값: Attrited와 차이 없음, low3과 차이 없음)\n\nStd와 IQR 역시 큰 차이가 발견되지 않음.\n\n따라서 해당 변수는 비록 Target 클러스터가 Attrited와 조금 더 유사한 모습을 보이기는 하지만, 연락 횟수가 많은 이유가 충성도를 의미하는지, 혹은 불만을 의미하는지 명확하게 알 수 없기 때문에 Target 클러스터의 이탈 확률이 높은 이유를 대변한다고 하기는 어려움.\n```","metadata":{}},{"cell_type":"markdown","source":"# ✔ Process 05 - 전략도출 및 제안\n\n1. Target 클러스터 인사이트 및 현황 분석<br>\n    - 클러스터 구성 및 주요 특징\n    - Target vs Attrited / Low3 비교 분석\n2. Target 클러스터 맞춤 실행 전략 및 핵심 캠페인<br>\n3. 실 비즈니스 적용 방안<br>\n4. 분석 한계 및 향후 과제\n---","metadata":{}},{"cell_type":"markdown","source":"##  🔷 Target 고객 클러스터 기반 이탈 방지 및 매출 증대 전략\n\n- Target 클러스터 이탈 방지 전략 / 예상 효과\n- 분석 한계 및 향후 과제","metadata":{}},{"cell_type":"markdown","source":"### **🔶 Target 클러스터 이탈 방지 전략 / 예상 효과**\n\n<br>\n\n### **▶︎ 현황 분석**\n\n\n#### (1) 클러스터 구성\n- Target 클러스터: Cluster 4, 고객 수 **470명**, 평균 이탈 확률 약 **56%**\n- 비교군(유사하지만 안정적인 고객군): Low3, 고객 수 **1,564명**, 평균 이탈 확률 약 **4%**\n- Attrited(이탈군): 고객 수 **1,627명**, 평균 이탈 확률 약 **93%**\n\n<br>\n\n#### (2) Target vs Attrited \n\n| 변수 | Target | Attrited | 차이 및 의미 |\n|------|--------|----------|--------------|\n| 거래량 (Total_Trans_Ct) | 46.00 | 44.93 | 근소 차이, 이탈 직전 가능성 낮음 |\n| 회전 잔고 (Total_Revolving_Bal) | 892.40 | 672.82 | 현금 보유력 있음, 회복 여지 있음 |\n| 활동 점수 (Engagement_Score) | 9.55 | 9.32 | 활동성 근소 우위, 관리 가치 높음 |\n\n> **해석 요약**  \n> Target 클러스터는 아직 이탈 완전 직전은 아니며, 활동성 기반 회복 가능성이 존재함.\n\n<br>\n\n#### (3) Target vs Low3 \n\n| 변수 | Target | Low3 | 차이 및 시사점 |\n|------|--------|------|----------------|\n| 거래량 (Total_Trans_Ct) | 46.00 | 57.26 | 낮음, 거래 빈도 증대 필요 |\n| 회전 잔고 (Total_Revolving_Bal) | 892.40 | 1650.64 | 낮음, 잔고 활용 유도 필수 |\n| 금액 변화율 (Total_Amt_Chng_Q4_Q1) | 0.68 | 0.79 | 낮음, 지출 변화 관리 필요 |\n| 활동 점수 (Engagement_Score) | 9.55 | 14.47 | 낮음, 고객 참여도 강화 필요 |\n\n> **해석 요약**  \n> 충성 고객 대비 거래·활동성 방어벽 부족, 방치 시 이탈 위험 상승.\n\n<br>\n\n#### (4) 관계수(Total_Relationship_Count)에 대한 추가 해석\n- **Low3**: 평균 관계 수 3.41로 비교적 적지만, 거래 활동은 활발 → **집중형 충성 고객**일 가능성 높음  \n- **Target/Attrited**: 관계 수가 더 높음에도 불구하고 거래·활동성은 낮음  \n- **결론**: 다관계 보유가 반드시 높은 충성도로 이어지지 않음 → **관계 수 단독 지표는 방어 요인으로 적합하지 않음**\n\n\n<br>\n\n### **▶︎ 실행 전략**\n### Target 클러스터 (이탈 가능성 높은 유지 고객)\n\n <목표>\n\n- 이탈 방지 및 거래·활동성 강화  \n- 잔고 활용과 고객 참여도 제고  \n- 즉각적 리스크 탐지 및 대응  \n- 소수 핵심 상품 이용 고객의 집중도 유지 및 확대\n\n| 구분 | 핵심 인사이트 | 실행 전략 |\n|------|--------------|-----------|\n| **유지 요인 강화** (Attrited 대비) | 거래량·활동 점수 우위 | - 핵심 상품·서비스 중심 관계 유지 강화<br>- 활동 유지 고객 등급 업그레이드<br>- 행동 유도형 리워드 제공 |\n| **위험 요인 보완** (Low3 대비) | 거래량·잔고·활동성 모두 낮음 | - 거래 빈도·금액 증대 캠페인<br>- 소액·저위험 상품 권유<br>- 지표 상승 시 추가 혜택 제공 |\n| **즉시 대응** | 이탈 확률 약 56%, 분포 폭 넓음 | - 거래·활동 급감 시 실시간 개입<br>- 비활동 전환 전에 리마인드 발송 |\n| **집중 패턴 강화** | 일부 고객은 소수 핵심 상품에 높은 집중도를 보임 | - 해당 핵심 상품에 혜택·프로모션 집중<br>- 핵심 상품 이용 고객 전용 혜택 제공 |\n\n<br>\n\n### **▶︎ 실행 전략 및 실무 적용 방안**\n\n#### (1) 거래 활성화\n- **월간 거래 챌린지**: 전월 대비 거래 10%↑ 시 포인트·리워드 제공  \n- **누적 거래 혜택**: 3개월 연속 일정 거래액 달성 시 등급 업그레이드  \n- **소액 상품 번들**: 진입 부담이 낮은 소액 패키지 상품·서비스 제안  \n\n#### (2) 잔고 활용 유도\n- **예치금 보너스**: 일정 잔고 유지 고객에 쿠폰·포인트 지급  \n- **목표 잔고 달성 이벤트**: 목표 달성 시 실물 리워드 지급  \n\n#### (3) 활동 점수 제고\n- **활동 트리거 메시지**: 고객 활동 패턴 기반 맞춤형 푸시 알림 발송  \n- **참여형 콘텐츠 제공**: 앱 내 미션/퀴즈 참여 시 포인트 지급  \n\n#### (4) 고위험군 집중 관리\n- **실시간 모니터링**: 거래량·금액·활동성 급감 고객 실시간 탐지 및 대시보드 알림  \n- **즉각 개입**: 혜택 제공, 이탈 이유 설문, 담당자 직접 컨택  \n- **고객 응대 체계 강화**: 설문·상담 프로세스로 원인 파악 및 대응 전략 고도화\n  \n #### (5) 집중 패턴 강화\n- **핵심 상품 집중 프로모션**: 일부 고객의 소수 핵심 상품 집중도 유지·확대  \n- **교차 판매 및 패키지 구성**: 다상품 보유 고객 대상 할인·포인트 연계 혜택 제공 → 전환 비용 상승으로 이탈 억제  \n\n#### (6) 캠페인 설계 및 최적화\n- **고객 세분화 기반 맞춤형 캠페인**: 거래 패턴·잔고·활동 점수 기반 개인 맞춤형 혜택 제공  \n- **성과 측정 및 개선 사이클 운영**: KPI(이탈률, 거래 증가율, 잔고 유지율 등) 중심 성과 분석 후 정기적 전략 조정  \n\n<br>\n\n### **▶︎ 예상 효과**\n\n#### (1) 가정  \n- Target 클러스터 고객 수: 470명  \n- 현재 평균 이탈 확률: 약 56% (0.56) → 전략 적용 후 46% (0.46) 목표 (10%p 감소 가정)  \n- 고객 1명 평균 LTV: 180,000원  \n  (LTV는 평균 거래액, 구매 빈도 등 추정치 기반 산정)  \n\n#### (2) 계산  \n- 추가 유지 고객 수 = 470 × 0.10 = 47명  \n- 추가 매출 유지 효과 = 47 × 180,000원 = 8,460,000원  \n\n#### (3) 추정  \n- 단기: 약 846만 원 매출 유지 효과  \n- 중기: Low3 클러스터 평균 이탈 확률 약 4% (0.04) 목표 달성 시  \n  유지 고객 수 = 470 × (0.56 - 0.04) = 약 246명  \n  → 약 4.4억 원 매출 유지 효과 가능\n\n<br>\n\n### **▶︎ 기대 효과**\n- **단기**: 거래·활동성 회복, 즉각 매출 유지\n- **중기**: Target → Low3 전환율 상승\n- **장기**: 고객 생애 가치(LTV) 극대화, 재구매율 안정화\n\n<br>\n\n### 부록: Target 클러스터 대비 주요 클러스터별 중앙값 퍼센트 차이  \n\n| 변수                     | Low3 (%)     | Attrited (%)   |\n|--------------------------|--------------|----------------|\n| Total_Trans_Ct           | +32.6        | -6.5           |\n| Total_Revolving_Bal      | +100.6       | -100           |\n| Total_Ct_Chng_Q4_Q1      | +19.0        | -11.5          |\n| Total_Relationship_Count | -25.0        | -25.0          |\n| Months_Inactive_12_mon   | -33.3        | 0.0            |\n| Total_Amt_Chng_Q4_Q1     | +9.5         | +4.7           |\n| Engagement_Score         | +56.2        | -6.6           |\n| Contacts_Count_12_mon    | 0.0          | 0.0            |\n| Customer_Age             | +2.2         | +4.4           |\n| churn_probability        | -97.6        | +82.2          |\n\n해석: Low3는 Target 대비 거래·활동성에서 대폭 우위, Attrited는 전반적 저하와 높은 이탈 확률 보임\n\n\n---\n\n### **🔶 분석 한계 및 향후 과제**\n\n\n#### **▶︎ 분석 한계 (Limitations)**\n1. **정형 데이터 중심의 분석**\n   - 거래·관계·활동성 지표 등 수치형 데이터에 기반해 분석  \n   - VOC, 상담 내역, 앱 사용 로그 등 **비정형 데이터**를 반영하지 못해 이탈 원인의 정성적 맥락이 부족\n\n2. **이탈 정의의 단순화**\n   - Attrition_Flag를 0/1로 단순 구분  \n   - 이탈까지 걸린 기간, 점진적 활동 감소 패턴 등 **연속적 위험 단계**를 고려하지 않음\n\n3. **단일 시점 분석**\n   - 특정 시점의 데이터로만 클러스터링 진행  \n   - 계절성, 장기 추이, 이벤트 영향 등 **시간 변동성**이 반영되지 않음\n\n<br>\n\n#### **▶︎ 향후 과제 및 고도화 방향 (Next Step)**\n1. **행동 로그 + 비정형 데이터 통합**\n   - 앱 클릭·이탈 로그, 고객 불만·문의 기록, 상담 대화 분석 추가  \n   - Target 고객군의 ‘왜’ 이탈 위험이 발생하는지 원인 규명 강화\n\n2. **시계열·생존분석 적용**\n   - 월별 거래/활동 변화율 추적  \n   - 이탈 시점 예측 및 리텐션 곡선 분석으로 **사전 개입 시점** 명확화\n\n3. **전략 A/B 테스트**\n   - 제안된 마케팅 전략을 Target 일부에 실험 적용  \n   - Low3 전환율, 거래 증가율, 이탈 감소율 등 성과를 **정량 비교**\n\n4. **실시간 모니터링·대시보드 구축**\n   - 거래·활동 급감 고객 자동 식별  \n   - 고위험군 알림 + 즉시 대응 프로세스 운영","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}